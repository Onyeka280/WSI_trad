{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13907615,"sourceType":"datasetVersion","datasetId":8861189}],"dockerImageVersionId":31259,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Pixel Level Extraction","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI FEATURE EXTRACTION (PARALLEL BATCH PROCESSING)\n# ============================================================================\n\n# Import all required libraries\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects\nfrom skimage import feature\nfrom skimage.feature import local_binary_pattern, hog, graycomatrix, graycoprops\nfrom scipy import stats\nfrom scipy.stats import skew, kurtosis\nimport pywt\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\n# Number of slides to process in parallel (adjust based on Kaggle performance)\nPARALLEL_WORKERS = 4  # Kaggle has 4 CPU cores - process 4 slides at once\nBATCH_SIZE = 8  # Process slides in batches (adjust if memory issues)\n\n# ============================================================================\n# STEP 1: CHOOSE WHICH DATASET TO PROCESS\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI FEATURE EXTRACTION - PARALLEL BATCH MODE\")\nprint(\"=\"*80)\n\n# SELECT ONE DATASET AT A TIME\ndataset_to_process = \"saadinn/bracs-wsi-group-at-type-fea\"  # â† CHANGE THIS FOR EACH RUN\n\nprint(f\"\\nDownloading dataset: {dataset_to_process}\")\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name: {dataset_name}\")\nprint(f\"âœ“ Parallel workers: {PARALLEL_WORKERS}\")\nprint(f\"âœ“ Batch size: {BATCH_SIZE}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION FUNCTIONS\n# ============================================================================\n\ndef build_tissue_mask(slide, level=4):\n    \"\"\"Creates binary mask identifying tissue regions at low resolution\"\"\"\n    img = np.array(slide.read_region((0, 0), level, slide.level_dimensions[level]))[:, :, :3]\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    mask = saturation > 0.05\n    mask = remove_small_objects(mask, min_size=500)\n    mask = remove_small_holes(mask, area_threshold=500)\n    return mask\n\ndef tissue_ratio(mask, x, y, patch_size, scale):\n    \"\"\"Calculates proportion of tissue in a patch location\"\"\"\n    xs = int(x / scale)\n    ys = int(y / scale)\n    ps = int(patch_size / scale)\n    patch_mask = mask[ys:ys+ps, xs:xs+ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return patch_mask.mean()\n\ndef preprocess_patch(patch):\n    \"\"\"Normalizes staining variations using histogram equalization\"\"\"\n    patch = cv2.cvtColor(patch, cv2.COLOR_RGB2LAB)\n    patch[:, :, 0] = cv2.equalizeHist(patch[:, :, 0])\n    patch = cv2.cvtColor(patch, cv2.COLOR_LAB2RGB)\n    return patch\n\n# ============================================================================\n# STEP 3: ENHANCED FEATURE EXTRACTORS\n# ============================================================================\n\nclass EnhancedColorExtractor:\n    \"\"\"Extracts comprehensive color features from RGB images\"\"\"\n    \n    @staticmethod\n    def extract_all_color_features(rgb_patch: np.ndarray) -> dict:\n        features = {}\n        \n        # RGB channel features\n        for idx, channel_name in enumerate(['R', 'G', 'B']):\n            channel = rgb_patch[:, :, idx].flatten()\n            features[f'{channel_name}_mean'] = float(np.mean(channel))\n            features[f'{channel_name}_std'] = float(np.std(channel))\n            features[f'{channel_name}_skewness'] = float(skew(channel))\n            features[f'{channel_name}_kurtosis'] = float(kurtosis(channel))\n            features[f'{channel_name}_min'] = float(np.min(channel))\n            features[f'{channel_name}_max'] = float(np.max(channel))\n            features[f'{channel_name}_range'] = float(np.max(channel) - np.min(channel))\n            hist, _ = np.histogram(channel, bins=256, range=(0, 255))\n            hist = hist / (hist.sum() + 1e-10)\n            features[f'{channel_name}_entropy'] = float(-np.sum(hist * np.log2(hist + 1e-10)))\n        \n        # HSV features\n        hsv = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2HSV)\n        for idx, channel_name in enumerate(['H', 'S', 'V']):\n            channel = hsv[:, :, idx].flatten()\n            features[f'HSV_{channel_name}_mean'] = float(np.mean(channel))\n            features[f'HSV_{channel_name}_std'] = float(np.std(channel))\n        \n        # LAB features\n        lab = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2LAB)\n        for idx, channel_name in enumerate(['L', 'A', 'B']):\n            channel = lab[:, :, idx].flatten()\n            features[f'LAB_{channel_name}_mean'] = float(np.mean(channel))\n            features[f'LAB_{channel_name}_std'] = float(np.std(channel))\n        \n        return features\n\n\nclass EnhancedTextureExtractor:\n    \"\"\"Comprehensive texture feature extraction\"\"\"\n    \n    @staticmethod\n    def extract_all_texture_features(gray_patch: np.ndarray) -> dict:\n        features = {}\n        \n        # LBP features\n        try:\n            lbp = local_binary_pattern(gray_patch, 24, 3, method='uniform')\n            features['LBP_mean'] = float(np.mean(lbp))\n            features['LBP_std'] = float(np.std(lbp))\n        except:\n            features['LBP_mean'] = 0.0\n            features['LBP_std'] = 0.0\n        \n        # Gabor features\n        try:\n            for freq_idx, frequency in enumerate([0.1, 0.2]):\n                for theta_idx, theta in enumerate([0, np.pi/4]):\n                    kernel = cv2.getGaborKernel((31, 31), 5.0, theta, 1.0/frequency, 0.5, 0)\n                    filtered = cv2.filter2D(gray_patch, cv2.CV_32F, kernel)\n                    features[f'Gabor_f{freq_idx}_t{theta_idx}_mean'] = float(np.mean(filtered))\n                    features[f'Gabor_f{freq_idx}_t{theta_idx}_std'] = float(np.std(filtered))\n        except:\n            pass\n        \n        # GLCM features\n        try:\n            gray_quantized = (gray_patch / 32).astype(np.uint8)\n            glcm = graycomatrix(gray_quantized, [1], [0], levels=8, symmetric=True, normed=True)\n            features['GLCM_contrast'] = float(graycoprops(glcm, 'contrast')[0, 0])\n            features['GLCM_homogeneity'] = float(graycoprops(glcm, 'homogeneity')[0, 0])\n            features['GLCM_energy'] = float(graycoprops(glcm, 'energy')[0, 0])\n        except:\n            pass\n        \n        return features\n\n\nclass WaveletFeatureExtractor:\n    \"\"\"Wavelet transform features\"\"\"\n    \n    @staticmethod\n    def extract_wavelet_features(gray_patch: np.ndarray) -> dict:\n        features = {}\n        \n        try:\n            coeffs = pywt.wavedec2(gray_patch, 'db4', level=2)\n            \n            # Approximation coefficients\n            cA = coeffs[0]\n            features['Wavelet_L0_LL_mean'] = float(np.mean(cA))\n            features['Wavelet_L0_LL_std'] = float(np.std(cA))\n            features['Wavelet_L0_LL_energy'] = float(np.sum(cA ** 2))\n            \n            # Detail coefficients\n            for i in range(1, len(coeffs)):\n                cH, cV, cD = coeffs[i]\n                features[f'Wavelet_L{i}_LH_energy'] = float(np.sum(cH ** 2))\n                features[f'Wavelet_L{i}_HL_energy'] = float(np.sum(cV ** 2))\n                features[f'Wavelet_L{i}_HH_energy'] = float(np.sum(cD ** 2))\n        except:\n            pass\n        \n        return features\n\n\nclass ComprehensivePixelFeatureExtractor:\n    \"\"\"Combines all pixel-level feature extractors\"\"\"\n    \n    def __init__(self):\n        self.color_extractor = EnhancedColorExtractor()\n        self.texture_extractor = EnhancedTextureExtractor()\n        self.wavelet_extractor = WaveletFeatureExtractor()\n    \n    def extract_all_features(self, rgb_patch: np.ndarray) -> dict:\n        all_features = {}\n        gray_patch = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        all_features.update(self.color_extractor.extract_all_color_features(rgb_patch))\n        all_features.update(self.texture_extractor.extract_all_texture_features(gray_patch))\n        all_features.update(self.wavelet_extractor.extract_wavelet_features(gray_patch))\n        return all_features\n\n# ============================================================================\n# STEP 4: PATCH-LEVEL FEATURE EXTRACTION\n# ============================================================================\n\ndef extract_features_from_wsi(\n    wsi_path,\n    patch_size=256,\n    target_level=1,\n    tissue_threshold=0.3\n):\n    \"\"\"Extracts features from all tissue patches in a WSI\"\"\"\n    slide = openslide.OpenSlide(wsi_path)\n    mask_level = slide.level_count - 1\n    tissue_mask = build_tissue_mask(slide, mask_level)\n    scale = slide.level_downsamples[mask_level]\n    extractor = ComprehensivePixelFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n    step = patch_size\n    \n    # Count total patches\n    total_patches = 0\n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio >= tissue_threshold:\n                total_patches += 1\n    \n    # Extract patches (NO progress bar for parallel processing)\n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio < tissue_threshold:\n                continue\n            \n            patch = slide.read_region(\n                (int(x * slide.level_downsamples[target_level]),\n                 int(y * slide.level_downsamples[target_level])),\n                target_level, (patch_size, patch_size)\n            )\n            patch = np.array(patch)[:, :, :3]\n            patch = preprocess_patch(patch)\n            patch_features = extractor.extract_all_features(patch)\n            patch_features['patch_x'] = x\n            patch_features['patch_y'] = y\n            patch_features['tissue_ratio'] = float(ratio)\n            features_list.append(patch_features)\n    \n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 5: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    \"\"\"Converts patch-level features to slide-level features\"\"\"\n    if not patch_features_list:\n        return {}\n    \n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n    \n    slide_features = {}\n    slide_features['slide_name'] = slide_name\n    slide_features['num_patches'] = len(patch_features_list)\n    \n    # Aggregate each feature\n    for feature in feature_cols:\n        feature_values = df[feature].values\n        slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n        slide_features[f'{feature}_std'] = float(np.std(feature_values))\n        slide_features[f'{feature}_min'] = float(np.min(feature_values))\n        slide_features[f'{feature}_max'] = float(np.max(feature_values))\n        slide_features[f'{feature}_median'] = float(np.median(feature_values))\n        slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n        slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n    \n    # Tissue coverage statistics\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n    \n    return slide_features\n\n# ============================================================================\n# STEP 6: PARALLEL SLIDE PROCESSING FUNCTION\n# ============================================================================\n\ndef process_single_slide(args):\n    \"\"\"\n    Process one complete slide (designed for parallel execution)\n    This function will be called by multiple workers simultaneously\n    \"\"\"\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    \n    try:\n        # Extract PATCH-level features\n        patch_features = extract_features_from_wsi(\n            slide_path,\n            patch_size=patch_size,\n            target_level=target_level,\n            tissue_threshold=tissue_threshold\n        )\n        \n        if patch_features:\n            # Aggregate to SLIDE-level\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, \n                f\"{dataset_name}_{slide_name}\"\n            )\n            \n            return {\n                'success': True,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': slide_features,\n                'num_patches': len(patch_features),\n                'error': None\n            }\n        else:\n            return {\n                'success': False,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': None,\n                'num_patches': 0,\n                'error': 'No tissue patches found'\n            }\n            \n    except Exception as e:\n        return {\n            'success': False,\n            'slide_path': slide_path,\n            'slide_name': slide_name,\n            'features': None,\n            'num_patches': 0,\n            'error': str(e)\n        }\n\n# ============================================================================\n# STEP 7: CHECKPOINT SYSTEM\n# ============================================================================\n\ndef load_checkpoint(dataset_name):\n    \"\"\"Load checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_{dataset_name}.json'\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            return set(json.load(f))\n    return set()\n\ndef save_checkpoint(processed_slides, dataset_name):\n    \"\"\"Save checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_{dataset_name}.json'\n    with open(checkpoint_file, 'w') as f:\n        json.dump(list(processed_slides), f)\n\n# ============================================================================\n# STEP 8: MAIN PROCESSING LOOP WITH PARALLEL BATCHES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING PARALLEL BATCH FEATURE EXTRACTION\")\nprint(\"=\"*80)\n\n# Create output directory\noutput_path = f'/kaggle/working/features_{dataset_name}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Load checkpoint\nprocessed_slides = load_checkpoint(dataset_name)\nprint(f\"Already processed: {len(processed_slides)} slides\")\n\n# Find all slides\nslides = []\nfor root, dirs, files in os.walk(dataset_path):\n    slides.extend([os.path.join(root, f) for f in files \n                  if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))])\n\n# Filter out already processed slides\nslides_to_process = [s for s in slides if s not in processed_slides]\n\nprint(f\"Total slides in dataset: {len(slides)}\")\nprint(f\"Slides remaining to process: {len(slides_to_process)}\")\n\n# Storage for slide-level features\nall_slides_features = []\n\n# Process slides in batches with parallel workers\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"PROCESSING BATCH {batch_start//BATCH_SIZE + 1}\")\n    print(f\"Slides {batch_start + 1}-{batch_end} of {len(slides_to_process)}\")\n    print(f\"Processing {len(batch_slides)} slides with {PARALLEL_WORKERS} parallel workers\")\n    print(f\"{'='*80}\")\n    \n    # Prepare arguments for parallel processing\n    slide_args = [\n        (slide_path, dataset_name, 256, 1, 0.3)\n        for slide_path in batch_slides\n    ]\n    \n    # Process batch in parallel\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        # Submit all slides in batch\n        futures = {executor.submit(process_single_slide, args): args[0] \n                  for args in slide_args}\n        \n        # Collect results as they complete\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            \n            try:\n                result = future.result()\n                \n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    processed_slides.add(result['slide_path'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n                    \n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n    \n    # Save checkpoint after each batch\n    save_checkpoint(processed_slides, dataset_name)\n    \n    # Save temporary results\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides completed\")\n\n# ============================================================================\n# STEP 9: SAVE FINAL RESULTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING FINAL RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    # Convert to DataFrame\n    final_df = pd.DataFrame(all_slides_features)\n    \n    print(f\"\\nFinal dataset shape: {final_df.shape}\")\n    print(f\"  - Rows (slides): {final_df.shape[0]}\")\n    print(f\"  - Columns (features): {final_df.shape[1]}\")\n    \n    # Save as CSV\n    csv_path = f'{output_path}/{dataset_name}_slide_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"âœ“ Saved CSV to: {csv_path}\")\n    \n    # Save as compressed numpy\n    npz_path = f'{output_path}/{dataset_name}_slide_features.npz'\n    np.savez_compressed(\n        npz_path,\n        slide_names=final_df['slide_name'].values,\n        features=final_df.drop('slide_name', axis=1).values,\n        feature_names=final_df.drop('slide_name', axis=1).columns.values\n    )\n    print(f\"âœ“ Saved NPZ to: {npz_path}\")\n    \n    # Show sample\n    print(\"\\n\" + \"=\"*80)\n    print(\"SAMPLE OUTPUT\")\n    print(\"=\"*80)\n    print(final_df.head())\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"FEATURE EXTRACTION COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Total slides processed: {len(all_slides_features)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n    print(f\"Output directory: {output_path}\")\n    print(f\"Parallel workers used: {PARALLEL_WORKERS}\")\n    print(f\"Batch size: {BATCH_SIZE}\")\nelse:\n    print(\"âš  No slides were successfully processed!\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"NEXT STEPS:\")\nprint(\"=\"*80)\nprint(\"1. Download the CSV file\")\nprint(\"2. Change the dataset name at the top of this code:\")\nprint(f'   dataset_to_process = \"saadinn/bracs-wsi-group-NEXT-DATASET\"')\nprint(\"3. Run again for the next dataset\")\nprint(\"4. Repeat for all 9 datasets\")\nprint(\"=\"*80)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Object Level","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (OPTIMIZED CPU)\n# ============================================================================\n\n# Import all required libraries\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, erosion, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\nPARALLEL_WORKERS = 4  # Kaggle has 4 CPU cores\nBATCH_SIZE = 8\n\n# ============================================================================\n# STEP 1: CHOOSE WHICH DATASET TO PROCESS\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - OPTIMIZED CPU VERSION\")\nprint(\"=\"*80)\n\ndataset_to_process = \"saadinn/bracs-wsi-group-at-type-fea\"\n\nprint(f\"\\nDownloading dataset: {dataset_to_process}\")\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name: {dataset_name}\")\nprint(f\"âœ“ Parallel workers: {PARALLEL_WORKERS}\")\nprint(f\"âœ“ Batch size: {BATCH_SIZE}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION FUNCTIONS\n# ============================================================================\n\ndef build_tissue_mask(slide, level=4):\n    \"\"\"Creates binary mask identifying tissue regions at low resolution\"\"\"\n    img = np.array(slide.read_region((0, 0), level, slide.level_dimensions[level]))[:, :, :3]\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    mask = saturation > 0.05\n    mask = remove_small_objects(mask, min_size=500)\n    mask = remove_small_holes(mask, area_threshold=500)\n    return mask\n\ndef tissue_ratio(mask, x, y, patch_size, scale):\n    \"\"\"Calculates proportion of tissue in a patch location\"\"\"\n    xs = int(x / scale)\n    ys = int(y / scale)\n    ps = int(patch_size / scale)\n    patch_mask = mask[ys:ys+ps, xs:xs+ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return patch_mask.mean()\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n    \"\"\"Segments nuclei from H&E stained histopathology images\"\"\"\n    \n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        \"\"\"Extract hematoxylin channel using color deconvolution\"\"\"\n        # Normalize RGB to [0, 1]\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.maximum(rgb_norm, 1e-6)\n        \n        # Convert to optical density (OD)\n        od = -np.log(rgb_norm)\n        \n        # H&E stain matrix\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],\n            [0.07, 0.99, 0.11],\n            [0.27, 0.57, 0.78]\n        ])\n        \n        # Deconvolve to get stain concentrations\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        \n        # Normalize to [0, 255]\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        \n        return hematoxylin\n    \n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        \"\"\"Segments nuclei using multiple methods for robustness\"\"\"\n        try:\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            _, nucleus_mask = cv2.threshold(hematoxylin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            nucleus_mask = nucleus_mask > 0\n        except:\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            gray_inv = 255 - gray\n            _, nucleus_mask = cv2.threshold(gray_inv, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            nucleus_mask = nucleus_mask > 0\n        \n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=15)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=15)\n        \n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n        \n        nucleus_mask = erosion(nucleus_mask, disk(1))\n        nucleus_mask = dilation(nucleus_mask, disk(2))\n        \n        distance = ndi.distance_transform_edt(nucleus_mask)\n        coords = peak_local_max(distance, min_distance=3, labels=nucleus_mask, exclude_border=False)\n        \n        if len(coords) == 0:\n            labeled_nuclei = label(nucleus_mask)\n            return labeled_nuclei\n        \n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n        \n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: OBJECT-LEVEL FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n    \"\"\"Extracts morphological and intensity features from individual nuclei\"\"\"\n    \n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        \"\"\"Extract features from a single nucleus region\"\"\"\n        features = {}\n        \n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        \n        if region.perimeter > 0:\n            features['circularity'] = float(4 * np.pi * region.area / (region.perimeter ** 2))\n        else:\n            features['circularity'] = 0.0\n        \n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        \n        if region.minor_axis_length > 0:\n            features['aspect_ratio'] = float(region.major_axis_length / region.minor_axis_length)\n        else:\n            features['aspect_ratio'] = 0.0\n        \n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n        \n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        \n        return features\n\n\nclass SpatialFeatureExtractor:\n    \"\"\"Extracts spatial arrangement features from nuclei populations\"\"\"\n    \n    @staticmethod\n    def extract_spatial_features(regions):\n        \"\"\"Extract features describing spatial distribution of nuclei\"\"\"\n        features = {}\n        \n        if len(regions) == 0:\n            return features\n        \n        centroids = np.array([region.centroid for region in regions])\n        \n        features['nucleus_count'] = len(regions)\n        total_area = sum([region.area for region in regions])\n        features['total_nucleus_area'] = float(total_area)\n        \n        if len(centroids) > 1:\n            distances = cdist(centroids, centroids)\n            np.fill_diagonal(distances, np.inf)\n            \n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n            \n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            features['pairwise_distance_mean'] = float(np.mean(upper_triangle))\n            features['pairwise_distance_std'] = float(np.std(upper_triangle))\n            features['pairwise_distance_min'] = float(np.min(upper_triangle))\n            features['pairwise_distance_max'] = float(np.max(upper_triangle))\n        \n        if len(centroids) > 2:\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n        \n        return features\n\n\nclass GraphFeatureExtractor:\n    \"\"\"Extracts graph-based features from nucleus spatial relationships\"\"\"\n    \n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        \"\"\"Build graph connecting nearby nuclei\"\"\"\n        from scipy.spatial import Delaunay\n        \n        if len(centroids) < 3:\n            return None, None\n        \n        try:\n            tri = Delaunay(centroids)\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i+1)%3]]))\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            return tri, list(edges)\n        except:\n            return None, None\n    \n    @staticmethod\n    def extract_graph_features(regions):\n        \"\"\"Extract graph-based topological features\"\"\"\n        features = {}\n        \n        if len(regions) < 3:\n            return features\n        \n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n        \n        if edges is None or len(edges) == 0:\n            return features\n        \n        features['num_edges'] = len(edges)\n        features['edge_density'] = float(len(edges) / (len(regions) * (len(regions) - 1) / 2))\n        \n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n        \n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n        \n        edge_lengths = [np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n        \n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n    \"\"\"Combines all object-level feature extractors\"\"\"\n    \n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n    \n    def extract_all_features(self, rgb_patch):\n        \"\"\"Extract all object-level features from a patch\"\"\"\n        all_features = {}\n        \n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        regions = [r for r in regions if r.area >= 10]\n        \n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum([r.area for r in regions]) if regions else 0.0)\n        \n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except:\n                    continue\n            \n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n        \n        if len(regions) > 0:\n            spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n            all_features.update(spatial_features)\n        \n        if len(regions) >= 3:\n            graph_features = self.graph_extractor.extract_graph_features(regions)\n            all_features.update(graph_features)\n        \n        return all_features\n\n# ============================================================================\n# STEP 5: PATCH-LEVEL FEATURE EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(wsi_path, patch_size=256, target_level=1, tissue_threshold=0.3):\n    \"\"\"Extracts object-level features from all tissue patches in a WSI\"\"\"\n    slide = openslide.OpenSlide(wsi_path)\n    mask_level = slide.level_count - 1\n    tissue_mask = build_tissue_mask(slide, mask_level)\n    scale = slide.level_downsamples[mask_level]\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n    step = patch_size\n    \n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio < tissue_threshold:\n                continue\n            \n            patch = slide.read_region(\n                (int(x * slide.level_downsamples[target_level]),\n                 int(y * slide.level_downsamples[target_level])),\n                target_level, (patch_size, patch_size)\n            )\n            patch = np.array(patch)[:, :, :3]\n            \n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception as e:\n                continue\n    \n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    \"\"\"Converts patch-level features to slide-level features with proper NaN handling\"\"\"\n    if not patch_features_list:\n        return {}\n    \n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n    \n    slide_features = {}\n    slide_features['slide_name'] = slide_name\n    slide_features['num_patches'] = len(patch_features_list)\n    \n    for feature in feature_cols:\n        feature_values = df[feature].dropna().values\n        \n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            slide_features[f'{feature}_mean'] = 0.0\n            slide_features[f'{feature}_std'] = 0.0\n            slide_features[f'{feature}_min'] = 0.0\n            slide_features[f'{feature}_max'] = 0.0\n            slide_features[f'{feature}_median'] = 0.0\n            slide_features[f'{feature}_q25'] = 0.0\n            slide_features[f'{feature}_q75'] = 0.0\n    \n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n    \n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING\n# ============================================================================\n\ndef process_single_slide(args):\n    \"\"\"Process one complete slide\"\"\"\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    \n    try:\n        patch_features = extract_object_features_from_wsi(\n            slide_path, patch_size, target_level, tissue_threshold\n        )\n        \n        if patch_features:\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, f\"{dataset_name}_{slide_name}\"\n            )\n            \n            return {\n                'success': True,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': slide_features,\n                'num_patches': len(patch_features),\n                'error': None\n            }\n        else:\n            return {\n                'success': False,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': None,\n                'num_patches': 0,\n                'error': 'No tissue patches found'\n            }\n    except Exception as e:\n        return {\n            'success': False,\n            'slide_path': slide_path,\n            'slide_name': slide_name,\n            'features': None,\n            'num_patches': 0,\n            'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: CHECKPOINT SYSTEM\n# ============================================================================\n\ndef load_checkpoint(dataset_name):\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            return set(json.load(f))\n    return set()\n\ndef save_checkpoint(processed_slides, dataset_name):\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    with open(checkpoint_file, 'w') as f:\n        json.dump(list(processed_slides), f)\n\n# ============================================================================\n# STEP 9: MAIN PROCESSING LOOP\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING PARALLEL BATCH OBJECT-LEVEL FEATURE EXTRACTION\")\nprint(\"=\"*80)\n\noutput_path = f'/kaggle/working/object_features_{dataset_name}/'\nos.makedirs(output_path, exist_ok=True)\n\nprocessed_slides = load_checkpoint(dataset_name)\nprint(f\"Already processed: {len(processed_slides)} slides\")\n\nslides = []\nfor root, dirs, files in os.walk(dataset_path):\n    slides.extend([os.path.join(root, f) for f in files \n                  if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))])\n\nslides_to_process = [s for s in slides if s not in processed_slides]\n\nprint(f\"Total slides in dataset: {len(slides)}\")\nprint(f\"Slides remaining to process: {len(slides_to_process)}\")\n\nall_slides_features = []\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"PROCESSING BATCH {batch_start//BATCH_SIZE + 1}\")\n    print(f\"Slides {batch_start + 1}-{batch_end} of {len(slides_to_process)}\")\n    print(f\"Processing {len(batch_slides)} slides with {PARALLEL_WORKERS} parallel workers\")\n    print(f\"{'='*80}\")\n    \n    slide_args = [(slide_path, dataset_name, 256, 1, 0.3) for slide_path in batch_slides]\n    \n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        futures = {executor.submit(process_single_slide, args): args[0] for args in slide_args}\n        \n        for future in as_completed(futures):\n            slide_path = futures[future]\n            \n            try:\n                result = future.result()\n                \n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    processed_slides.add(result['slide_path'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n    \n    save_checkpoint(processed_slides, dataset_name)\n    \n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides completed\")\n\n# ============================================================================\n# STEP 10: SAVE FINAL RESULTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING FINAL RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    final_df = pd.DataFrame(all_slides_features)\n    \n    print(f\"\\nFinal dataset shape: {final_df.shape}\")\n    print(f\"  - Rows (slides): {final_df.shape[0]}\")\n    print(f\"  - Columns (features): {final_df.shape[1]}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"NUCLEUS DETECTION DIAGNOSTICS\")\n    print(\"=\"*80)\n    \n    nucleus_count_cols = [col for col in final_df.columns if 'nucleus_count' in col.lower()]\n    if nucleus_count_cols:\n        for col in nucleus_count_cols:\n            mean_count = final_df[col].mean()\n            print(f\"{col}: mean = {mean_count:.2f}\")\n            zero_count = (final_df[col] == 0).sum()\n            print(f\"  Slides with 0 nuclei: {zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n    \n    nan_counts = final_df.isna().sum()\n    cols_with_nans = nan_counts[nan_counts > 0]\n    if len(cols_with_nans) > 0:\n        print(f\"\\nColumns with NaN values: {len(cols_with_nans)}/{len(final_df.columns)}\")\n        print(f\"Most NaN values: {nan_counts.max()} ({100*nan_counts.max()/len(final_df):.1f}% of slides)\")\n        print(\"\\nTop 10 columns with NaNs:\")\n        print(nan_counts.nlargest(10))\n    else:\n        print(\"\\nâœ“ No NaN values found! All features properly computed.\")\n    \n    zero_cols = (final_df == 0).all()\n    all_zero_cols = zero_cols[zero_cols].index.tolist()\n    if all_zero_cols:\n        print(f\"\\nColumns with all zeros: {len(all_zero_cols)}\")\n        if len(all_zero_cols) <= 20:\n            print(f\"Zero columns: {all_zero_cols}\")\n    \n    print(\"=\"*80)\n    \n    csv_path = f'{output_path}/{dataset_name}_slide_object_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved CSV to: {csv_path}\")\n    \n    npz_path = f'{output_path}/{dataset_name}_slide_object_features.npz'\n    np.savez_compressed(\n        npz_path,\n        slide_names=final_df['slide_name'].values,\n        features=final_df.drop('slide_name', axis=1).values,\n        feature_names=final_df.drop('slide_name', axis=1).columns.values\n    )\n    print(f\"âœ“ Saved NPZ to: {npz_path}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"SAMPLE OUTPUT\")\n    print(\"=\"*80)\n    print(final_df.head())\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"OBJECT-LEVEL FEATURE EXTRACTION COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Total slides processed: {len(all_slides_features)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\nelse:\n    print(\"âš  No slides were successfully processed!\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"NEXT STEPS:\")\nprint(\"=\"*80)\nprint(\"1. Download the CSV file\")\nprint(\"2. Change dataset_to_process for next dataset\")\nprint(\"3. Repeat for all datasets\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-16T12:10:43.759042Z","iopub.execute_input":"2026-02-16T12:10:43.759378Z","iopub.status.idle":"2026-02-16T18:24:34.509939Z","shell.execute_reply.started":"2026-02-16T12:10:43.759350Z","shell.execute_reply":"2026-02-16T18:24:34.509057Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nBRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - OPTIMIZED CPU VERSION\n================================================================================\n\nDownloading dataset: saadinn/bracs-wsi-group-at-type-fea\nâœ“ Downloaded to: /kaggle/input/bracs-wsi-group-at-type-fea\nâœ“ Dataset name: bracs-wsi-group-at-type-fea\nâœ“ Parallel workers: 4\nâœ“ Batch size: 8\n\n================================================================================\nSTARTING PARALLEL BATCH OBJECT-LEVEL FEATURE EXTRACTION\n================================================================================\nAlready processed: 0 slides\nTotal slides in dataset: 41\nSlides remaining to process: 41\n\n================================================================================\nPROCESSING BATCH 1\nSlides 1-8 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1955.svs: 1686 patches\n  âœ“ BRACS_1319.svs: 3538 patches\n  âœ“ BRACS_1610.svs: 2999 patches\n  âœ“ BRACS_2007.svs: 1220 patches\n  âœ“ BRACS_300.svs: 1896 patches\n  âœ“ BRACS_1773.svs: 3447 patches\n  âœ“ BRACS_1239.svs: 6249 patches\n  âœ“ BRACS_1257.svs: 5965 patches\n\n  ðŸ’¾ Batch checkpoint: 8 slides completed\n\n================================================================================\nPROCESSING BATCH 2\nSlides 9-16 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1937.svs: 2457 patches\n  âœ“ BRACS_1968.svs: 2141 patches\n  âœ“ BRACS_1003693.svs: 3490 patches\n  âœ“ BRACS_1857.svs: 1711 patches\n  âœ“ BRACS_3266.svs: 724 patches\n  âœ“ BRACS_1865.svs: 4328 patches\n  âœ“ BRACS_1813.svs: 3797 patches\n  âœ“ BRACS_1838.svs: 3772 patches\n\n  ðŸ’¾ Batch checkpoint: 16 slides completed\n\n================================================================================\nPROCESSING BATCH 3\nSlides 17-24 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1506.svs: 2004 patches\n  âœ“ BRACS_1775.svs: 2824 patches\n  âœ“ BRACS_1777.svs: 4548 patches\n  âœ“ BRACS_1871.svs: 2254 patches\n  âœ“ BRACS_1250.svs: 2888 patches\n  âœ“ BRACS_1858.svs: 5577 patches\n  âœ“ BRACS_743.svs: 6235 patches\n  âœ“ BRACS_1916.svs: 2023 patches\n\n  ðŸ’¾ Batch checkpoint: 24 slides completed\n\n================================================================================\nPROCESSING BATCH 4\nSlides 25-32 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1941.svs: 1750 patches\n  âœ“ BRACS_1971.svs: 2425 patches\n  âœ“ BRACS_1788.svs: 1685 patches\n  âœ“ BRACS_1510.svs: 1679 patches\n  âœ“ BRACS_1954.svs: 1598 patches\n  âœ“ BRACS_1815.svs: 3231 patches\n  âœ“ BRACS_1926.svs: 3109 patches\n  âœ“ BRACS_1774.svs: 1340 patches\n\n  ðŸ’¾ Batch checkpoint: 32 slides completed\n\n================================================================================\nPROCESSING BATCH 5\nSlides 33-40 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_3285.svs: 196 patches\n  âœ“ BRACS_1886.svs: 1173 patches\n  âœ“ BRACS_1943.svs: 1780 patches\n  âœ“ BRACS_1799.svs: 2238 patches\n  âœ“ BRACS_1778.svs: 1737 patches\n  âœ“ BRACS_1944.svs: 1085 patches\n  âœ“ BRACS_1936.svs: 2642 patches\n  âœ“ BRACS_1814.svs: 4049 patches\n\n  ðŸ’¾ Batch checkpoint: 40 slides completed\n\n================================================================================\nPROCESSING BATCH 6\nSlides 41-41 of 41\nProcessing 1 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1975.svs: 1987 patches\n\n  ðŸ’¾ Batch checkpoint: 41 slides completed\n\n================================================================================\nSAVING FINAL RESULTS\n================================================================================\n\nFinal dataset shape: (41, 914)\n  - Rows (slides): 41\n  - Columns (features): 914\n\n================================================================================\nNUCLEUS DETECTION DIAGNOSTICS\n================================================================================\nnucleus_count_mean: mean = 164.65\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_std: mean = 93.21\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_min: mean = 2.15\n  Slides with 0 nuclei: 8/41 (19.5%)\nnucleus_count_max: mean = 576.54\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_median: mean = 149.88\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_q25: mean = 97.80\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_q75: mean = 216.59\n  Slides with 0 nuclei: 0/41 (0.0%)\n\nâœ“ No NaN values found! All features properly computed.\n\nColumns with all zeros: 4\nZero columns: ['nucleus_eccentricity_min_min', 'nucleus_eccentricity_min_median', 'nucleus_eccentricity_min_q25', 'nucleus_eccentricity_min_q75']\n================================================================================\n\nâœ“ Saved CSV to: /kaggle/working/object_features_bracs-wsi-group-at-type-fea//bracs-wsi-group-at-type-fea_slide_object_features.csv\nâœ“ Saved NPZ to: /kaggle/working/object_features_bracs-wsi-group-at-type-fea//bracs-wsi-group-at-type-fea_slide_object_features.npz\n\n================================================================================\nSAMPLE OUTPUT\n================================================================================\n                                   slide_name  num_patches  \\\n0  bracs-wsi-group-at-type-fea_BRACS_1955.svs         1686   \n1  bracs-wsi-group-at-type-fea_BRACS_1319.svs         3538   \n2  bracs-wsi-group-at-type-fea_BRACS_1610.svs         2999   \n3  bracs-wsi-group-at-type-fea_BRACS_2007.svs         1220   \n4   bracs-wsi-group-at-type-fea_BRACS_300.svs         1896   \n\n   nucleus_count_mean  nucleus_count_std  nucleus_count_min  \\\n0          132.724792         106.259738                1.0   \n1          172.067835          85.198474                3.0   \n2          225.217739         119.689229                2.0   \n3           94.814754          59.901505                0.0   \n4          111.973101          60.697274                0.0   \n\n   nucleus_count_max  nucleus_count_median  nucleus_count_q25  \\\n0              537.0                  95.0               52.0   \n1              727.0                 164.5              115.0   \n2              621.0                 218.0              127.0   \n3              385.0                  82.5               55.0   \n4              409.0                  97.0               73.0   \n\n   nucleus_count_q75  total_nucleus_area_mean  ...  edge_length_min_q75  \\\n0              191.0              8826.459075  ...             3.562268   \n1              217.0             13694.207744  ...             3.458205   \n2              310.0              9290.619206  ...             3.235310   \n3              120.0              9533.280328  ...             3.538361   \n4              137.0              4321.507911  ...             3.449757   \n\n   edge_length_max_mean  edge_length_max_std  edge_length_max_min  \\\n0             94.710535             6.894386             9.734188   \n1             94.533672             5.963857            13.480766   \n2             94.469718             5.613326             9.771811   \n3             94.126964             8.673883             8.456438   \n4             95.272391             5.276133             4.647896   \n\n   edge_length_max_max  edge_length_max_median  edge_length_max_q25  \\\n0            99.996850               96.606371            93.236292   \n1            99.996735               96.084394            92.260192   \n2            99.995932               95.885284            92.392050   \n3            99.992932               96.591791            92.631874   \n4            99.999175               96.683538            93.479366   \n\n   edge_length_max_q75  tissue_ratio_mean  tissue_ratio_std  \n0            98.626822           0.951496          0.147781  \n1            98.417548           0.960510          0.130243  \n2            98.210163           0.977511          0.101101  \n3            98.492261           0.945173          0.154304  \n4            98.629700           0.985835          0.079484  \n\n[5 rows x 914 columns]\n\n================================================================================\nOBJECT-LEVEL FEATURE EXTRACTION COMPLETE!\n================================================================================\nDataset: bracs-wsi-group-at-type-fea\nTotal slides processed: 41\nFeatures per slide: 914\n\n================================================================================\nNEXT STEPS:\n================================================================================\n1. Download the CSV file\n2. Change dataset_to_process for next dataset\n3. Repeat for all datasets\n================================================================================\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (PARALLEL BATCH)\n# ============================================================================\n\n# Import all required libraries\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, erosion, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\n# Number of slides to process in parallel (adjust based on Kaggle performance)\nPARALLEL_WORKERS = 4  # Kaggle has 4 CPU cores - process 4 slides at once\nBATCH_SIZE = 8  # Process slides in batches (adjust if memory issues)\n\n# ============================================================================\n# STEP 1: CHOOSE WHICH DATASET TO PROCESS\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - PARALLEL BATCH MODE\")\nprint(\"=\"*80)\n\n# SELECT ONE DATASET AT A TIME\ndataset_to_process = \"saadinn/bracs-wsi-group-at-type-fea\"  # â† CHANGE THIS FOR EACH RUN\n\nprint(f\"\\nDownloading dataset: {dataset_to_process}\")\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name: {dataset_name}\")\nprint(f\"âœ“ Parallel workers: {PARALLEL_WORKERS}\")\nprint(f\"âœ“ Batch size: {BATCH_SIZE}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION FUNCTIONS\n# ============================================================================\n\ndef build_tissue_mask(slide, level=4):\n    \"\"\"Creates binary mask identifying tissue regions at low resolution\"\"\"\n    img = np.array(slide.read_region((0, 0), level, slide.level_dimensions[level]))[:, :, :3]\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    mask = saturation > 0.05\n    mask = remove_small_objects(mask, min_size=500)\n    mask = remove_small_holes(mask, area_threshold=500)\n    return mask\n\ndef tissue_ratio(mask, x, y, patch_size, scale):\n    \"\"\"Calculates proportion of tissue in a patch location\"\"\"\n    xs = int(x / scale)\n    ys = int(y / scale)\n    ps = int(patch_size / scale)\n    patch_mask = mask[ys:ys+ps, xs:xs+ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return patch_mask.mean()\n\ndef preprocess_patch(patch):\n    \"\"\"Normalizes staining variations using histogram equalization\"\"\"\n    patch = cv2.cvtColor(patch, cv2.COLOR_RGB2LAB)\n    patch[:, :, 0] = cv2.equalizeHist(patch[:, :, 0])\n    patch = cv2.cvtColor(patch, cv2.COLOR_LAB2RGB)\n    return patch\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n    \"\"\"Segments nuclei from H&E stained histopathology images\"\"\"\n    \n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        \"\"\"\n        Extract hematoxylin channel using color deconvolution\n        Hematoxylin stains nuclei (blue/purple in H&E)\n        \"\"\"\n        # Normalize RGB to [0, 1]\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.maximum(rgb_norm, 1e-6)  # Avoid log(0)\n        \n        # Convert to optical density (OD)\n        od = -np.log(rgb_norm)\n        \n        # H&E stain matrix (standard values from Ruifrok & Johnston)\n        # Columns are [Hematoxylin, Eosin, Residual]\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],  # Hematoxylin (absorbs red)\n            [0.07, 0.99, 0.11],  # Eosin (absorbs blue)\n            [0.27, 0.57, 0.78]   # Residual\n        ])\n        \n        # Deconvolve to get stain concentrations\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        \n        # Normalize to [0, 255]\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        \n        return hematoxylin\n    \n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        \"\"\"\n        Segments nuclei using multiple methods for robustness\n        Returns labeled image where each nucleus has unique ID\n        \"\"\"\n        try:\n            # Method 1: Color deconvolution (preferred)\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            \n            # Apply Otsu thresholding\n            _, nucleus_mask = cv2.threshold(hematoxylin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            nucleus_mask = nucleus_mask > 0\n            \n        except:\n            # Method 2: Fallback to simple grayscale thresholding\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            \n            # Invert (nuclei are dark)\n            gray_inv = 255 - gray\n            \n            # Otsu thresholding\n            _, nucleus_mask = cv2.threshold(gray_inv, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            nucleus_mask = nucleus_mask > 0\n        \n        # Clean up mask\n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=15)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=15)\n        \n        # If no nuclei detected, return empty labeled image\n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n        \n        # Apply morphological operations to separate touching nuclei\n        nucleus_mask = erosion(nucleus_mask, disk(1))\n        nucleus_mask = dilation(nucleus_mask, disk(2))\n        \n        # Distance transform for watershed\n        distance = ndi.distance_transform_edt(nucleus_mask)\n        \n        # Find peaks (nucleus centers) with lower threshold for sensitivity\n        coords = peak_local_max(distance, min_distance=3, labels=nucleus_mask, \n                                exclude_border=False)\n        \n        if len(coords) == 0:\n            # No peaks found, just label connected components\n            labeled_nuclei = label(nucleus_mask)\n            return labeled_nuclei\n        \n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        \n        # Watershed segmentation\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n        \n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: OBJECT-LEVEL FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n    \"\"\"Extracts morphological and intensity features from individual nuclei\"\"\"\n    \n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        \"\"\"Extract features from a single nucleus region\"\"\"\n        features = {}\n        \n        # MORPHOLOGICAL FEATURES\n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        \n        # Shape descriptors\n        if region.perimeter > 0:\n            features['circularity'] = float(4 * np.pi * region.area / (region.perimeter ** 2))\n        else:\n            features['circularity'] = 0.0\n        \n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        \n        if region.minor_axis_length > 0:\n            features['aspect_ratio'] = float(region.major_axis_length / region.minor_axis_length)\n        else:\n            features['aspect_ratio'] = 0.0\n        \n        # Bounding box features\n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n        \n        # INTENSITY FEATURES (from grayscale)\n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        \n        return features\n\n\nclass SpatialFeatureExtractor:\n    \"\"\"Extracts spatial arrangement features from nuclei populations\"\"\"\n    \n    @staticmethod\n    def extract_spatial_features(regions):\n        \"\"\"Extract features describing spatial distribution of nuclei\"\"\"\n        features = {}\n        \n        if len(regions) == 0:\n            return features\n        \n        # Get centroids\n        centroids = np.array([region.centroid for region in regions])\n        \n        # DENSITY FEATURES\n        features['nucleus_count'] = len(regions)\n        \n        # Calculate area covered by all nuclei\n        total_area = sum([region.area for region in regions])\n        features['total_nucleus_area'] = float(total_area)\n        \n        # DISTANCE FEATURES (nearest neighbor analysis)\n        if len(centroids) > 1:\n            # Compute pairwise distances\n            distances = cdist(centroids, centroids)\n            # Set diagonal to inf to exclude self-distances\n            np.fill_diagonal(distances, np.inf)\n            \n            # Nearest neighbor distances\n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n            \n            # All pairwise distances statistics\n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            features['pairwise_distance_mean'] = float(np.mean(upper_triangle))\n            features['pairwise_distance_std'] = float(np.std(upper_triangle))\n            features['pairwise_distance_min'] = float(np.min(upper_triangle))\n            features['pairwise_distance_max'] = float(np.max(upper_triangle))\n            \n        # CLUSTERING MEASURES\n        if len(centroids) > 2:\n            # Variance in spatial distribution\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            \n            # Range (spatial extent)\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n        \n        return features\n\n\nclass GraphFeatureExtractor:\n    \"\"\"Extracts graph-based features from nucleus spatial relationships\"\"\"\n    \n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        \"\"\"Build graph connecting nearby nuclei\"\"\"\n        from scipy.spatial import Delaunay\n        \n        if len(centroids) < 3:\n            return None, None\n        \n        try:\n            tri = Delaunay(centroids)\n            \n            # Extract edges from triangulation\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i+1)%3]]))\n                    \n                    # Only keep edges shorter than threshold\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            \n            return tri, list(edges)\n        except:\n            return None, None\n    \n    @staticmethod\n    def extract_graph_features(regions):\n        \"\"\"Extract graph-based topological features\"\"\"\n        features = {}\n        \n        if len(regions) < 3:\n            return features\n        \n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n        \n        if edges is None or len(edges) == 0:\n            return features\n        \n        # Graph statistics\n        features['num_edges'] = len(edges)\n        features['edge_density'] = float(len(edges) / (len(regions) * (len(regions) - 1) / 2))\n        \n        # Degree distribution (how many connections each nucleus has)\n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n        \n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n        \n        # Edge length statistics\n        edge_lengths = [np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n        \n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n    \"\"\"Combines all object-level feature extractors\"\"\"\n    \n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n    \n    def extract_all_features(self, rgb_patch):\n        \"\"\"Extract all object-level features from a patch\"\"\"\n        all_features = {}\n        \n        # Segment nuclei\n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        \n        # Get region properties\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        \n        # Filter out very small regions (noise)\n        regions = [r for r in regions if r.area >= 10]\n        \n        # ALWAYS set nucleus_count and total_nucleus_area (even if 0)\n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum([r.area for r in regions]) if regions else 0.0)\n        \n        # Individual nucleus features (aggregate statistics)\n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except:\n                    continue\n            \n            # Aggregate nucleus features across all nuclei in patch\n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n        \n        # Spatial features (only if nuclei exist)\n        if len(regions) > 0:\n            spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n            all_features.update(spatial_features)\n        \n        # Graph features (only if enough nuclei)\n        if len(regions) >= 3:\n            graph_features = self.graph_extractor.extract_graph_features(regions)\n            all_features.update(graph_features)\n        \n        return all_features\n\n# ============================================================================\n# STEP 5: PATCH-LEVEL FEATURE EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(\n    wsi_path,\n    patch_size=256,\n    target_level=1,\n    tissue_threshold=0.3\n):\n    \"\"\"Extracts object-level features from all tissue patches in a WSI\"\"\"\n    slide = openslide.OpenSlide(wsi_path)\n    mask_level = slide.level_count - 1\n    tissue_mask = build_tissue_mask(slide, mask_level)\n    scale = slide.level_downsamples[mask_level]\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n    step = patch_size\n    \n    # Extract patches (NO progress bar for parallel processing)\n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio < tissue_threshold:\n                continue\n            \n            patch = slide.read_region(\n                (int(x * slide.level_downsamples[target_level]),\n                 int(y * slide.level_downsamples[target_level])),\n                target_level, (patch_size, patch_size)\n            )\n            patch = np.array(patch)[:, :, :3]\n            # Don't preprocess for object detection - keep original staining\n            \n            # Extract object-level features\n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception as e:\n                # Skip patches where segmentation fails\n                continue\n    \n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION (FIXED VERSION)\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    \"\"\"Converts patch-level features to slide-level features with proper NaN handling\"\"\"\n    if not patch_features_list:\n        return {}\n    \n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n    \n    slide_features = {}\n    slide_features['slide_name'] = slide_name\n    slide_features['num_patches'] = len(patch_features_list)\n    \n    # Aggregate each feature with proper NaN handling\n    for feature in feature_cols:\n        # CRITICAL FIX: Only aggregate features that have non-NaN values\n        feature_values = df[feature].dropna().values\n        \n        # Only compute statistics if we have at least one valid value\n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            # Feature never appeared in any patch - set to 0 (semantically correct)\n            slide_features[f'{feature}_mean'] = 0.0\n            slide_features[f'{feature}_std'] = 0.0\n            slide_features[f'{feature}_min'] = 0.0\n            slide_features[f'{feature}_max'] = 0.0\n            slide_features[f'{feature}_median'] = 0.0\n            slide_features[f'{feature}_q25'] = 0.0\n            slide_features[f'{feature}_q75'] = 0.0\n    \n    # Tissue coverage statistics\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n    \n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING FUNCTION\n# ============================================================================\n\ndef process_single_slide(args):\n    \"\"\"\n    Process one complete slide (designed for parallel execution)\n    This function will be called by multiple workers simultaneously\n    \"\"\"\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    \n    try:\n        # Extract PATCH-level object features\n        patch_features = extract_object_features_from_wsi(\n            slide_path,\n            patch_size=patch_size,\n            target_level=target_level,\n            tissue_threshold=tissue_threshold\n        )\n        \n        if patch_features:\n            # Aggregate to SLIDE-level\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, \n                f\"{dataset_name}_{slide_name}\"\n            )\n            \n            return {\n                'success': True,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': slide_features,\n                'num_patches': len(patch_features),\n                'error': None\n            }\n        else:\n            return {\n                'success': False,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': None,\n                'num_patches': 0,\n                'error': 'No tissue patches found'\n            }\n            \n    except Exception as e:\n        return {\n            'success': False,\n            'slide_path': slide_path,\n            'slide_name': slide_name,\n            'features': None,\n            'num_patches': 0,\n            'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: CHECKPOINT SYSTEM\n# ============================================================================\n\ndef load_checkpoint(dataset_name):\n    \"\"\"Load checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            return set(json.load(f))\n    return set()\n\ndef save_checkpoint(processed_slides, dataset_name):\n    \"\"\"Save checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    with open(checkpoint_file, 'w') as f:\n        json.dump(list(processed_slides), f)\n\n# ============================================================================\n# STEP 9: MAIN PROCESSING LOOP WITH PARALLEL BATCHES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING PARALLEL BATCH OBJECT-LEVEL FEATURE EXTRACTION\")\nprint(\"=\"*80)\n\n# Create output directory\noutput_path = f'/kaggle/working/object_features_{dataset_name}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Load checkpoint\nprocessed_slides = load_checkpoint(dataset_name)\nprint(f\"Already processed: {len(processed_slides)} slides\")\n\n# Find all slides\nslides = []\nfor root, dirs, files in os.walk(dataset_path):\n    slides.extend([os.path.join(root, f) for f in files \n                  if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))])\n\n# Filter out already processed slides\nslides_to_process = [s for s in slides if s not in processed_slides]\n\nprint(f\"Total slides in dataset: {len(slides)}\")\nprint(f\"Slides remaining to process: {len(slides_to_process)}\")\n\n# Storage for slide-level features\nall_slides_features = []\n\n# Process slides in batches with parallel workers\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"PROCESSING BATCH {batch_start//BATCH_SIZE + 1}\")\n    print(f\"Slides {batch_start + 1}-{batch_end} of {len(slides_to_process)}\")\n    print(f\"Processing {len(batch_slides)} slides with {PARALLEL_WORKERS} parallel workers\")\n    print(f\"{'='*80}\")\n    \n    # Prepare arguments for parallel processing\n    slide_args = [\n        (slide_path, dataset_name, 256, 1, 0.3)\n        for slide_path in batch_slides\n    ]\n    \n    # Process batch in parallel\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        # Submit all slides in batch\n        futures = {executor.submit(process_single_slide, args): args[0] \n                  for args in slide_args}\n        \n        # Collect results as they complete\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            \n            try:\n                result = future.result()\n                \n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    processed_slides.add(result['slide_path'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n                    \n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n    \n    # Save checkpoint after each batch\n    save_checkpoint(processed_slides, dataset_name)\n    \n    # Save temporary results\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides completed\")\n\n# ============================================================================\n# STEP 10: SAVE FINAL RESULTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING FINAL RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    # Convert to DataFrame\n    final_df = pd.DataFrame(all_slides_features)\n    \n    print(f\"\\nFinal dataset shape: {final_df.shape}\")\n    print(f\"  - Rows (slides): {final_df.shape[0]}\")\n    print(f\"  - Columns (features): {final_df.shape[1]}\")\n    \n    # DIAGNOSTIC: Check nucleus detection rates\n    print(\"\\n\" + \"=\"*80)\n    print(\"NUCLEUS DETECTION DIAGNOSTICS\")\n    print(\"=\"*80)\n    \n    # Check if nucleus_count column exists\n    nucleus_count_cols = [col for col in final_df.columns if 'nucleus_count' in col.lower()]\n    if nucleus_count_cols:\n        for col in nucleus_count_cols:\n            mean_count = final_df[col].mean()\n            print(f\"{col}: mean = {mean_count:.2f}\")\n            \n            # Count slides with zero nuclei\n            zero_count = (final_df[col] == 0).sum()\n            print(f\"  Slides with 0 nuclei: {zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n    \n    # Check NaN prevalence (should be ZERO or minimal with our fixes)\n    nan_counts = final_df.isna().sum()\n    cols_with_nans = nan_counts[nan_counts > 0]\n    if len(cols_with_nans) > 0:\n        print(f\"\\nColumns with NaN values: {len(cols_with_nans)}/{len(final_df.columns)}\")\n        print(f\"Most NaN values: {nan_counts.max()} ({100*nan_counts.max()/len(final_df):.1f}% of slides)\")\n        print(\"\\nTop 10 columns with NaNs:\")\n        print(nan_counts.nlargest(10))\n    else:\n        print(\"\\nâœ“ No NaN values found! All features properly computed.\")\n    \n    # Check for all-zero columns (features that never occurred)\n    zero_cols = (final_df == 0).all()\n    all_zero_cols = zero_cols[zero_cols].index.tolist()\n    if all_zero_cols:\n        print(f\"\\nColumns with all zeros: {len(all_zero_cols)}\")\n        print(\"(These features never occurred in any slide)\")\n        if len(all_zero_cols) <= 20:\n            print(f\"Zero columns: {all_zero_cols}\")\n    \n    print(\"=\"*80)\n    \n    # Save as CSV\n    csv_path = f'{output_path}/{dataset_name}_slide_object_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved CSV to: {csv_path}\")\n    \n    # Save as compressed numpy\n    npz_path = f'{output_path}/{dataset_name}_slide_object_features.npz'\n    np.savez_compressed(\n        npz_path,\n        slide_names=final_df['slide_name'].values,\n        features=final_df.drop('slide_name', axis=1).values,\n        feature_names=final_df.drop('slide_name', axis=1).columns.values\n    )\n    print(f\"âœ“ Saved NPZ to: {npz_path}\")\n    \n    # Show sample\n    print(\"\\n\" + \"=\"*80)\n    print(\"SAMPLE OUTPUT\")\n    print(\"=\"*80)\n    print(final_df.head())\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"OBJECT-LEVEL FEATURE EXTRACTION COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Total slides processed: {len(all_slides_features)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n    print(f\"Output directory: {output_path}\")\n    print(f\"Parallel workers used: {PARALLEL_WORKERS}\")\n    print(f\"Batch size: {BATCH_SIZE}\")\n    \n    # Feature summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"FEATURE CATEGORIES EXTRACTED:\")\n    print(\"=\"*80)\n    print(\"1. NUCLEUS MORPHOLOGY:\")\n    print(\"   - Area, perimeter, eccentricity, solidity, circularity\")\n    print(\"   - Major/minor axis lengths, aspect ratio\")\n    print(\"   - Bounding box dimensions\")\n    print(\"\\n2. NUCLEUS INTENSITY:\")\n    print(\"   - Mean, std, min, max, median\")\n    print(\"   - Range, skewness, kurtosis\")\n    print(\"\\n3. SPATIAL DISTRIBUTION:\")\n    print(\"   - Nucleus count and density\")\n    print(\"   - Nearest neighbor distances\")\n    print(\"   - Pairwise distance statistics\")\n    print(\"   - Centroid variance and range\")\n    print(\"\\n4. GRAPH TOPOLOGY:\")\n    print(\"   - Edge count and density\")\n    print(\"   - Degree distribution\")\n    print(\"   - Edge length statistics\")\nelse:\n    print(\"âš  No slides were successfully processed!\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"NEXT STEPS:\")\nprint(\"=\"*80)\nprint(\"1. Download the CSV file\")\nprint(\"2. Change the dataset name at the top of this code:\")\nprint(f'   dataset_to_process = \"saadinn/bracs-wsi-group-NEXT-DATASET\"')\nprint(\"3. Run again for the next dataset\")\nprint(\"4. Repeat for all 9 datasets\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-15T10:13:01.420728Z","iopub.execute_input":"2026-02-15T10:13:01.421313Z","execution_failed":"2026-02-15T18:04:20.529Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nBRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - PARALLEL BATCH MODE\n================================================================================\n\nDownloading dataset: saadinn/bracs-wsi-group-at-type-fea\nâœ“ Downloaded to: /kaggle/input/bracs-wsi-group-at-type-fea\nâœ“ Dataset name: bracs-wsi-group-at-type-fea\nâœ“ Parallel workers: 4\nâœ“ Batch size: 8\n\n================================================================================\nSTARTING PARALLEL BATCH OBJECT-LEVEL FEATURE EXTRACTION\n================================================================================\nAlready processed: 0 slides\nTotal slides in dataset: 41\nSlides remaining to process: 41\n\n================================================================================\nPROCESSING BATCH 1\nSlides 1-8 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1955.svs: 1686 patches\n  âœ“ BRACS_1319.svs: 3538 patches\n  âœ“ BRACS_1610.svs: 2999 patches\n  âœ“ BRACS_2007.svs: 1220 patches\n  âœ“ BRACS_300.svs: 1896 patches\n  âœ“ BRACS_1773.svs: 3447 patches\n  âœ“ BRACS_1239.svs: 6249 patches\n  âœ“ BRACS_1257.svs: 5965 patches\n\n  ðŸ’¾ Batch checkpoint: 8 slides completed\n\n================================================================================\nPROCESSING BATCH 2\nSlides 9-16 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1937.svs: 2457 patches\n  âœ“ BRACS_1968.svs: 2141 patches\n  âœ“ BRACS_1003693.svs: 3490 patches\n  âœ“ BRACS_1857.svs: 1711 patches\n  âœ“ BRACS_3266.svs: 724 patches\n  âœ“ BRACS_1865.svs: 4328 patches\n  âœ“ BRACS_1813.svs: 3797 patches\n  âœ“ BRACS_1838.svs: 3772 patches\n\n  ðŸ’¾ Batch checkpoint: 16 slides completed\n\n================================================================================\nPROCESSING BATCH 3\nSlides 17-24 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1506.svs: 2004 patches\n  âœ“ BRACS_1775.svs: 2824 patches\n  âœ“ BRACS_1777.svs: 4548 patches\n  âœ“ BRACS_1871.svs: 2254 patches\n  âœ“ BRACS_1858.svs: 5577 patches\n  âœ“ BRACS_1250.svs: 2888 patches\n  âœ“ BRACS_743.svs: 6235 patches\n  âœ“ BRACS_1916.svs: 2023 patches\n\n  ðŸ’¾ Batch checkpoint: 24 slides completed\n\n================================================================================\nPROCESSING BATCH 4\nSlides 25-32 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1941.svs: 1750 patches\n  âœ“ BRACS_1971.svs: 2425 patches\n  âœ“ BRACS_1788.svs: 1685 patches\n  âœ“ BRACS_1510.svs: 1679 patches\n  âœ“ BRACS_1954.svs: 1598 patches\n  âœ“ BRACS_1815.svs: 3231 patches\n  âœ“ BRACS_1926.svs: 3109 patches\n  âœ“ BRACS_1774.svs: 1340 patches\n\n  ðŸ’¾ Batch checkpoint: 32 slides completed\n\n================================================================================\nPROCESSING BATCH 5\nSlides 33-40 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":" # ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI HYBRID OBJECT-LEVEL FEATURES (PARALLEL BATCH)\n# ============================================================================\n\n# Import all required libraries\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects\nfrom skimage.measure import label, regionprops_table\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import pdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\nPARALLEL_WORKERS = 4  # Process 4 slides at once\nBATCH_SIZE = 8  # Process slides in batches\n\n# ============================================================================\n# STEP 1: CHOOSE WHICH DATASET TO PROCESS\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI HYBRID OBJECT-LEVEL FEATURE EXTRACTION - PARALLEL BATCH MODE\")\nprint(\"=\"*80)\n\n# SELECT ONE DATASET AT A TIME\ndataset_to_process = \"saadinn/bracs-wsi-group-at-type-fea\"  # â† CHANGE THIS FOR EACH RUN\n\nprint(f\"\\nDownloading dataset: {dataset_to_process}\")\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name: {dataset_name}\")\nprint(f\"âœ“ Parallel workers: {PARALLEL_WORKERS}\")\nprint(f\"âœ“ Batch size: {BATCH_SIZE}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION FUNCTIONS\n# ============================================================================\n\ndef build_tissue_mask(slide, level=4):\n    \"\"\"Creates binary mask identifying tissue regions at low resolution\"\"\"\n    img = np.array(slide.read_region((0, 0), level, slide.level_dimensions[level]))[:, :, :3]\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    mask = saturation > 0.05\n    mask = remove_small_objects(mask, min_size=500)\n    mask = remove_small_holes(mask, area_threshold=500)\n    return mask\n\ndef tissue_ratio(mask, x, y, patch_size, scale):\n    \"\"\"Calculates proportion of tissue in a patch location\"\"\"\n    xs = int(x / scale)\n    ys = int(y / scale)\n    ps = int(patch_size / scale)\n    patch_mask = mask[ys:ys+ps, xs:xs+ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return patch_mask.mean()\n\n# ============================================================================\n# STEP 3: COLOR-BASED NUCLEUS ENHANCEMENT\n# ============================================================================\n\nclass ColorEnhancedNucleusSegmenter:\n    \"\"\"Nucleus segmentation using color preprocessing + fast thresholding\"\"\"\n    \n    @staticmethod\n    def extract_nucleus_channel(rgb_patch):\n        \"\"\"\n        Extract nucleus-specific channel using multiple color space features\n        Combines the best of color preprocessing with fast computation\n        \"\"\"\n        # Method 1: Blue ratio (nuclei are blue/purple in H&E)\n        blue = rgb_patch[:, :, 2].astype(np.float32)\n        red = rgb_patch[:, :, 0].astype(np.float32)\n        green = rgb_patch[:, :, 1].astype(np.float32)\n        \n        # Blue dominance ratio (avoid division by zero)\n        blue_ratio = blue / (red + green + blue + 1e-10)\n        blue_ratio = (blue_ratio * 255).astype(np.uint8)\n        \n        # Method 2: HSV saturation (nuclei are saturated)\n        hsv = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2HSV)\n        saturation = hsv[:, :, 1]\n        \n        # Method 3: Grayscale (nuclei are dark)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        gray_inv = 255 - gray\n        \n        # Method 4: LAB color space (nuclei have specific B values)\n        lab = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2LAB)\n        b_channel = lab[:, :, 2]  # Blue-yellow axis\n        \n        # Combine channels with weighted sum (optimized weights for H&E)\n        combined = (\n            0.4 * blue_ratio.astype(np.float32) +\n            0.2 * saturation.astype(np.float32) +\n            0.3 * gray_inv.astype(np.float32) +\n            0.1 * b_channel.astype(np.float32)\n        )\n        \n        # Normalize to 0-255\n        combined = np.clip(combined, 0, 255).astype(np.uint8)\n        \n        return combined\n    \n    @staticmethod\n    def segment_nuclei_hybrid(rgb_patch):\n        \"\"\"\n        Hybrid segmentation: Color preprocessing + fast thresholding\n        Balances accuracy and speed\n        \"\"\"\n        # Extract enhanced nucleus channel\n        nucleus_channel = ColorEnhancedNucleusSegmenter.extract_nucleus_channel(rgb_patch)\n        \n        # Apply CLAHE (Contrast Limited Adaptive Histogram Equalization)\n        # This enhances local contrast - helps with varying staining intensity\n        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n        nucleus_channel = clahe.apply(nucleus_channel)\n        \n        # Adaptive thresholding on enhanced channel\n        binary = cv2.adaptiveThreshold(\n            nucleus_channel, 255,\n            cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n            cv2.THRESH_BINARY,\n            blockSize=15,\n            C=-3  # Negative C makes it more sensitive\n        )\n        \n        # Morphological operations to clean up\n        kernel_small = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (2, 2))\n        kernel_medium = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n        \n        # Remove small noise\n        binary = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel_small)\n        # Fill small holes\n        binary = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel_medium)\n        \n        # Remove very small objects (noise)\n        binary = remove_small_objects(binary > 0, min_size=15)\n        \n        # Label connected components\n        labeled = label(binary)\n        \n        return labeled\n\n# ============================================================================\n# STEP 4: FAST OBJECT-LEVEL FEATURE EXTRACTION WITH COLOR ENHANCEMENT\n# ============================================================================\n\nclass HybridObjectFeatureExtractor:\n    \"\"\"Optimized feature extraction with color-enhanced segmentation\"\"\"\n    \n    @staticmethod\n    def extract_hybrid_features(rgb_patch):\n        \"\"\"\n        Extract object-level features using color-enhanced segmentation\n        Returns aggregated statistics for speed\n        \"\"\"\n        features = {}\n        \n        # Segment nuclei using color-enhanced method\n        labeled = ColorEnhancedNucleusSegmenter.segment_nuclei_hybrid(rgb_patch)\n        \n        # Get grayscale for intensity measurements\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        \n        # Use regionprops_table for fast batch processing\n        props = regionprops_table(\n            labeled, \n            intensity_image=gray,\n            properties=[\n                'label', 'area', 'perimeter', 'eccentricity', \n                'solidity', 'extent', 'major_axis_length', \n                'minor_axis_length', 'centroid',\n                'intensity_mean', 'intensity_min', 'intensity_max'\n            ]\n        )\n        \n        # Convert to DataFrame for easy aggregation\n        df = pd.DataFrame(props)\n        \n        # Filter out noise (very small objects)\n        df = df[df['area'] >= 10]\n        \n        if len(df) == 0:\n            # No nuclei detected - provide defaults for ALL features\n            features['nucleus_count'] = 0\n            features['total_nucleus_area'] = 0.0\n            \n            # Morphology defaults\n            for col in ['area', 'perimeter', 'eccentricity', 'solidity', \n                        'extent', 'major_axis_length', 'minor_axis_length']:\n                features[f'{col}_mean'] = 0.0\n                features[f'{col}_std'] = 0.0\n                features[f'{col}_min'] = 0.0\n                features[f'{col}_max'] = 0.0\n            \n            # Shape descriptor defaults\n            for col in ['circularity', 'aspect_ratio']:\n                features[f'{col}_mean'] = 0.0\n                features[f'{col}_std'] = 0.0\n            \n            # Intensity defaults\n            for col in ['intensity_mean', 'intensity_min', 'intensity_max']:\n                features[f'{col}_mean'] = 0.0\n                features[f'{col}_std'] = 0.0\n            \n            # Spatial defaults\n            features['nn_distance_mean'] = 0.0\n            features['pairwise_distance_mean'] = 0.0\n            features['pairwise_distance_std'] = 0.0\n            features['pairwise_distance_min'] = 0.0\n            features['pairwise_distance_max'] = 0.0\n            features['centroid_x_variance'] = 0.0\n            features['centroid_y_variance'] = 0.0\n            features['centroid_x_range'] = 0.0\n            features['centroid_y_range'] = 0.0\n            \n            # Density defaults\n            patch_area = rgb_patch.shape[0] * rgb_patch.shape[1]\n            features['nucleus_density'] = 0.0\n            features['nucleus_area_fraction'] = 0.0\n            \n            return features\n        \n        # BASIC COUNTS\n        features['nucleus_count'] = len(df)\n        features['total_nucleus_area'] = float(df['area'].sum())\n        \n        # MORPHOLOGY STATISTICS (vectorized - very fast)\n        for col in ['area', 'perimeter', 'eccentricity', 'solidity', \n                    'extent', 'major_axis_length', 'minor_axis_length']:\n            features[f'{col}_mean'] = float(df[col].mean())\n            features[f'{col}_std'] = float(df[col].std())\n            features[f'{col}_min'] = float(df[col].min())\n            features[f'{col}_max'] = float(df[col].max())\n        \n        # SHAPE DESCRIPTORS\n        df['circularity'] = 4 * np.pi * df['area'] / (df['perimeter'] ** 2 + 1e-10)\n        df['aspect_ratio'] = df['major_axis_length'] / (df['minor_axis_length'] + 1e-10)\n        \n        for col in ['circularity', 'aspect_ratio']:\n            features[f'{col}_mean'] = float(df[col].mean())\n            features[f'{col}_std'] = float(df[col].std())\n        \n        # INTENSITY STATISTICS\n        for col in ['intensity_mean', 'intensity_min', 'intensity_max']:\n            features[f'{col}_mean'] = float(df[col].mean())\n            features[f'{col}_std'] = float(df[col].std())\n        \n        # SPATIAL FEATURES (if we have multiple nuclei)\n        if len(df) > 1:\n            # Extract centroids\n            centroids = df[['centroid-0', 'centroid-1']].values\n            \n            # Compute ALL pairwise distances at once (vectorized)\n            pairwise_dists = pdist(centroids)\n            \n            if len(pairwise_dists) > 0:\n                features['nn_distance_mean'] = float(pairwise_dists.min())  # Approximate NN\n                features['pairwise_distance_mean'] = float(pairwise_dists.mean())\n                features['pairwise_distance_std'] = float(pairwise_dists.std())\n                features['pairwise_distance_min'] = float(pairwise_dists.min())\n                features['pairwise_distance_max'] = float(pairwise_dists.max())\n            \n            # Spatial spread\n            features['centroid_x_variance'] = float(centroids[:, 1].var())\n            features['centroid_y_variance'] = float(centroids[:, 0].var())\n            features['centroid_x_range'] = float(centroids[:, 1].max() - centroids[:, 1].min())\n            features['centroid_y_range'] = float(centroids[:, 0].max() - centroids[:, 0].min())\n        else:\n            # Only 1 or 0 nuclei - provide defaults for spatial features\n            features['nn_distance_mean'] = 0.0\n            features['pairwise_distance_mean'] = 0.0\n            features['pairwise_distance_std'] = 0.0\n            features['pairwise_distance_min'] = 0.0\n            features['pairwise_distance_max'] = 0.0\n            features['centroid_x_variance'] = 0.0\n            features['centroid_y_variance'] = 0.0\n            features['centroid_x_range'] = 0.0\n            features['centroid_y_range'] = 0.0\n        \n        # DENSITY FEATURES\n        patch_area = rgb_patch.shape[0] * rgb_patch.shape[1]\n        features['nucleus_density'] = features['nucleus_count'] / patch_area\n        features['nucleus_area_fraction'] = features['total_nucleus_area'] / patch_area\n        \n        return features\n\n# ============================================================================\n# STEP 5: PATCH-LEVEL FEATURE EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(\n    wsi_path,\n    patch_size=256,\n    target_level=1,\n    tissue_threshold=0.3\n):\n    \"\"\"Extracts object-level features from all tissue patches in a WSI\"\"\"\n    slide = openslide.OpenSlide(wsi_path)\n    mask_level = slide.level_count - 1\n    tissue_mask = build_tissue_mask(slide, mask_level)\n    scale = slide.level_downsamples[mask_level]\n    extractor = HybridObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n    step = patch_size\n    \n    # Extract patches (NO progress bar for parallel processing)\n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio < tissue_threshold:\n                continue\n            \n            patch = slide.read_region(\n                (int(x * slide.level_downsamples[target_level]),\n                 int(y * slide.level_downsamples[target_level])),\n                target_level, (patch_size, patch_size)\n            )\n            patch = np.array(patch)[:, :, :3]\n            \n            # Extract object-level features (hybrid method with color preprocessing)\n            try:\n                patch_features = extractor.extract_hybrid_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception as e:\n                # If extraction fails, skip this patch\n                continue\n    \n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    \"\"\"Converts patch-level features to slide-level features\"\"\"\n    if not patch_features_list:\n        return {}\n    \n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n    \n    slide_features = {}\n    slide_features['slide_name'] = slide_name\n    slide_features['num_patches'] = len(patch_features_list)\n    \n    # Aggregate each feature\n    for feature in feature_cols:\n        feature_values = df[feature].values\n        slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n        slide_features[f'{feature}_std'] = float(np.std(feature_values))\n        slide_features[f'{feature}_min'] = float(np.min(feature_values))\n        slide_features[f'{feature}_max'] = float(np.max(feature_values))\n        slide_features[f'{feature}_median'] = float(np.median(feature_values))\n        slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n        slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n    \n    # Tissue coverage statistics\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n    \n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING FUNCTION\n# ============================================================================\n\ndef process_single_slide(args):\n    \"\"\"Process one complete slide (designed for parallel execution)\"\"\"\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    \n    try:\n        # Extract PATCH-level object features\n        patch_features = extract_object_features_from_wsi(\n            slide_path,\n            patch_size=patch_size,\n            target_level=target_level,\n            tissue_threshold=tissue_threshold\n        )\n        \n        if patch_features:\n            # Aggregate to SLIDE-level\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, \n                f\"{dataset_name}_{slide_name}\"\n            )\n            \n            return {\n                'success': True,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': slide_features,\n                'num_patches': len(patch_features),\n                'error': None\n            }\n        else:\n            return {\n                'success': False,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': None,\n                'num_patches': 0,\n                'error': 'No tissue patches found'\n            }\n            \n    except Exception as e:\n        return {\n            'success': False,\n            'slide_path': slide_path,\n            'slide_name': slide_name,\n            'features': None,\n            'num_patches': 0,\n            'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: CHECKPOINT SYSTEM\n# ============================================================================\n\ndef load_checkpoint(dataset_name):\n    \"\"\"Load checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            return set(json.load(f))\n    return set()\n\ndef save_checkpoint(processed_slides, dataset_name):\n    \"\"\"Save checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    with open(checkpoint_file, 'w') as f:\n        json.dump(list(processed_slides), f)\n\n# ============================================================================\n# STEP 9: MAIN PROCESSING LOOP WITH PARALLEL BATCHES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING PARALLEL BATCH HYBRID OBJECT-LEVEL FEATURE EXTRACTION\")\nprint(\"=\"*80)\n\n# Create output directory\noutput_path = f'/kaggle/working/object_features_{dataset_name}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Load checkpoint\nprocessed_slides = load_checkpoint(dataset_name)\nprint(f\"Already processed: {len(processed_slides)} slides\")\n\n# Find all slides\nslides = []\nfor root, dirs, files in os.walk(dataset_path):\n    slides.extend([os.path.join(root, f) for f in files \n                  if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))])\n\n# Filter out already processed slides\nslides_to_process = [s for s in slides if s not in processed_slides]\n\nprint(f\"Total slides in dataset: {len(slides)}\")\nprint(f\"Slides remaining to process: {len(slides_to_process)}\")\n\n# Storage for slide-level features\nall_slides_features = []\n\n# Process slides in batches with parallel workers\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"PROCESSING BATCH {batch_start//BATCH_SIZE + 1}\")\n    print(f\"Slides {batch_start + 1}-{batch_end} of {len(slides_to_process)}\")\n    print(f\"Processing {len(batch_slides)} slides with {PARALLEL_WORKERS} parallel workers\")\n    print(f\"{'='*80}\")\n    \n    # Prepare arguments for parallel processing\n    slide_args = [\n        (slide_path, dataset_name, 256, 1, 0.3)\n        for slide_path in batch_slides\n    ]\n    \n    # Process batch in parallel\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        # Submit all slides in batch\n        futures = {executor.submit(process_single_slide, args): args[0] \n                  for args in slide_args}\n        \n        # Collect results as they complete\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            \n            try:\n                result = future.result()\n                \n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    processed_slides.add(result['slide_path'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n                    \n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n    \n    # Save checkpoint after each batch\n    save_checkpoint(processed_slides, dataset_name)\n    \n    # Save temporary results\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides completed\")\n\n# ============================================================================\n# STEP 10: SAVE FINAL RESULTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING FINAL RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    # Convert to DataFrame\n    final_df = pd.DataFrame(all_slides_features)\n    \n    print(f\"\\nFinal dataset shape: {final_df.shape}\")\n    print(f\"  - Rows (slides): {final_df.shape[0]}\")\n    print(f\"  - Columns (features): {final_df.shape[1]}\")\n    \n    # DIAGNOSTIC: Check nucleus detection rates\n    print(\"\\n\" + \"=\"*80)\n    print(\"NUCLEUS DETECTION DIAGNOSTICS\")\n    print(\"=\"*80)\n    \n    # Check if nucleus_count column exists\n    nucleus_count_cols = [col for col in final_df.columns if 'nucleus_count' in col.lower()]\n    if nucleus_count_cols:\n        for col in nucleus_count_cols:\n            mean_count = final_df[col].mean()\n            print(f\"{col}: mean = {mean_count:.2f}\")\n            \n            # Count slides with zero nuclei\n            zero_count = (final_df[col] == 0).sum()\n            print(f\"  Slides with 0 nuclei: {zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n    \n    # Check NaN prevalence\n    nan_counts = final_df.isna().sum()\n    cols_with_nans = nan_counts[nan_counts > 0]\n    if len(cols_with_nans) > 0:\n        print(f\"\\nColumns with NaN values: {len(cols_with_nans)}/{len(final_df.columns)}\")\n        print(f\"Most NaN values: {nan_counts.max()} ({100*nan_counts.max()/len(final_df):.1f}% of slides)\")\n    else:\n        print(\"\\nâœ“ No NaN values found!\")\n    \n    print(\"=\"*80)\n    \n    # Save as CSV\n    csv_path = f'{output_path}/{dataset_name}_slide_object_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved CSV to: {csv_path}\")\n    \n    # Save as compressed numpy\n    npz_path = f'{output_path}/{dataset_name}_slide_object_features.npz'\n    np.savez_compressed(\n        npz_path,\n        slide_names=final_df['slide_name'].values,\n        features=final_df.drop('slide_name', axis=1).values,\n        feature_names=final_df.drop('slide_name', axis=1).columns.values\n    )\n    print(f\"âœ“ Saved NPZ to: {npz_path}\")\n    \n    # Show sample\n    print(\"\\n\" + \"=\"*80)\n    print(\"SAMPLE OUTPUT\")\n    print(\"=\"*80)\n    print(final_df.head())\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"HYBRID OBJECT-LEVEL FEATURE EXTRACTION COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Total slides processed: {len(all_slides_features)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n    print(f\"Output directory: {output_path}\")\n    print(f\"Parallel workers used: {PARALLEL_WORKERS}\")\n    print(f\"Batch size: {BATCH_SIZE}\")\n    \n    # Feature summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"HYBRID APPROACH - BEST OF BOTH WORLDS:\")\n    print(\"=\"*80)\n    print(\"âœ“ Color preprocessing (blue ratio, HSV, LAB, grayscale)\")\n    print(\"âœ“ CLAHE enhancement (local contrast)\")\n    print(\"âœ“ Fast adaptive thresholding (no watershed)\")\n    print(\"âœ“ Vectorized feature extraction (regionprops_table)\")\n    print(\"âœ“ Complete default values (no NaN)\")\n    print(\"\\nFEATURE CATEGORIES:\")\n    print(\"1. Nucleus morphology (area, perimeter, shape)\")\n    print(\"2. Nucleus intensity statistics\")\n    print(\"3. Spatial distribution (distances, density)\")\n    print(\"4. Density metrics (count, area fraction)\")\nelse:\n    print(\"âš  No slides were successfully processed!\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"NEXT STEPS:\")\nprint(\"=\"*80)\nprint(\"1. Download the CSV file\")\nprint(\"2. Change the dataset name at the top of this code:\")\nprint(f'   dataset_to_process = \"saadinn/bracs-wsi-group-NEXT-DATASET\"')\nprint(\"3. Run again for the next dataset\")\nprint(\"4. Repeat for all 9 datasets\")\nprint(\"=\"*80)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-14T21:24:27.720241Z","iopub.execute_input":"2026-02-14T21:24:27.720532Z","iopub.status.idle":"2026-02-14T22:38:33.637885Z","shell.execute_reply.started":"2026-02-14T21:24:27.720505Z","shell.execute_reply":"2026-02-14T22:38:33.636561Z"}},"outputs":[{"name":"stdout","text":"================================================================================\nBRACS WSI HYBRID OBJECT-LEVEL FEATURE EXTRACTION - PARALLEL BATCH MODE\n================================================================================\n\nDownloading dataset: saadinn/bracs-wsi-group-at-type-fea\nâœ“ Downloaded to: /kaggle/input/bracs-wsi-group-at-type-fea\nâœ“ Dataset name: bracs-wsi-group-at-type-fea\nâœ“ Parallel workers: 4\nâœ“ Batch size: 8\n\n================================================================================\nSTARTING PARALLEL BATCH HYBRID OBJECT-LEVEL FEATURE EXTRACTION\n================================================================================\nAlready processed: 0 slides\nTotal slides in dataset: 41\nSlides remaining to process: 41\n\n================================================================================\nPROCESSING BATCH 1\nSlides 1-8 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1955.svs: 1686 patches\n  âœ“ BRACS_1610.svs: 2999 patches\n  âœ“ BRACS_1319.svs: 3538 patches\n  âœ“ BRACS_2007.svs: 1220 patches\n  âœ“ BRACS_300.svs: 1896 patches\n  âœ“ BRACS_1773.svs: 3447 patches\n  âœ“ BRACS_1239.svs: 6249 patches\n  âœ“ BRACS_1257.svs: 5965 patches\n\n  ðŸ’¾ Batch checkpoint: 8 slides completed\n\n================================================================================\nPROCESSING BATCH 2\nSlides 9-16 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1937.svs: 2457 patches\n  âœ“ BRACS_1968.svs: 2141 patches\n  âœ“ BRACS_1003693.svs: 3490 patches\n  âœ“ BRACS_1857.svs: 1711 patches\n  âœ“ BRACS_3266.svs: 724 patches\n  âœ“ BRACS_1813.svs: 3797 patches\n  âœ“ BRACS_1865.svs: 4328 patches\n  âœ“ BRACS_1838.svs: 3772 patches\n\n  ðŸ’¾ Batch checkpoint: 16 slides completed\n\n================================================================================\nPROCESSING BATCH 3\nSlides 17-24 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1506.svs: 2004 patches\n  âœ“ BRACS_1775.svs: 2824 patches\n  âœ“ BRACS_1777.svs: 4548 patches\n  âœ“ BRACS_1250.svs: 2888 patches\n  âœ“ BRACS_1858.svs: 5577 patches\n  âœ“ BRACS_1871.svs: 2254 patches\n  âœ“ BRACS_1916.svs: 2023 patches\n  âœ“ BRACS_743.svs: 6235 patches\n\n  ðŸ’¾ Batch checkpoint: 24 slides completed\n\n================================================================================\nPROCESSING BATCH 4\nSlides 25-32 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1788.svs: 1685 patches\n  âœ“ BRACS_1941.svs: 1750 patches\n  âœ“ BRACS_1971.svs: 2425 patches\n  âœ“ BRACS_1954.svs: 1598 patches\n  âœ“ BRACS_1815.svs: 3231 patches\n  âœ“ BRACS_1510.svs: 1679 patches\n  âœ“ BRACS_1926.svs: 3109 patches\n  âœ“ BRACS_1774.svs: 1340 patches\n\n  ðŸ’¾ Batch checkpoint: 32 slides completed\n\n================================================================================\nPROCESSING BATCH 5\nSlides 33-40 of 41\nProcessing 8 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_3285.svs: 196 patches\n  âœ“ BRACS_1886.svs: 1173 patches\n  âœ“ BRACS_1778.svs: 1737 patches\n  âœ“ BRACS_1943.svs: 1780 patches\n  âœ“ BRACS_1799.svs: 2238 patches\n  âœ“ BRACS_1944.svs: 1085 patches\n  âœ“ BRACS_1936.svs: 2642 patches\n  âœ“ BRACS_1814.svs: 4049 patches\n\n  ðŸ’¾ Batch checkpoint: 40 slides completed\n\n================================================================================\nPROCESSING BATCH 6\nSlides 41-41 of 41\nProcessing 1 slides with 4 parallel workers\n================================================================================\n  âœ“ BRACS_1975.svs: 1987 patches\n\n  ðŸ’¾ Batch checkpoint: 41 slides completed\n\n================================================================================\nSAVING FINAL RESULTS\n================================================================================\n\nFinal dataset shape: (41, 361)\n  - Rows (slides): 41\n  - Columns (features): 361\n\n================================================================================\nNUCLEUS DETECTION DIAGNOSTICS\n================================================================================\nnucleus_count_mean: mean = 116.40\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_std: mean = 47.34\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_min: mean = 2.80\n  Slides with 0 nuclei: 7/41 (17.1%)\nnucleus_count_max: mean = 280.98\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_median: mean = 113.90\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_q25: mean = 83.63\n  Slides with 0 nuclei: 0/41 (0.0%)\nnucleus_count_q75: mean = 147.24\n  Slides with 0 nuclei: 0/41 (0.0%)\n\nColumns with NaN values: 84/361\nMost NaN values: 13 (31.7% of slides)\n================================================================================\n\nâœ“ Saved CSV to: /kaggle/working/object_features_bracs-wsi-group-at-type-fea//bracs-wsi-group-at-type-fea_slide_object_features.csv\nâœ“ Saved NPZ to: /kaggle/working/object_features_bracs-wsi-group-at-type-fea//bracs-wsi-group-at-type-fea_slide_object_features.npz\n\n================================================================================\nSAMPLE OUTPUT\n================================================================================\n                                   slide_name  num_patches  \\\n0  bracs-wsi-group-at-type-fea_BRACS_1955.svs         1686   \n1  bracs-wsi-group-at-type-fea_BRACS_1610.svs         2999   \n2  bracs-wsi-group-at-type-fea_BRACS_1319.svs         3538   \n3  bracs-wsi-group-at-type-fea_BRACS_2007.svs         1220   \n4   bracs-wsi-group-at-type-fea_BRACS_300.svs         1896   \n\n   nucleus_count_mean  nucleus_count_std  nucleus_count_min  \\\n0          111.743772          51.211337                0.0   \n1          203.428476          50.750238                1.0   \n2          157.636518          61.689407                4.0   \n3          113.990164          78.430338                0.0   \n4          110.827532          41.551482                7.0   \n\n   nucleus_count_max  nucleus_count_median  nucleus_count_q25  \\\n0              324.0                 109.0               76.0   \n1              294.0                 217.0              181.0   \n2              300.0                 167.0              113.0   \n3              285.0                 113.0               49.0   \n4              271.0                 107.0               81.0   \n\n   nucleus_count_q75  total_nucleus_area_mean  ...  nucleus_density_q75  \\\n0             143.00             18251.297746  ...             0.002182   \n1             238.00             13988.748916  ...             0.003632   \n2             204.00             18661.892877  ...             0.003113   \n3             175.25             14042.578689  ...             0.002674   \n4             138.00             23109.669304  ...             0.002106   \n\n   nucleus_area_fraction_mean  nucleus_area_fraction_std  \\\n0                    0.278493                   0.096349   \n1                    0.213451                   0.067718   \n2                    0.284758                   0.080067   \n3                    0.214273                   0.129311   \n4                    0.352626                   0.073883   \n\n   nucleus_area_fraction_min  nucleus_area_fraction_max  \\\n0                   0.000000                   0.451126   \n1                   0.001205                   0.442719   \n2                   0.002975                   0.446518   \n3                   0.000000                   0.473312   \n4                   0.005371                   0.472412   \n\n   nucleus_area_fraction_median  nucleus_area_fraction_q25  \\\n0                      0.296623                   0.206280   \n1                      0.213547                   0.168571   \n2                      0.298653                   0.238613   \n3                      0.246552                   0.123856   \n4                      0.374115                   0.325024   \n\n   nucleus_area_fraction_q75  tissue_ratio_mean  tissue_ratio_std  \n0                   0.360035           0.951496          0.147781  \n1                   0.262306           0.977511          0.101101  \n2                   0.346878           0.960510          0.130243  \n3                   0.313980           0.945173          0.154304  \n4                   0.400677           0.985835          0.079484  \n\n[5 rows x 361 columns]\n\n================================================================================\nHYBRID OBJECT-LEVEL FEATURE EXTRACTION COMPLETE!\n================================================================================\nDataset: bracs-wsi-group-at-type-fea\nTotal slides processed: 41\nFeatures per slide: 361\nOutput directory: /kaggle/working/object_features_bracs-wsi-group-at-type-fea/\nParallel workers used: 4\nBatch size: 8\n\n================================================================================\nHYBRID APPROACH - BEST OF BOTH WORLDS:\n================================================================================\nâœ“ Color preprocessing (blue ratio, HSV, LAB, grayscale)\nâœ“ CLAHE enhancement (local contrast)\nâœ“ Fast adaptive thresholding (no watershed)\nâœ“ Vectorized feature extraction (regionprops_table)\nâœ“ Complete default values (no NaN)\n\nFEATURE CATEGORIES:\n1. Nucleus morphology (area, perimeter, shape)\n2. Nucleus intensity statistics\n3. Spatial distribution (distances, density)\n4. Density metrics (count, area fraction)\n\n================================================================================\nNEXT STEPS:\n================================================================================\n1. Download the CSV file\n2. Change the dataset name at the top of this code:\n   dataset_to_process = \"saadinn/bracs-wsi-group-NEXT-DATASET\"\n3. Run again for the next dataset\n4. Repeat for all 9 datasets\n================================================================================\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (PARALLEL BATCH)\n# ============================================================================\n\n# Import all required libraries\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, erosion, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\n# Number of slides to process in parallel (adjust based on Kaggle performance)\nPARALLEL_WORKERS = 4  # Kaggle has 4 CPU cores - process 4 slides at once\nBATCH_SIZE = 8  # Process slides in batches (adjust if memory issues)\n\n# ============================================================================\n# STEP 1: CHOOSE WHICH DATASET TO PROCESS\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - PARALLEL BATCH MODE\")\nprint(\"=\"*80)\n\n# SELECT ONE DATASET AT A TIME\ndataset_to_process = \"saadinn/bracs-wsi-group-at-type-fea\"  # â† CHANGE THIS FOR EACH RUN\n\nprint(f\"\\nDownloading dataset: {dataset_to_process}\")\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name: {dataset_name}\")\nprint(f\"âœ“ Parallel workers: {PARALLEL_WORKERS}\")\nprint(f\"âœ“ Batch size: {BATCH_SIZE}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION FUNCTIONS\n# ============================================================================\n\ndef build_tissue_mask(slide, level=4):\n    \"\"\"Creates binary mask identifying tissue regions at low resolution\"\"\"\n    img = np.array(slide.read_region((0, 0), level, slide.level_dimensions[level]))[:, :, :3]\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    mask = saturation > 0.05\n    mask = remove_small_objects(mask, min_size=500)\n    mask = remove_small_holes(mask, area_threshold=500)\n    return mask\n\ndef tissue_ratio(mask, x, y, patch_size, scale):\n    \"\"\"Calculates proportion of tissue in a patch location\"\"\"\n    xs = int(x / scale)\n    ys = int(y / scale)\n    ps = int(patch_size / scale)\n    patch_mask = mask[ys:ys+ps, xs:xs+ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return patch_mask.mean()\n\ndef preprocess_patch(patch):\n    \"\"\"Normalizes staining variations using histogram equalization\"\"\"\n    patch = cv2.cvtColor(patch, cv2.COLOR_RGB2LAB)\n    patch[:, :, 0] = cv2.equalizeHist(patch[:, :, 0])\n    patch = cv2.cvtColor(patch, cv2.COLOR_LAB2RGB)\n    return patch\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n    \"\"\"Segments nuclei from H&E stained histopathology images\"\"\"\n    \n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        \"\"\"\n        Segments nuclei using color deconvolution and watershed\n        Returns labeled image where each nucleus has unique ID\n        \"\"\"\n        # Convert to grayscale for processing\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        \n        # Hematoxylin channel extraction (approximation)\n        # In H&E, nuclei are stained by hematoxylin (blue/purple)\n        hsv = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2HSV)\n        \n        # Create binary mask for dark purple/blue nuclei\n        # Method 1: Threshold on blue channel and intensity\n        blue_channel = rgb_patch[:, :, 2]\n        red_channel = rgb_patch[:, :, 0]\n        green_channel = rgb_patch[:, :, 1]\n        \n        # Nuclei are typically blue dominant and dark\n        nucleus_mask = (blue_channel > red_channel) & (blue_channel > green_channel)\n        nucleus_mask = nucleus_mask & (gray < 200)  # Dark regions\n        \n        # Clean up mask\n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=20)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=20)\n        \n        # Apply morphological operations to separate touching nuclei\n        nucleus_mask = erosion(nucleus_mask, disk(1))\n        nucleus_mask = dilation(nucleus_mask, disk(1))\n        \n        # Distance transform for watershed\n        distance = ndi.distance_transform_edt(nucleus_mask)\n        \n        # Find peaks (nucleus centers)\n        coords = peak_local_max(distance, min_distance=5, labels=nucleus_mask)\n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        \n        # Watershed segmentation\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n        \n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: OBJECT-LEVEL FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n    \"\"\"Extracts morphological and intensity features from individual nuclei\"\"\"\n    \n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        \"\"\"Extract features from a single nucleus region\"\"\"\n        features = {}\n        \n        # MORPHOLOGICAL FEATURES\n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        \n        # Shape descriptors\n        if region.perimeter > 0:\n            features['circularity'] = float(4 * np.pi * region.area / (region.perimeter ** 2))\n        else:\n            features['circularity'] = 0.0\n        \n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        \n        if region.minor_axis_length > 0:\n            features['aspect_ratio'] = float(region.major_axis_length / region.minor_axis_length)\n        else:\n            features['aspect_ratio'] = 0.0\n        \n        # Bounding box features\n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n        \n        # INTENSITY FEATURES (from grayscale)\n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        \n        return features\n\n\nclass SpatialFeatureExtractor:\n    \"\"\"Extracts spatial arrangement features from nuclei populations\"\"\"\n    \n    @staticmethod\n    def extract_spatial_features(regions):\n        \"\"\"Extract features describing spatial distribution of nuclei\"\"\"\n        features = {}\n        \n        if len(regions) == 0:\n            return features\n        \n        # Get centroids\n        centroids = np.array([region.centroid for region in regions])\n        \n        # DENSITY FEATURES\n        features['nucleus_count'] = len(regions)\n        \n        # Calculate area covered by all nuclei\n        total_area = sum([region.area for region in regions])\n        features['total_nucleus_area'] = float(total_area)\n        \n        # DISTANCE FEATURES (nearest neighbor analysis)\n        if len(centroids) > 1:\n            # Compute pairwise distances\n            distances = cdist(centroids, centroids)\n            # Set diagonal to inf to exclude self-distances\n            np.fill_diagonal(distances, np.inf)\n            \n            # Nearest neighbor distances\n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n            \n            # All pairwise distances statistics\n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            features['pairwise_distance_mean'] = float(np.mean(upper_triangle))\n            features['pairwise_distance_std'] = float(np.std(upper_triangle))\n            \n        # CLUSTERING MEASURES\n        if len(centroids) > 2:\n            # Variance in spatial distribution\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            \n        return features\n\n\nclass GraphFeatureExtractor:\n    \"\"\"Extracts graph-based features from nucleus spatial relationships\"\"\"\n    \n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        \"\"\"Build graph connecting nearby nuclei\"\"\"\n        from scipy.spatial import Delaunay\n        \n        if len(centroids) < 3:\n            return None, None\n        \n        try:\n            tri = Delaunay(centroids)\n            \n            # Extract edges from triangulation\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i+1)%3]]))\n                    \n                    # Only keep edges shorter than threshold\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            \n            return tri, list(edges)\n        except:\n            return None, None\n    \n    @staticmethod\n    def extract_graph_features(regions):\n        \"\"\"Extract graph-based topological features\"\"\"\n        features = {}\n        \n        if len(regions) < 3:\n            return features\n        \n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n        \n        if edges is None:\n            return features\n        \n        # Graph statistics\n        features['num_edges'] = len(edges)\n        features['edge_density'] = float(len(edges) / (len(regions) * (len(regions) - 1) / 2))\n        \n        # Degree distribution (how many connections each nucleus has)\n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n        \n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n        \n        # Edge length statistics\n        edge_lengths = [np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        \n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n    \"\"\"Combines all object-level feature extractors\"\"\"\n    \n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n    \n    def extract_all_features(self, rgb_patch):\n        \"\"\"Extract all object-level features from a patch\"\"\"\n        all_features = {}\n        \n        # Segment nuclei\n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        \n        # Get region properties\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        \n        # Individual nucleus features (aggregate statistics)\n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                nucleus_features_list.append(nuc_feat)\n            \n            # Aggregate nucleus features across all nuclei in patch\n            df = pd.DataFrame(nucleus_features_list)\n            for col in df.columns:\n                all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                all_features[f'nucleus_{col}_median'] = float(df[col].median())\n        \n        # Spatial features\n        spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n        all_features.update(spatial_features)\n        \n        # Graph features\n        graph_features = self.graph_extractor.extract_graph_features(regions)\n        all_features.update(graph_features)\n        \n        return all_features\n\n# ============================================================================\n# STEP 5: PATCH-LEVEL FEATURE EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(\n    wsi_path,\n    patch_size=256,\n    target_level=1,\n    tissue_threshold=0.3\n):\n    \"\"\"Extracts object-level features from all tissue patches in a WSI\"\"\"\n    slide = openslide.OpenSlide(wsi_path)\n    mask_level = slide.level_count - 1\n    tissue_mask = build_tissue_mask(slide, mask_level)\n    scale = slide.level_downsamples[mask_level]\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n    step = patch_size\n    \n    # Extract patches (NO progress bar for parallel processing)\n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio < tissue_threshold:\n                continue\n            \n            patch = slide.read_region(\n                (int(x * slide.level_downsamples[target_level]),\n                 int(y * slide.level_downsamples[target_level])),\n                target_level, (patch_size, patch_size)\n            )\n            patch = np.array(patch)[:, :, :3]\n            patch = preprocess_patch(patch)\n            \n            # Extract object-level features\n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception as e:\n                # Skip patches where segmentation fails\n                continue\n    \n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    \"\"\"Converts patch-level features to slide-level features\"\"\"\n    if not patch_features_list:\n        return {}\n    \n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n    \n    slide_features = {}\n    slide_features['slide_name'] = slide_name\n    slide_features['num_patches'] = len(patch_features_list)\n    \n    # Aggregate each feature\n    for feature in feature_cols:\n        feature_values = df[feature].values\n        slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n        slide_features[f'{feature}_std'] = float(np.std(feature_values))\n        slide_features[f'{feature}_min'] = float(np.min(feature_values))\n        slide_features[f'{feature}_max'] = float(np.max(feature_values))\n        slide_features[f'{feature}_median'] = float(np.median(feature_values))\n        slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n        slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n    \n    # Tissue coverage statistics\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n    \n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING FUNCTION\n# ============================================================================\n\ndef process_single_slide(args):\n    \"\"\"\n    Process one complete slide (designed for parallel execution)\n    This function will be called by multiple workers simultaneously\n    \"\"\"\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    \n    try:\n        # Extract PATCH-level object features\n        patch_features = extract_object_features_from_wsi(\n            slide_path,\n            patch_size=patch_size,\n            target_level=target_level,\n            tissue_threshold=tissue_threshold\n        )\n        \n        if patch_features:\n            # Aggregate to SLIDE-level\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, \n                f\"{dataset_name}_{slide_name}\"\n            )\n            \n            return {\n                'success': True,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': slide_features,\n                'num_patches': len(patch_features),\n                'error': None\n            }\n        else:\n            return {\n                'success': False,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': None,\n                'num_patches': 0,\n                'error': 'No tissue patches found'\n            }\n            \n    except Exception as e:\n        return {\n            'success': False,\n            'slide_path': slide_path,\n            'slide_name': slide_name,\n            'features': None,\n            'num_patches': 0,\n            'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: CHECKPOINT SYSTEM\n# ============================================================================\n\ndef load_checkpoint(dataset_name):\n    \"\"\"Load checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            return set(json.load(f))\n    return set()\n\ndef save_checkpoint(processed_slides, dataset_name):\n    \"\"\"Save checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    with open(checkpoint_file, 'w') as f:\n        json.dump(list(processed_slides), f)\n\n# ============================================================================\n# STEP 9: MAIN PROCESSING LOOP WITH PARALLEL BATCHES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING PARALLEL BATCH OBJECT-LEVEL FEATURE EXTRACTION\")\nprint(\"=\"*80)\n\n# Create output directory\noutput_path = f'/kaggle/working/object_features_{dataset_name}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Load checkpoint\nprocessed_slides = load_checkpoint(dataset_name)\nprint(f\"Already processed: {len(processed_slides)} slides\")\n\n# Find all slides\nslides = []\nfor root, dirs, files in os.walk(dataset_path):\n    slides.extend([os.path.join(root, f) for f in files \n                  if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))])\n\n# Filter out already processed slides\nslides_to_process = [s for s in slides if s not in processed_slides]\n\nprint(f\"Total slides in dataset: {len(slides)}\")\nprint(f\"Slides remaining to process: {len(slides_to_process)}\")\n\n# Storage for slide-level features\nall_slides_features = []\n\n# Process slides in batches with parallel workers\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"PROCESSING BATCH {batch_start//BATCH_SIZE + 1}\")\n    print(f\"Slides {batch_start + 1}-{batch_end} of {len(slides_to_process)}\")\n    print(f\"Processing {len(batch_slides)} slides with {PARALLEL_WORKERS} parallel workers\")\n    print(f\"{'='*80}\")\n    \n    # Prepare arguments for parallel processing\n    slide_args = [\n        (slide_path, dataset_name, 256, 1, 0.3)\n        for slide_path in batch_slides\n    ]\n    \n    # Process batch in parallel\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        # Submit all slides in batch\n        futures = {executor.submit(process_single_slide, args): args[0] \n                  for args in slide_args}\n        \n        # Collect results as they complete\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            \n            try:\n                result = future.result()\n                \n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    processed_slides.add(result['slide_path'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n                    \n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n    \n    # Save checkpoint after each batch\n    save_checkpoint(processed_slides, dataset_name)\n    \n    # Save temporary results\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides completed\")\n\n# ============================================================================\n# STEP 10: SAVE FINAL RESULTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING FINAL RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    # Convert to DataFrame\n    final_df = pd.DataFrame(all_slides_features)\n    \n    print(f\"\\nFinal dataset shape: {final_df.shape}\")\n    print(f\"  - Rows (slides): {final_df.shape[0]}\")\n    print(f\"  - Columns (features): {final_df.shape[1]}\")\n    \n    # Save as CSV\n    csv_path = f'{output_path}/{dataset_name}_slide_object_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"âœ“ Saved CSV to: {csv_path}\")\n    \n    # Save as compressed numpy\n    npz_path = f'{output_path}/{dataset_name}_slide_object_features.npz'\n    np.savez_compressed(\n        npz_path,\n        slide_names=final_df['slide_name'].values,\n        features=final_df.drop('slide_name', axis=1).values,\n        feature_names=final_df.drop('slide_name', axis=1).columns.values\n    )\n    print(f\"âœ“ Saved NPZ to: {npz_path}\")\n    \n    # Show sample\n    print(\"\\n\" + \"=\"*80)\n    print(\"SAMPLE OUTPUT\")\n    print(\"=\"*80)\n    print(final_df.head())\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"OBJECT-LEVEL FEATURE EXTRACTION COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Total slides processed: {len(all_slides_features)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n    print(f\"Output directory: {output_path}\")\n    print(f\"Parallel workers used: {PARALLEL_WORKERS}\")\n    print(f\"Batch size: {BATCH_SIZE}\")\n    \n    # Feature summary\n    print(\"\\n\" + \"=\"*80)\n    print(\"FEATURE CATEGORIES EXTRACTED:\")\n    print(\"=\"*80)\n    print(\"1. NUCLEUS MORPHOLOGY:\")\n    print(\"   - Area, perimeter, eccentricity, solidity, circularity\")\n    print(\"   - Major/minor axis lengths, aspect ratio\")\n    print(\"   - Bounding box dimensions\")\n    print(\"\\n2. NUCLEUS INTENSITY:\")\n    print(\"   - Mean, std, min, max, median\")\n    print(\"   - Range, skewness, kurtosis\")\n    print(\"\\n3. SPATIAL DISTRIBUTION:\")\n    print(\"   - Nucleus count and density\")\n    print(\"   - Nearest neighbor distances\")\n    print(\"   - Pairwise distance statistics\")\n    print(\"   - Centroid variance\")\n    print(\"\\n4. GRAPH TOPOLOGY:\")\n    print(\"   - Edge count and density\")\n    print(\"   - Degree distribution\")\n    print(\"   - Edge length statistics\")\nelse:\n    print(\"âš  No slides were successfully processed!\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"NEXT STEPS:\")\nprint(\"=\"*80)\nprint(\"1. Download the CSV file\")\nprint(\"2. Change the dataset name at the top of this code:\")\nprint(f'   dataset_to_process = \"saadinn/bracs-wsi-group-NEXT-DATASET\"')\nprint(\"3. Run again for the next dataset\")\nprint(\"4. Repeat for all 9 datasets\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"hi","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}