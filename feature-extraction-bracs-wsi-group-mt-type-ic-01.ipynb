{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":13910473,"datasetId":8863312,"databundleVersionId":14677690},{"sourceType":"datasetVersion","sourceId":14882549,"datasetId":9521821,"databundleVersionId":15745731}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI FEATURE EXTRACTION (PARALLEL BATCH PROCESSING)\n# ============================================================================\n\n# Import all required libraries\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects\nfrom skimage import feature\nfrom skimage.feature import local_binary_pattern, hog, graycomatrix, graycoprops\nfrom scipy import stats\nfrom scipy.stats import skew, kurtosis\nimport pywt\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\n# Number of slides to process in parallel (adjust based on Kaggle performance)\nPARALLEL_WORKERS = 4  # Kaggle has 4 CPU cores - process 4 slides at once\nBATCH_SIZE = 8  # Process slides in batches (adjust if memory issues)\n\n# ============================================================================\n# STEP 1: CHOOSE WHICH DATASET TO PROCESS\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI FEATURE EXTRACTION - PARALLEL BATCH MODE\")\nprint(\"=\"*80)\n\n# SELECT ONE DATASET AT A TIME\ndataset_to_process = \"saadinn/bracs-wsi-group-mt-type-ic-01\"  # â† CHANGE THIS FOR EACH RUN\n\nprint(f\"\\nDownloading dataset: {dataset_to_process}\")\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name: {dataset_name}\")\nprint(f\"âœ“ Parallel workers: {PARALLEL_WORKERS}\")\nprint(f\"âœ“ Batch size: {BATCH_SIZE}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION FUNCTIONS\n# ============================================================================\n\ndef build_tissue_mask(slide, level=4):\n    \"\"\"Creates binary mask identifying tissue regions at low resolution\"\"\"\n    img = np.array(slide.read_region((0, 0), level, slide.level_dimensions[level]))[:, :, :3]\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    mask = saturation > 0.05\n    mask = remove_small_objects(mask, min_size=500)\n    mask = remove_small_holes(mask, area_threshold=500)\n    return mask\n\ndef tissue_ratio(mask, x, y, patch_size, scale):\n    \"\"\"Calculates proportion of tissue in a patch location\"\"\"\n    xs = int(x / scale)\n    ys = int(y / scale)\n    ps = int(patch_size / scale)\n    patch_mask = mask[ys:ys+ps, xs:xs+ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return patch_mask.mean()\n\ndef preprocess_patch(patch):\n    \"\"\"Normalizes staining variations using histogram equalization\"\"\"\n    patch = cv2.cvtColor(patch, cv2.COLOR_RGB2LAB)\n    patch[:, :, 0] = cv2.equalizeHist(patch[:, :, 0])\n    patch = cv2.cvtColor(patch, cv2.COLOR_LAB2RGB)\n    return patch\n\n# ============================================================================\n# STEP 3: ENHANCED FEATURE EXTRACTORS\n# ============================================================================\n\nclass EnhancedColorExtractor:\n    \"\"\"Extracts comprehensive color features from RGB images\"\"\"\n    \n    @staticmethod\n    def extract_all_color_features(rgb_patch: np.ndarray) -> dict:\n        features = {}\n        \n        # RGB channel features\n        for idx, channel_name in enumerate(['R', 'G', 'B']):\n            channel = rgb_patch[:, :, idx].flatten()\n            features[f'{channel_name}_mean'] = float(np.mean(channel))\n            features[f'{channel_name}_std'] = float(np.std(channel))\n            features[f'{channel_name}_skewness'] = float(skew(channel))\n            features[f'{channel_name}_kurtosis'] = float(kurtosis(channel))\n            features[f'{channel_name}_min'] = float(np.min(channel))\n            features[f'{channel_name}_max'] = float(np.max(channel))\n            features[f'{channel_name}_range'] = float(np.max(channel) - np.min(channel))\n            hist, _ = np.histogram(channel, bins=256, range=(0, 255))\n            hist = hist / (hist.sum() + 1e-10)\n            features[f'{channel_name}_entropy'] = float(-np.sum(hist * np.log2(hist + 1e-10)))\n        \n        # HSV features\n        hsv = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2HSV)\n        for idx, channel_name in enumerate(['H', 'S', 'V']):\n            channel = hsv[:, :, idx].flatten()\n            features[f'HSV_{channel_name}_mean'] = float(np.mean(channel))\n            features[f'HSV_{channel_name}_std'] = float(np.std(channel))\n        \n        # LAB features\n        lab = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2LAB)\n        for idx, channel_name in enumerate(['L', 'A', 'B']):\n            channel = lab[:, :, idx].flatten()\n            features[f'LAB_{channel_name}_mean'] = float(np.mean(channel))\n            features[f'LAB_{channel_name}_std'] = float(np.std(channel))\n        \n        return features\n\n\nclass EnhancedTextureExtractor:\n    \"\"\"Comprehensive texture feature extraction\"\"\"\n    \n    @staticmethod\n    def extract_all_texture_features(gray_patch: np.ndarray) -> dict:\n        features = {}\n        \n        # LBP features\n        try:\n            lbp = local_binary_pattern(gray_patch, 24, 3, method='uniform')\n            features['LBP_mean'] = float(np.mean(lbp))\n            features['LBP_std'] = float(np.std(lbp))\n        except:\n            features['LBP_mean'] = 0.0\n            features['LBP_std'] = 0.0\n        \n        # Gabor features\n        try:\n            for freq_idx, frequency in enumerate([0.1, 0.2]):\n                for theta_idx, theta in enumerate([0, np.pi/4]):\n                    kernel = cv2.getGaborKernel((31, 31), 5.0, theta, 1.0/frequency, 0.5, 0)\n                    filtered = cv2.filter2D(gray_patch, cv2.CV_32F, kernel)\n                    features[f'Gabor_f{freq_idx}_t{theta_idx}_mean'] = float(np.mean(filtered))\n                    features[f'Gabor_f{freq_idx}_t{theta_idx}_std'] = float(np.std(filtered))\n        except:\n            pass\n        \n        # GLCM features\n        try:\n            gray_quantized = (gray_patch / 32).astype(np.uint8)\n            glcm = graycomatrix(gray_quantized, [1], [0], levels=8, symmetric=True, normed=True)\n            features['GLCM_contrast'] = float(graycoprops(glcm, 'contrast')[0, 0])\n            features['GLCM_homogeneity'] = float(graycoprops(glcm, 'homogeneity')[0, 0])\n            features['GLCM_energy'] = float(graycoprops(glcm, 'energy')[0, 0])\n        except:\n            pass\n        \n        return features\n\n\nclass WaveletFeatureExtractor:\n    \"\"\"Wavelet transform features\"\"\"\n    \n    @staticmethod\n    def extract_wavelet_features(gray_patch: np.ndarray) -> dict:\n        features = {}\n        \n        try:\n            coeffs = pywt.wavedec2(gray_patch, 'db4', level=2)\n            \n            # Approximation coefficients\n            cA = coeffs[0]\n            features['Wavelet_L0_LL_mean'] = float(np.mean(cA))\n            features['Wavelet_L0_LL_std'] = float(np.std(cA))\n            features['Wavelet_L0_LL_energy'] = float(np.sum(cA ** 2))\n            \n            # Detail coefficients\n            for i in range(1, len(coeffs)):\n                cH, cV, cD = coeffs[i]\n                features[f'Wavelet_L{i}_LH_energy'] = float(np.sum(cH ** 2))\n                features[f'Wavelet_L{i}_HL_energy'] = float(np.sum(cV ** 2))\n                features[f'Wavelet_L{i}_HH_energy'] = float(np.sum(cD ** 2))\n        except:\n            pass\n        \n        return features\n\n\nclass ComprehensivePixelFeatureExtractor:\n    \"\"\"Combines all pixel-level feature extractors\"\"\"\n    \n    def __init__(self):\n        self.color_extractor = EnhancedColorExtractor()\n        self.texture_extractor = EnhancedTextureExtractor()\n        self.wavelet_extractor = WaveletFeatureExtractor()\n    \n    def extract_all_features(self, rgb_patch: np.ndarray) -> dict:\n        all_features = {}\n        gray_patch = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        all_features.update(self.color_extractor.extract_all_color_features(rgb_patch))\n        all_features.update(self.texture_extractor.extract_all_texture_features(gray_patch))\n        all_features.update(self.wavelet_extractor.extract_wavelet_features(gray_patch))\n        return all_features\n\n# ============================================================================\n# STEP 4: PATCH-LEVEL FEATURE EXTRACTION\n# ============================================================================\n\ndef extract_features_from_wsi(\n    wsi_path,\n    patch_size=256,\n    target_level=1,\n    tissue_threshold=0.3\n):\n    \"\"\"Extracts features from all tissue patches in a WSI\"\"\"\n    slide = openslide.OpenSlide(wsi_path)\n    mask_level = slide.level_count - 1\n    tissue_mask = build_tissue_mask(slide, mask_level)\n    scale = slide.level_downsamples[mask_level]\n    extractor = ComprehensivePixelFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n    step = patch_size\n    \n    # Count total patches\n    total_patches = 0\n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio >= tissue_threshold:\n                total_patches += 1\n    \n    # Extract patches (NO progress bar for parallel processing)\n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio < tissue_threshold:\n                continue\n            \n            patch = slide.read_region(\n                (int(x * slide.level_downsamples[target_level]),\n                 int(y * slide.level_downsamples[target_level])),\n                target_level, (patch_size, patch_size)\n            )\n            patch = np.array(patch)[:, :, :3]\n            patch = preprocess_patch(patch)\n            patch_features = extractor.extract_all_features(patch)\n            patch_features['patch_x'] = x\n            patch_features['patch_y'] = y\n            patch_features['tissue_ratio'] = float(ratio)\n            features_list.append(patch_features)\n    \n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 5: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    \"\"\"Converts patch-level features to slide-level features\"\"\"\n    if not patch_features_list:\n        return {}\n    \n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n    \n    slide_features = {}\n    slide_features['slide_name'] = slide_name\n    slide_features['num_patches'] = len(patch_features_list)\n    \n    # Aggregate each feature\n    for feature in feature_cols:\n        feature_values = df[feature].values\n        slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n        slide_features[f'{feature}_std'] = float(np.std(feature_values))\n        slide_features[f'{feature}_min'] = float(np.min(feature_values))\n        slide_features[f'{feature}_max'] = float(np.max(feature_values))\n        slide_features[f'{feature}_median'] = float(np.median(feature_values))\n        slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n        slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n    \n    # Tissue coverage statistics\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n    \n    return slide_features\n\n# ============================================================================\n# STEP 6: PARALLEL SLIDE PROCESSING FUNCTION\n# ============================================================================\n\ndef process_single_slide(args):\n    \"\"\"\n    Process one complete slide (designed for parallel execution)\n    This function will be called by multiple workers simultaneously\n    \"\"\"\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    \n    try:\n        # Extract PATCH-level features\n        patch_features = extract_features_from_wsi(\n            slide_path,\n            patch_size=patch_size,\n            target_level=target_level,\n            tissue_threshold=tissue_threshold\n        )\n        \n        if patch_features:\n            # Aggregate to SLIDE-level\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, \n                f\"{dataset_name}_{slide_name}\"\n            )\n            \n            return {\n                'success': True,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': slide_features,\n                'num_patches': len(patch_features),\n                'error': None\n            }\n        else:\n            return {\n                'success': False,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': None,\n                'num_patches': 0,\n                'error': 'No tissue patches found'\n            }\n            \n    except Exception as e:\n        return {\n            'success': False,\n            'slide_path': slide_path,\n            'slide_name': slide_name,\n            'features': None,\n            'num_patches': 0,\n            'error': str(e)\n        }\n\n# ============================================================================\n# STEP 7: CHECKPOINT SYSTEM\n# ============================================================================\n\ndef load_checkpoint(dataset_name):\n    \"\"\"Load checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_{dataset_name}.json'\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            return set(json.load(f))\n    return set()\n\ndef save_checkpoint(processed_slides, dataset_name):\n    \"\"\"Save checkpoint for specific dataset\"\"\"\n    checkpoint_file = f'/kaggle/working/checkpoint_{dataset_name}.json'\n    with open(checkpoint_file, 'w') as f:\n        json.dump(list(processed_slides), f)\n\n# ============================================================================\n# STEP 8: MAIN PROCESSING LOOP WITH PARALLEL BATCHES\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING PARALLEL BATCH FEATURE EXTRACTION\")\nprint(\"=\"*80)\n\n# Create output directory\noutput_path = f'/kaggle/working/features_{dataset_name}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Load checkpoint\nprocessed_slides = load_checkpoint(dataset_name)\nprint(f\"Already processed: {len(processed_slides)} slides\")\n\n# Find all slides\nslides = []\nfor root, dirs, files in os.walk(dataset_path):\n    slides.extend([os.path.join(root, f) for f in files \n                  if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))])\n\n# Filter out already processed slides\nslides_to_process = [s for s in slides if s not in processed_slides]\n\nprint(f\"Total slides in dataset: {len(slides)}\")\nprint(f\"Slides remaining to process: {len(slides_to_process)}\")\n\n# Storage for slide-level features\nall_slides_features = []\n\n# Process slides in batches with parallel workers\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"PROCESSING BATCH {batch_start//BATCH_SIZE + 1}\")\n    print(f\"Slides {batch_start + 1}-{batch_end} of {len(slides_to_process)}\")\n    print(f\"Processing {len(batch_slides)} slides with {PARALLEL_WORKERS} parallel workers\")\n    print(f\"{'='*80}\")\n    \n    # Prepare arguments for parallel processing\n    slide_args = [\n        (slide_path, dataset_name, 256, 1, 0.3)\n        for slide_path in batch_slides\n    ]\n    \n    # Process batch in parallel\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        # Submit all slides in batch\n        futures = {executor.submit(process_single_slide, args): args[0] \n                  for args in slide_args}\n        \n        # Collect results as they complete\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            \n            try:\n                result = future.result()\n                \n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    processed_slides.add(result['slide_path'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n                    \n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n    \n    # Save checkpoint after each batch\n    save_checkpoint(processed_slides, dataset_name)\n    \n    # Save temporary results\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides completed\")\n\n# ============================================================================\n# STEP 9: SAVE FINAL RESULTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING FINAL RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    # Convert to DataFrame\n    final_df = pd.DataFrame(all_slides_features)\n    \n    print(f\"\\nFinal dataset shape: {final_df.shape}\")\n    print(f\"  - Rows (slides): {final_df.shape[0]}\")\n    print(f\"  - Columns (features): {final_df.shape[1]}\")\n    \n    # Save as CSV\n    csv_path = f'{output_path}/{dataset_name}_slide_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"âœ“ Saved CSV to: {csv_path}\")\n    \n    # Save as compressed numpy\n    npz_path = f'{output_path}/{dataset_name}_slide_features.npz'\n    np.savez_compressed(\n        npz_path,\n        slide_names=final_df['slide_name'].values,\n        features=final_df.drop('slide_name', axis=1).values,\n        feature_names=final_df.drop('slide_name', axis=1).columns.values\n    )\n    print(f\"âœ“ Saved NPZ to: {npz_path}\")\n    \n    # Show sample\n    print(\"\\n\" + \"=\"*80)\n    print(\"SAMPLE OUTPUT\")\n    print(\"=\"*80)\n    print(final_df.head())\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"FEATURE EXTRACTION COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Total slides processed: {len(all_slides_features)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n    print(f\"Output directory: {output_path}\")\n    print(f\"Parallel workers used: {PARALLEL_WORKERS}\")\n    print(f\"Batch size: {BATCH_SIZE}\")\nelse:\n    print(\"âš  No slides were successfully processed!\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"NEXT STEPS:\")\nprint(\"=\"*80)\nprint(\"1. Download the CSV file\")\nprint(\"2. Change the dataset name at the top of this code:\")\nprint(f'   dataset_to_process = \"saadinn/bracs-wsi-group-NEXT-DATASET\"')\nprint(\"3. Run again for the next dataset\")\nprint(\"4. Repeat for all 9 datasets\")\nprint(\"=\"*80)\n","metadata":{"execution":{"iopub.status.busy":"2026-02-07T18:53:00.176347Z","iopub.execute_input":"2026-02-07T18:53:00.176714Z","iopub.status.idle":"2026-02-07T20:40:05.202560Z","shell.execute_reply.started":"2026-02-07T18:53:00.176687Z","shell.execute_reply":"2026-02-07T20:40:05.200545Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Object Level extraction","metadata":{}},{"cell_type":"markdown","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (OPTIMIZED CPU)\n# ============================================================================\n\n# Import all required libraries\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, erosion, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom tqdm import tqdm\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# CONFIGURATION\n# ============================================================================\n\nPARALLEL_WORKERS = 4  # Kaggle has 4 CPU cores\nBATCH_SIZE = 8\n\n# ============================================================================\n# STEP 1: CHOOSE WHICH DATASET TO PROCESS\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - OPTIMIZED CPU VERSION\")\nprint(\"=\"*80)\n\ndataset_to_process = \"saadinn/bracs-wsi-group-mt-type-ic-01\"\n\nprint(f\"\\nDownloading dataset: {dataset_to_process}\")\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name: {dataset_name}\")\nprint(f\"âœ“ Parallel workers: {PARALLEL_WORKERS}\")\nprint(f\"âœ“ Batch size: {BATCH_SIZE}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION FUNCTIONS\n# ============================================================================\n\ndef build_tissue_mask(slide, level=4):\n    \"\"\"Creates binary mask identifying tissue regions at low resolution\"\"\"\n    img = np.array(slide.read_region((0, 0), level, slide.level_dimensions[level]))[:, :, :3]\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    mask = saturation > 0.05\n    mask = remove_small_objects(mask, min_size=500)\n    mask = remove_small_holes(mask, area_threshold=500)\n    return mask\n\ndef tissue_ratio(mask, x, y, patch_size, scale):\n    \"\"\"Calculates proportion of tissue in a patch location\"\"\"\n    xs = int(x / scale)\n    ys = int(y / scale)\n    ps = int(patch_size / scale)\n    patch_mask = mask[ys:ys+ps, xs:xs+ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return patch_mask.mean()\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n    \"\"\"Segments nuclei from H&E stained histopathology images\"\"\"\n    \n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        \"\"\"Extract hematoxylin channel using color deconvolution\"\"\"\n        # Normalize RGB to [0, 1]\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.maximum(rgb_norm, 1e-6)\n        \n        # Convert to optical density (OD)\n        od = -np.log(rgb_norm)\n        \n        # H&E stain matrix\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],\n            [0.07, 0.99, 0.11],\n            [0.27, 0.57, 0.78]\n        ])\n        \n        # Deconvolve to get stain concentrations\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        \n        # Normalize to [0, 255]\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        \n        return hematoxylin\n    \n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        \"\"\"Segments nuclei using multiple methods for robustness\"\"\"\n        try:\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            _, nucleus_mask = cv2.threshold(hematoxylin, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            nucleus_mask = nucleus_mask > 0\n        except:\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            gray_inv = 255 - gray\n            _, nucleus_mask = cv2.threshold(gray_inv, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n            nucleus_mask = nucleus_mask > 0\n        \n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=15)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=15)\n        \n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n        \n        nucleus_mask = erosion(nucleus_mask, disk(1))\n        nucleus_mask = dilation(nucleus_mask, disk(2))\n        \n        distance = ndi.distance_transform_edt(nucleus_mask)\n        coords = peak_local_max(distance, min_distance=3, labels=nucleus_mask, exclude_border=False)\n        \n        if len(coords) == 0:\n            labeled_nuclei = label(nucleus_mask)\n            return labeled_nuclei\n        \n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n        \n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: OBJECT-LEVEL FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n    \"\"\"Extracts morphological and intensity features from individual nuclei\"\"\"\n    \n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        \"\"\"Extract features from a single nucleus region\"\"\"\n        features = {}\n        \n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        \n        if region.perimeter > 0:\n            features['circularity'] = float(4 * np.pi * region.area / (region.perimeter ** 2))\n        else:\n            features['circularity'] = 0.0\n        \n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        \n        if region.minor_axis_length > 0:\n            features['aspect_ratio'] = float(region.major_axis_length / region.minor_axis_length)\n        else:\n            features['aspect_ratio'] = 0.0\n        \n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n        \n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        \n        return features\n\n\nclass SpatialFeatureExtractor:\n    \"\"\"Extracts spatial arrangement features from nuclei populations\"\"\"\n    \n    @staticmethod\n    def extract_spatial_features(regions):\n        \"\"\"Extract features describing spatial distribution of nuclei\"\"\"\n        features = {}\n        \n        if len(regions) == 0:\n            return features\n        \n        centroids = np.array([region.centroid for region in regions])\n        \n        features['nucleus_count'] = len(regions)\n        total_area = sum([region.area for region in regions])\n        features['total_nucleus_area'] = float(total_area)\n        \n        if len(centroids) > 1:\n            distances = cdist(centroids, centroids)\n            np.fill_diagonal(distances, np.inf)\n            \n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n            \n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            features['pairwise_distance_mean'] = float(np.mean(upper_triangle))\n            features['pairwise_distance_std'] = float(np.std(upper_triangle))\n            features['pairwise_distance_min'] = float(np.min(upper_triangle))\n            features['pairwise_distance_max'] = float(np.max(upper_triangle))\n        \n        if len(centroids) > 2:\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n        \n        return features\n\n\nclass GraphFeatureExtractor:\n    \"\"\"Extracts graph-based features from nucleus spatial relationships\"\"\"\n    \n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        \"\"\"Build graph connecting nearby nuclei\"\"\"\n        from scipy.spatial import Delaunay\n        \n        if len(centroids) < 3:\n            return None, None\n        \n        try:\n            tri = Delaunay(centroids)\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i+1)%3]]))\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            return tri, list(edges)\n        except:\n            return None, None\n    \n    @staticmethod\n    def extract_graph_features(regions):\n        \"\"\"Extract graph-based topological features\"\"\"\n        features = {}\n        \n        if len(regions) < 3:\n            return features\n        \n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n        \n        if edges is None or len(edges) == 0:\n            return features\n        \n        features['num_edges'] = len(edges)\n        features['edge_density'] = float(len(edges) / (len(regions) * (len(regions) - 1) / 2))\n        \n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n        \n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n        \n        edge_lengths = [np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n        \n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n    \"\"\"Combines all object-level feature extractors\"\"\"\n    \n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n    \n    def extract_all_features(self, rgb_patch):\n        \"\"\"Extract all object-level features from a patch\"\"\"\n        all_features = {}\n        \n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        regions = [r for r in regions if r.area >= 10]\n        \n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum([r.area for r in regions]) if regions else 0.0)\n        \n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except:\n                    continue\n            \n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n        \n        if len(regions) > 0:\n            spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n            all_features.update(spatial_features)\n        \n        if len(regions) >= 3:\n            graph_features = self.graph_extractor.extract_graph_features(regions)\n            all_features.update(graph_features)\n        \n        return all_features\n\n# ============================================================================\n# STEP 5: PATCH-LEVEL FEATURE EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(wsi_path, patch_size=256, target_level=1, tissue_threshold=0.3):\n    \"\"\"Extracts object-level features from all tissue patches in a WSI\"\"\"\n    slide = openslide.OpenSlide(wsi_path)\n    mask_level = slide.level_count - 1\n    tissue_mask = build_tissue_mask(slide, mask_level)\n    scale = slide.level_downsamples[mask_level]\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n    step = patch_size\n    \n    for y in range(0, height, step):\n        for x in range(0, width, step):\n            ratio = tissue_ratio(tissue_mask, x * slide.level_downsamples[target_level],\n                                y * slide.level_downsamples[target_level], patch_size, scale)\n            if ratio < tissue_threshold:\n                continue\n            \n            patch = slide.read_region(\n                (int(x * slide.level_downsamples[target_level]),\n                 int(y * slide.level_downsamples[target_level])),\n                target_level, (patch_size, patch_size)\n            )\n            patch = np.array(patch)[:, :, :3]\n            \n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception as e:\n                continue\n    \n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    \"\"\"Converts patch-level features to slide-level features with proper NaN handling\"\"\"\n    if not patch_features_list:\n        return {}\n    \n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n    \n    slide_features = {}\n    slide_features['slide_name'] = slide_name\n    slide_features['num_patches'] = len(patch_features_list)\n    \n    for feature in feature_cols:\n        feature_values = df[feature].dropna().values\n        \n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            slide_features[f'{feature}_mean'] = 0.0\n            slide_features[f'{feature}_std'] = 0.0\n            slide_features[f'{feature}_min'] = 0.0\n            slide_features[f'{feature}_max'] = 0.0\n            slide_features[f'{feature}_median'] = 0.0\n            slide_features[f'{feature}_q25'] = 0.0\n            slide_features[f'{feature}_q75'] = 0.0\n    \n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n    \n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING\n# ============================================================================\n\ndef process_single_slide(args):\n    \"\"\"Process one complete slide\"\"\"\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    \n    try:\n        patch_features = extract_object_features_from_wsi(\n            slide_path, patch_size, target_level, tissue_threshold\n        )\n        \n        if patch_features:\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, f\"{dataset_name}_{slide_name}\"\n            )\n            \n            return {\n                'success': True,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': slide_features,\n                'num_patches': len(patch_features),\n                'error': None\n            }\n        else:\n            return {\n                'success': False,\n                'slide_path': slide_path,\n                'slide_name': slide_name,\n                'features': None,\n                'num_patches': 0,\n                'error': 'No tissue patches found'\n            }\n    except Exception as e:\n        return {\n            'success': False,\n            'slide_path': slide_path,\n            'slide_name': slide_name,\n            'features': None,\n            'num_patches': 0,\n            'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: CHECKPOINT SYSTEM\n# ============================================================================\n\ndef load_checkpoint(dataset_name):\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    if os.path.exists(checkpoint_file):\n        with open(checkpoint_file, 'r') as f:\n            return set(json.load(f))\n    return set()\n\ndef save_checkpoint(processed_slides, dataset_name):\n    checkpoint_file = f'/kaggle/working/checkpoint_object_{dataset_name}.json'\n    with open(checkpoint_file, 'w') as f:\n        json.dump(list(processed_slides), f)\n\n# ============================================================================\n# STEP 9: MAIN PROCESSING LOOP\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING PARALLEL BATCH OBJECT-LEVEL FEATURE EXTRACTION\")\nprint(\"=\"*80)\n\noutput_path = f'/kaggle/working/object_features_{dataset_name}/'\nos.makedirs(output_path, exist_ok=True)\n\nprocessed_slides = load_checkpoint(dataset_name)\nprint(f\"Already processed: {len(processed_slides)} slides\")\n\nslides = []\nfor root, dirs, files in os.walk(dataset_path):\n    slides.extend([os.path.join(root, f) for f in files \n                  if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))])\n\nslides_to_process = [s for s in slides if s not in processed_slides]\n\nprint(f\"Total slides in dataset: {len(slides)}\")\nprint(f\"Slides remaining to process: {len(slides_to_process)}\")\n\nall_slides_features = []\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n    \n    print(f\"\\n{'='*80}\")\n    print(f\"PROCESSING BATCH {batch_start//BATCH_SIZE + 1}\")\n    print(f\"Slides {batch_start + 1}-{batch_end} of {len(slides_to_process)}\")\n    print(f\"Processing {len(batch_slides)} slides with {PARALLEL_WORKERS} parallel workers\")\n    print(f\"{'='*80}\")\n    \n    slide_args = [(slide_path, dataset_name, 256, 1, 0.3) for slide_path in batch_slides]\n    \n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        futures = {executor.submit(process_single_slide, args): args[0] for args in slide_args}\n        \n        for future in as_completed(futures):\n            slide_path = futures[future]\n            \n            try:\n                result = future.result()\n                \n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    processed_slides.add(result['slide_path'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n    \n    save_checkpoint(processed_slides, dataset_name)\n    \n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides completed\")\n\n# ============================================================================\n# STEP 10: SAVE FINAL RESULTS\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING FINAL RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    final_df = pd.DataFrame(all_slides_features)\n    \n    print(f\"\\nFinal dataset shape: {final_df.shape}\")\n    print(f\"  - Rows (slides): {final_df.shape[0]}\")\n    print(f\"  - Columns (features): {final_df.shape[1]}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"NUCLEUS DETECTION DIAGNOSTICS\")\n    print(\"=\"*80)\n    \n    nucleus_count_cols = [col for col in final_df.columns if 'nucleus_count' in col.lower()]\n    if nucleus_count_cols:\n        for col in nucleus_count_cols:\n            mean_count = final_df[col].mean()\n            print(f\"{col}: mean = {mean_count:.2f}\")\n            zero_count = (final_df[col] == 0).sum()\n            print(f\"  Slides with 0 nuclei: {zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n    \n    nan_counts = final_df.isna().sum()\n    cols_with_nans = nan_counts[nan_counts > 0]\n    if len(cols_with_nans) > 0:\n        print(f\"\\nColumns with NaN values: {len(cols_with_nans)}/{len(final_df.columns)}\")\n        print(f\"Most NaN values: {nan_counts.max()} ({100*nan_counts.max()/len(final_df):.1f}% of slides)\")\n        print(\"\\nTop 10 columns with NaNs:\")\n        print(nan_counts.nlargest(10))\n    else:\n        print(\"\\nâœ“ No NaN values found! All features properly computed.\")\n    \n    zero_cols = (final_df == 0).all()\n    all_zero_cols = zero_cols[zero_cols].index.tolist()\n    if all_zero_cols:\n        print(f\"\\nColumns with all zeros: {len(all_zero_cols)}\")\n        if len(all_zero_cols) <= 20:\n            print(f\"Zero columns: {all_zero_cols}\")\n    \n    print(\"=\"*80)\n    \n    csv_path = f'{output_path}/{dataset_name}_slide_object_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved CSV to: {csv_path}\")\n    \n    npz_path = f'{output_path}/{dataset_name}_slide_object_features.npz'\n    np.savez_compressed(\n        npz_path,\n        slide_names=final_df['slide_name'].values,\n        features=final_df.drop('slide_name', axis=1).values,\n        feature_names=final_df.drop('slide_name', axis=1).columns.values\n    )\n    print(f\"âœ“ Saved NPZ to: {npz_path}\")\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"SAMPLE OUTPUT\")\n    print(\"=\"*80)\n    print(final_df.head())\n    \n    print(\"\\n\" + \"=\"*80)\n    print(\"OBJECT-LEVEL FEATURE EXTRACTION COMPLETE!\")\n    print(\"=\"*80)\n    print(f\"Dataset: {dataset_name}\")\n    print(f\"Total slides processed: {len(all_slides_features)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\nelse:\n    print(\"âš  No slides were successfully processed!\")\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"NEXT STEPS:\")\nprint(\"=\"*80)\nprint(\"1. Download the CSV file\")\nprint(\"2. Change dataset_to_process for next dataset\")\nprint(\"3. Repeat for all datasets\")\nprint(\"=\"*80)\n\n\n# ============================================================================\n# STEP 11: SAVE OUTPUT AS KAGGLE DATASET\n# ============================================================================\n\nfrom kaggle import api\nimport shutil\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"CREATING KAGGLE DATASET FOR OUTPUT\")\nprint(\"=\"*80)\n\n# Create dataset metadata\ndataset_slug = f\"object-features-{dataset_name.replace('_', '-')}\"\nmetadata = {\n    \"title\": f\"Object Features - {dataset_name}\",\n    \"id\": f\"onyekamuoka/{dataset_slug}\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n\nmetadata_path = f'{output_path}/dataset-metadata.json'\nwith open(metadata_path, 'w') as f:\n    json.dump(metadata, f, indent=2)\n\ntry:\n    # Create new dataset (first time)\n    api.dataset_create_new(\n        folder=output_path,\n        dir_mode='zip',\n        convert_to_csv=False,\n        public=False\n    )\n    print(f\"âœ“ Created new dataset: {dataset_slug}\")\nexcept:\n    # Update existing dataset (subsequent runs)\n    api.dataset_create_version(\n        folder=output_path,\n        version_notes=f\"Updated features for {dataset_name}\",\n        dir_mode='zip',\n        convert_to_csv=False\n    )\n    print(f\"âœ“ Updated existing dataset: {dataset_slug}\")\n\nprint(f\"\\nâœ“ Dataset available at: https://www.kaggle.com/datasets/onyekamuoka/{dataset_slug}\")\nprint(\"  Download anytime from Kaggle!\")","metadata":{"execution":{"iopub.status.busy":"2026-02-21T10:50:52.229148Z","iopub.execute_input":"2026-02-21T10:50:52.229577Z","execution_failed":"2026-02-21T22:50:49.609Z"}}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Object Level","metadata":{}},{"cell_type":"markdown","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (SLICED RUNS)\n# ============================================================================\n#\n# HOW TO USE:\n#   This notebook processes a specific slice of slides to stay within\n#   Kaggle's 12-hour time limit. Run it multiple times, changing only\n#   SLIDE_START_INDEX and SLIDE_END_INDEX each time.\n#\n#   Recommended splits for UDH (74 slides, 31 already done):\n#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n#   â”‚  Run    â”‚  Slide Range        â”‚  Change To       â”‚\n#   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n#   â”‚  Run A  â”‚  slides 32 â€“ 47    â”‚  START=32 END=48 â”‚\n#   â”‚  Run B  â”‚  slides 48 â€“ 63    â”‚  START=48 END=64 â”‚\n#   â”‚  Run C  â”‚  slides 64 â€“ 74    â”‚  START=64 END=74 â”‚\n#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n#\n#   After all runs complete, use bracs_wsi_merge.py to combine the CSVs.\n#\n# ============================================================================\n\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# *** CHANGE THESE TWO NUMBERS EACH RUN ***\n# ============================================================================\n\nSLIDE_START_INDEX = 0   # first slide to process (0-based index into sorted slide list)\nSLIDE_END_INDEX   = 15   # process up to but NOT including this index\n\n# ============================================================================\n# CONFIGURATION (leave these unchanged across all runs)\n# ============================================================================\n\nPARALLEL_WORKERS = 4\nBATCH_SIZE = 8\ndataset_to_process = \"saadinn/bracs-wsi-group-mt-type-ic-01\"\n\n# ============================================================================\n# SETUP\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - SLICED RUN\")\nprint(\"=\"*80)\nprint(f\"\\nSlide slice: index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1}\")\nprint(f\"Downloading dataset: {dataset_to_process}\")\n\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\n\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name:  {dataset_name}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION\n# ============================================================================\n\ndef build_tissue_mask(slide):\n    mask_level = slide.level_count - 1\n    img = np.array(\n        slide.read_region((0, 0), mask_level, slide.level_dimensions[mask_level])\n    )[:, :, :3]\n\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    value = hsv[:, :, 2]\n\n    mask = (saturation > 0.03) & (value < 0.95)\n    mask = remove_small_objects(mask, min_size=300)\n    mask = remove_small_holes(mask, area_threshold=300)\n    return mask, mask_level\n\n\ndef tissue_ratio(mask, x_level0, y_level0, patch_size_level0, scale):\n    xs = int(x_level0 / scale)\n    ys = int(y_level0 / scale)\n    ps = max(int(patch_size_level0 / scale), 1)\n    patch_mask = mask[ys:ys + ps, xs:xs + ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return float(patch_mask.mean())\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n\n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.clip(rgb_norm, 1e-6, 1.0)\n        od = -np.log(rgb_norm)\n\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],\n            [0.07, 0.99, 0.11],\n            [0.27, 0.57, 0.78]\n        ])\n\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        return hematoxylin\n\n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        try:\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            hematoxylin_eq = clahe.apply(hematoxylin)\n\n            _, nucleus_mask_otsu = cv2.threshold(\n                hematoxylin_eq, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n            )\n\n            otsu_ratio = nucleus_mask_otsu.mean() / 255.0\n            if otsu_ratio < 0.05 or otsu_ratio > 0.70:\n                nucleus_mask = cv2.adaptiveThreshold(\n                    hematoxylin_eq, 255,\n                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                    cv2.THRESH_BINARY,\n                    blockSize=31,\n                    C=-2\n                )\n                nucleus_mask = nucleus_mask > 0\n            else:\n                nucleus_mask = nucleus_mask_otsu > 0\n\n        except Exception:\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            gray_inv = 255 - gray\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            gray_inv_eq = clahe.apply(gray_inv)\n            nucleus_mask = cv2.adaptiveThreshold(\n                gray_inv_eq, 255,\n                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                cv2.THRESH_BINARY,\n                blockSize=31,\n                C=-2\n            )\n            nucleus_mask = nucleus_mask > 0\n\n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=8)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=8)\n\n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n\n        nucleus_mask = dilation(nucleus_mask, disk(1))\n        distance = ndi.distance_transform_edt(nucleus_mask)\n        coords = peak_local_max(\n            distance, min_distance=2, labels=nucleus_mask, exclude_border=False\n        )\n\n        if len(coords) == 0:\n            return label(nucleus_mask)\n\n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n\n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n\n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        features = {}\n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        features['circularity'] = (\n            float(4 * np.pi * region.area / (region.perimeter ** 2))\n            if region.perimeter > 0 else 0.0\n        )\n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        features['aspect_ratio'] = (\n            float(region.major_axis_length / region.minor_axis_length)\n            if region.minor_axis_length > 0 else 0.0\n        )\n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n\n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        return features\n\n\nclass SpatialFeatureExtractor:\n\n    @staticmethod\n    def extract_spatial_features(regions):\n        default_keys = [\n            'nucleus_count', 'total_nucleus_area',\n            'nn_distance_mean', 'nn_distance_std', 'nn_distance_min',\n            'nn_distance_max', 'nn_distance_median',\n            'pairwise_distance_mean', 'pairwise_distance_std',\n            'pairwise_distance_min', 'pairwise_distance_max',\n            'centroid_x_variance', 'centroid_y_variance',\n            'centroid_x_range', 'centroid_y_range',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) == 0:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        features['nucleus_count'] = float(len(regions))\n        features['total_nucleus_area'] = float(sum(r.area for r in regions))\n\n        if len(centroids) > 1:\n            distances = cdist(centroids, centroids)\n            np.fill_diagonal(distances, np.inf)\n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n\n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            finite_vals = upper_triangle[np.isfinite(upper_triangle)]\n            if len(finite_vals) > 0:\n                features['pairwise_distance_mean'] = float(np.mean(finite_vals))\n                features['pairwise_distance_std'] = float(np.std(finite_vals))\n                features['pairwise_distance_min'] = float(np.min(finite_vals))\n                features['pairwise_distance_max'] = float(np.max(finite_vals))\n\n        if len(centroids) > 2:\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n\n        return features\n\n\nclass GraphFeatureExtractor:\n\n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        from scipy.spatial import Delaunay\n        if len(centroids) < 3:\n            return None, None\n        try:\n            tri = Delaunay(centroids)\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i + 1) % 3]]))\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            return tri, list(edges)\n        except Exception:\n            return None, None\n\n    @staticmethod\n    def extract_graph_features(regions):\n        default_keys = [\n            'num_edges', 'edge_density',\n            'degree_mean', 'degree_std', 'degree_max', 'degree_min',\n            'edge_length_mean', 'edge_length_std',\n            'edge_length_min', 'edge_length_max',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) < 3:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n\n        if edges is None or len(edges) == 0:\n            return features\n\n        features['num_edges'] = float(len(edges))\n        n = len(regions)\n        features['edge_density'] = float(len(edges) / (n * (n - 1) / 2))\n\n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n\n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n\n        edge_lengths = [\n            np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges\n        ]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n\n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n\n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n\n    def extract_all_features(self, rgb_patch):\n        all_features = {}\n\n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        regions = [r for r in regions if r.area >= 8]\n\n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum(r.area for r in regions)) if regions else 0.0\n\n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except Exception:\n                    continue\n\n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n\n        spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n        all_features.update(spatial_features)\n\n        graph_features = self.graph_extractor.extract_graph_features(regions)\n        all_features.update(graph_features)\n\n        return all_features\n\n# ============================================================================\n# STEP 5: WSI PATCH EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(wsi_path, patch_size=256, target_level=1, tissue_threshold=0.3):\n    slide = openslide.OpenSlide(wsi_path)\n    tissue_mask, mask_level = build_tissue_mask(slide)\n    mask_scale = slide.level_downsamples[mask_level]\n    target_downsample = slide.level_downsamples[target_level]\n\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n\n    for y in range(0, height, patch_size):\n        for x in range(0, width, patch_size):\n            x_level0 = int(x * target_downsample)\n            y_level0 = int(y * target_downsample)\n            patch_size_level0 = int(patch_size * target_downsample)\n\n            ratio = tissue_ratio(tissue_mask, x_level0, y_level0, patch_size_level0, mask_scale)\n\n            if ratio < tissue_threshold:\n                continue\n\n            patch = slide.read_region((x_level0, y_level0), target_level, (patch_size, patch_size))\n            patch = np.array(patch)[:, :, :3]\n\n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception:\n                continue\n\n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    if not patch_features_list:\n        return {}\n\n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n\n    slide_features = {'slide_name': slide_name, 'num_patches': len(patch_features_list)}\n\n    for feature in feature_cols:\n        feature_values = df[feature].dropna().values\n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            for suffix in ['mean', 'std', 'min', 'max', 'median', 'q25', 'q75']:\n                slide_features[f'{feature}_{suffix}'] = 0.0\n\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n\n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING\n# ============================================================================\n\ndef process_single_slide(args):\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    try:\n        patch_features = extract_object_features_from_wsi(\n            slide_path, patch_size, target_level, tissue_threshold\n        )\n        if patch_features:\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, f\"{dataset_name}_{slide_name}\"\n            )\n            return {\n                'success': True, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': slide_features,\n                'num_patches': len(patch_features), 'error': None\n            }\n        else:\n            return {\n                'success': False, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': None,\n                'num_patches': 0, 'error': 'No tissue patches found'\n            }\n    except Exception as e:\n        return {\n            'success': False, 'slide_path': slide_path,\n            'slide_name': slide_name, 'features': None,\n            'num_patches': 0, 'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: MAIN PROCESSING LOOP\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING SLICED BATCH PROCESSING\")\nprint(\"=\"*80)\n\n# Build run-specific output folder so each run's CSV is separate\nrun_label = f\"slides_{SLIDE_START_INDEX}_{SLIDE_END_INDEX - 1}\"\noutput_path = f'/kaggle/working/object_features_{dataset_name}_{run_label}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Collect and sort all slides so the index is deterministic across runs\nall_slides = []\nfor root, dirs, files in os.walk(dataset_path):\n    all_slides.extend([\n        os.path.join(root, f) for f in files\n        if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))\n    ])\nall_slides = sorted(all_slides)  # IMPORTANT: sort so index is consistent every run\n\nprint(f\"Total slides in dataset: {len(all_slides)}\")\n\n# Apply the slice\nslides_to_process = all_slides[SLIDE_START_INDEX:SLIDE_END_INDEX]\nprint(f\"This run will process: {len(slides_to_process)} slides \"\n      f\"(index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1})\")\nfor s in slides_to_process:\n    print(f\"  â€¢ {os.path.basename(s)}\")\n\nall_slides_features = []\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n\n    print(f\"\\n{'='*80}\")\n    print(f\"BATCH {batch_start // BATCH_SIZE + 1} â€” \"\n          f\"slides {SLIDE_START_INDEX + batch_start + 1}â€“\"\n          f\"{SLIDE_START_INDEX + batch_end} of {len(all_slides)} total\")\n    print(f\"{'='*80}\")\n\n    slide_args = [(s, dataset_name, 256, 1, 0.3) for s in batch_slides]\n\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        futures = {executor.submit(process_single_slide, args): args[0] for args in slide_args}\n\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            try:\n                result = future.result()\n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n\n    # Save interim CSV after every batch\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides saved so far\")\n\n# ============================================================================\n# STEP 9: SAVE THIS RUN'S FINAL CSV\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING RUN RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    final_df = pd.DataFrame(all_slides_features)\n    print(f\"Slides processed this run: {len(final_df)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n\n    # Diagnostics\n    nucleus_count_cols = [c for c in final_df.columns if 'nucleus_count' in c.lower()]\n    for col in nucleus_count_cols:\n        zero_count = (final_df[col] == 0).sum()\n        print(f\"{col}: mean={final_df[col].mean():.2f}, \"\n              f\"zero slides={zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n\n    nan_total = final_df.isna().sum().sum()\n    print(f\"Total NaN values: {nan_total} ({'none âœ“' if nan_total == 0 else 'check merge script'})\")\n\n    csv_path = f'{output_path}/{dataset_name}_{run_label}_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved: {csv_path}\")\nelse:\n    print(\"âš  No slides were successfully processed this run!\")\n\n# ============================================================================\n# STEP 10: UPLOAD THIS RUN'S OUTPUT TO KAGGLE DATASETS\n# ============================================================================\n\nfrom kaggle import api\n\ndataset_slug = f\"object-features-{dataset_name.replace('_', '-')}-{run_label.replace('_', '-')}\"\nmetadata = {\n    \"title\": f\"Object Features {dataset_name} {run_label}\",\n    \"id\": f\"onyekamuoka/{dataset_slug}\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n\nwith open(f'{output_path}/dataset-metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\n\ntry:\n    api.dataset_create_new(\n        folder=output_path, dir_mode='zip', convert_to_csv=False, public=False\n    )\n    print(f\"âœ“ Created Kaggle dataset: {dataset_slug}\")\nexcept Exception:\n    api.dataset_create_version(\n        folder=output_path,\n        version_notes=f\"Run {run_label}\",\n        dir_mode='zip', convert_to_csv=False\n    )\n    print(f\"âœ“ Updated Kaggle dataset: {dataset_slug}\")\n\nprint(f\"\\nâœ“ https://www.kaggle.com/datasets/onyekamuoka/{dataset_slug}\")\nprint(\"\\n\" + \"=\"*80)\nprint(f\"RUN COMPLETE â€” {run_label}\")\nprint(\"Change SLIDE_START_INDEX and SLIDE_END_INDEX and run again for next slice.\")\nprint(\"When all runs done, use bracs_wsi_merge.py to combine all CSVs.\")\nprint(\"=\"*80)","metadata":{}},{"cell_type":"markdown","source":"# Object Level Take two","metadata":{}},{"cell_type":"markdown","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (SLICED RUNS)\n# ============================================================================\n#\n# HOW TO USE:\n#   This notebook processes a specific slice of slides to stay within\n#   Kaggle's 12-hour time limit. Run it multiple times, changing only\n#   SLIDE_START_INDEX and SLIDE_END_INDEX each time.\n#\n#   Recommended splits for UDH (74 slides, 31 already done):\n#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n#   â”‚  Run    â”‚  Slide Range        â”‚  Change To       â”‚\n#   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n#   â”‚  Run A  â”‚  slides 32 â€“ 47    â”‚  START=32 END=48 â”‚\n#   â”‚  Run B  â”‚  slides 48 â€“ 63    â”‚  START=48 END=64 â”‚\n#   â”‚  Run C  â”‚  slides 64 â€“ 74    â”‚  START=64 END=74 â”‚\n#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n#\n#   After all runs complete, use bracs_wsi_merge.py to combine the CSVs.\n#\n# ============================================================================\n\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# *** CHANGE THESE TWO NUMBERS EACH RUN ***\n# ============================================================================\n\nSLIDE_START_INDEX = 0   # first slide to process (0-based index into sorted slide list)\nSLIDE_END_INDEX   = 15   # process up to but NOT including this index\n\n# ============================================================================\n# CONFIGURATION (leave these unchanged across all runs)\n# ============================================================================\n\nPARALLEL_WORKERS = 4\nBATCH_SIZE = 8\ndataset_to_process = \"saadinn/bracs-wsi-group-mt-type-ic-01\"\n\n# ============================================================================\n# SETUP\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - SLICED RUN\")\nprint(\"=\"*80)\nprint(f\"\\nSlide slice: index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1}\")\nprint(f\"Downloading dataset: {dataset_to_process}\")\n\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\n\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name:  {dataset_name}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION\n# ============================================================================\n\ndef build_tissue_mask(slide):\n    mask_level = slide.level_count - 1\n    img = np.array(\n        slide.read_region((0, 0), mask_level, slide.level_dimensions[mask_level])\n    )[:, :, :3]\n\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    value = hsv[:, :, 2]\n\n    mask = (saturation > 0.03) & (value < 0.95)\n    mask = remove_small_objects(mask, min_size=300)\n    mask = remove_small_holes(mask, area_threshold=300)\n    return mask, mask_level\n\n\ndef tissue_ratio(mask, x_level0, y_level0, patch_size_level0, scale):\n    xs = int(x_level0 / scale)\n    ys = int(y_level0 / scale)\n    ps = max(int(patch_size_level0 / scale), 1)\n    patch_mask = mask[ys:ys + ps, xs:xs + ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return float(patch_mask.mean())\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n\n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.clip(rgb_norm, 1e-6, 1.0)\n        od = -np.log(rgb_norm)\n\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],\n            [0.07, 0.99, 0.11],\n            [0.27, 0.57, 0.78]\n        ])\n\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        return hematoxylin\n\n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        try:\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            hematoxylin_eq = clahe.apply(hematoxylin)\n\n            _, nucleus_mask_otsu = cv2.threshold(\n                hematoxylin_eq, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n            )\n\n            otsu_ratio = nucleus_mask_otsu.mean() / 255.0\n            if otsu_ratio < 0.05 or otsu_ratio > 0.70:\n                nucleus_mask = cv2.adaptiveThreshold(\n                    hematoxylin_eq, 255,\n                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                    cv2.THRESH_BINARY,\n                    blockSize=31,\n                    C=-2\n                )\n                nucleus_mask = nucleus_mask > 0\n            else:\n                nucleus_mask = nucleus_mask_otsu > 0\n\n        except Exception:\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            gray_inv = 255 - gray\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            gray_inv_eq = clahe.apply(gray_inv)\n            nucleus_mask = cv2.adaptiveThreshold(\n                gray_inv_eq, 255,\n                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                cv2.THRESH_BINARY,\n                blockSize=31,\n                C=-2\n            )\n            nucleus_mask = nucleus_mask > 0\n\n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=8)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=8)\n\n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n\n        nucleus_mask = dilation(nucleus_mask, disk(1))\n        distance = ndi.distance_transform_edt(nucleus_mask)\n        coords = peak_local_max(\n            distance, min_distance=2, labels=nucleus_mask, exclude_border=False\n        )\n\n        if len(coords) == 0:\n            return label(nucleus_mask)\n\n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n\n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n\n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        features = {}\n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        features['circularity'] = (\n            float(4 * np.pi * region.area / (region.perimeter ** 2))\n            if region.perimeter > 0 else 0.0\n        )\n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        features['aspect_ratio'] = (\n            float(region.major_axis_length / region.minor_axis_length)\n            if region.minor_axis_length > 0 else 0.0\n        )\n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n\n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        return features\n\n\nclass SpatialFeatureExtractor:\n\n    @staticmethod\n    def extract_spatial_features(regions):\n        default_keys = [\n            'nucleus_count', 'total_nucleus_area',\n            'nn_distance_mean', 'nn_distance_std', 'nn_distance_min',\n            'nn_distance_max', 'nn_distance_median',\n            'pairwise_distance_mean', 'pairwise_distance_std',\n            'pairwise_distance_min', 'pairwise_distance_max',\n            'centroid_x_variance', 'centroid_y_variance',\n            'centroid_x_range', 'centroid_y_range',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) == 0:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        features['nucleus_count'] = float(len(regions))\n        features['total_nucleus_area'] = float(sum(r.area for r in regions))\n\n        if len(centroids) > 1:\n            distances = cdist(centroids, centroids)\n            np.fill_diagonal(distances, np.inf)\n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n\n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            finite_vals = upper_triangle[np.isfinite(upper_triangle)]\n            if len(finite_vals) > 0:\n                features['pairwise_distance_mean'] = float(np.mean(finite_vals))\n                features['pairwise_distance_std'] = float(np.std(finite_vals))\n                features['pairwise_distance_min'] = float(np.min(finite_vals))\n                features['pairwise_distance_max'] = float(np.max(finite_vals))\n\n        if len(centroids) > 2:\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n\n        return features\n\n\nclass GraphFeatureExtractor:\n\n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        from scipy.spatial import Delaunay\n        if len(centroids) < 3:\n            return None, None\n        try:\n            tri = Delaunay(centroids)\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i + 1) % 3]]))\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            return tri, list(edges)\n        except Exception:\n            return None, None\n\n    @staticmethod\n    def extract_graph_features(regions):\n        default_keys = [\n            'num_edges', 'edge_density',\n            'degree_mean', 'degree_std', 'degree_max', 'degree_min',\n            'edge_length_mean', 'edge_length_std',\n            'edge_length_min', 'edge_length_max',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) < 3:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n\n        if edges is None or len(edges) == 0:\n            return features\n\n        features['num_edges'] = float(len(edges))\n        n = len(regions)\n        features['edge_density'] = float(len(edges) / (n * (n - 1) / 2))\n\n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n\n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n\n        edge_lengths = [\n            np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges\n        ]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n\n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n\n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n\n    def extract_all_features(self, rgb_patch):\n        all_features = {}\n\n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        regions = [r for r in regions if r.area >= 8]\n\n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum(r.area for r in regions)) if regions else 0.0\n\n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except Exception:\n                    continue\n\n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n\n        spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n        all_features.update(spatial_features)\n\n        graph_features = self.graph_extractor.extract_graph_features(regions)\n        all_features.update(graph_features)\n\n        return all_features\n\n# ============================================================================\n# STEP 5: WSI PATCH EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(wsi_path, patch_size=256, target_level=1, tissue_threshold=0.3):\n    slide = openslide.OpenSlide(wsi_path)\n    tissue_mask, mask_level = build_tissue_mask(slide)\n    mask_scale = slide.level_downsamples[mask_level]\n    target_downsample = slide.level_downsamples[target_level]\n\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n\n    for y in range(0, height, patch_size):\n        for x in range(0, width, patch_size):\n            x_level0 = int(x * target_downsample)\n            y_level0 = int(y * target_downsample)\n            patch_size_level0 = int(patch_size * target_downsample)\n\n            ratio = tissue_ratio(tissue_mask, x_level0, y_level0, patch_size_level0, mask_scale)\n\n            if ratio < tissue_threshold:\n                continue\n\n            patch = slide.read_region((x_level0, y_level0), target_level, (patch_size, patch_size))\n            patch = np.array(patch)[:, :, :3]\n\n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception:\n                continue\n\n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    if not patch_features_list:\n        return {}\n\n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n\n    slide_features = {'slide_name': slide_name, 'num_patches': len(patch_features_list)}\n\n    for feature in feature_cols:\n        feature_values = df[feature].dropna().values\n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            for suffix in ['mean', 'std', 'min', 'max', 'median', 'q25', 'q75']:\n                slide_features[f'{feature}_{suffix}'] = 0.0\n\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n\n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING\n# ============================================================================\n\ndef process_single_slide(args):\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    try:\n        patch_features = extract_object_features_from_wsi(\n            slide_path, patch_size, target_level, tissue_threshold\n        )\n        if patch_features:\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, f\"{dataset_name}_{slide_name}\"\n            )\n            return {\n                'success': True, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': slide_features,\n                'num_patches': len(patch_features), 'error': None\n            }\n        else:\n            return {\n                'success': False, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': None,\n                'num_patches': 0, 'error': 'No tissue patches found'\n            }\n    except Exception as e:\n        return {\n            'success': False, 'slide_path': slide_path,\n            'slide_name': slide_name, 'features': None,\n            'num_patches': 0, 'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: MAIN PROCESSING LOOP\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING SLICED BATCH PROCESSING\")\nprint(\"=\"*80)\n\n# Build run-specific output folder so each run's CSV is separate\nrun_label = f\"slides_{SLIDE_START_INDEX}_{SLIDE_END_INDEX - 1}\"\noutput_path = f'/kaggle/working/object_features_{dataset_name}_{run_label}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Collect and sort all slides so the index is deterministic across runs\nall_slides = []\nfor root, dirs, files in os.walk(dataset_path):\n    all_slides.extend([\n        os.path.join(root, f) for f in files\n        if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))\n    ])\nall_slides = sorted(all_slides)  # IMPORTANT: sort so index is consistent every run\n\nprint(f\"Total slides in dataset: {len(all_slides)}\")\n\n# Apply the slice\nslides_to_process = all_slides[SLIDE_START_INDEX:SLIDE_END_INDEX]\nprint(f\"This run will process: {len(slides_to_process)} slides \"\n      f\"(index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1})\")\nfor s in slides_to_process:\n    print(f\"  â€¢ {os.path.basename(s)}\")\n\nall_slides_features = []\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n\n    print(f\"\\n{'='*80}\")\n    print(f\"BATCH {batch_start // BATCH_SIZE + 1} â€” \"\n          f\"slides {SLIDE_START_INDEX + batch_start + 1}â€“\"\n          f\"{SLIDE_START_INDEX + batch_end} of {len(all_slides)} total\")\n    print(f\"{'='*80}\")\n\n    slide_args = [(s, dataset_name, 256, 1, 0.3) for s in batch_slides]\n\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        futures = {executor.submit(process_single_slide, args): args[0] for args in slide_args}\n\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            try:\n                result = future.result()\n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n\n    # Save interim CSV after every batch\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides saved so far\")\n\n# ============================================================================\n# STEP 9: SAVE THIS RUN'S FINAL CSV\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING RUN RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    final_df = pd.DataFrame(all_slides_features)\n    print(f\"Slides processed this run: {len(final_df)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n\n    # Diagnostics\n    nucleus_count_cols = [c for c in final_df.columns if 'nucleus_count' in c.lower()]\n    for col in nucleus_count_cols:\n        zero_count = (final_df[col] == 0).sum()\n        print(f\"{col}: mean={final_df[col].mean():.2f}, \"\n              f\"zero slides={zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n\n    nan_total = final_df.isna().sum().sum()\n    print(f\"Total NaN values: {nan_total} ({'none âœ“' if nan_total == 0 else 'check merge script'})\")\n\n    csv_path = f'{output_path}/{dataset_name}_{run_label}_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved: {csv_path}\")\nelse:\n    print(\"âš  No slides were successfully processed this run!\")\n\n# ============================================================================\n# STEP 10: UPLOAD THIS RUN'S OUTPUT TO KAGGLE DATASETS\n# ============================================================================\n\nfrom kaggle import api\n\ndataset_slug = f\"object-features-{dataset_name.replace('_', '-')}-{run_label.replace('_', '-')}\"\nmetadata = {\n    \"title\": f\"Object Features {dataset_name} {run_label}\",\n    \"id\": f\"onyekamuoka/{dataset_slug}\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n\nwith open(f'{output_path}/dataset-metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\n\ntry:\n    api.dataset_create_new(\n        folder=output_path, dir_mode='zip', convert_to_csv=False, public=False\n    )\n    print(f\"âœ“ Created Kaggle dataset: {dataset_slug}\")\nexcept Exception:\n    api.dataset_create_version(\n        folder=output_path,\n        version_notes=f\"Run {run_label}\",\n        dir_mode='zip', convert_to_csv=False\n    )\n    print(f\"âœ“ Updated Kaggle dataset: {dataset_slug}\")\n\nprint(f\"\\nâœ“ https://www.kaggle.com/datasets/onyekamuoka/{dataset_slug}\")\nprint(\"\\n\" + \"=\"*80)\nprint(f\"RUN COMPLETE â€” {run_label}\")\nprint(\"Change SLIDE_START_INDEX and SLIDE_END_INDEX and run again for next slice.\")\nprint(\"When all runs done, use bracs_wsi_merge.py to combine all CSVs.\")\nprint(\"=\"*80)","metadata":{}},{"cell_type":"markdown","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (SLICED RUNS)\n# ============================================================================\n#\n# HOW TO USE:\n#   This notebook processes a specific slice of slides to stay within\n#   Kaggle's 12-hour time limit. Run it multiple times, changing only\n#   SLIDE_START_INDEX and SLIDE_END_INDEX each time.\n#\n#   Recommended splits for UDH (74 slides, 31 already done):\n#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n#   â”‚  Run    â”‚  Slide Range        â”‚  Change To       â”‚\n#   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n#   â”‚  Run A  â”‚  slides 32 â€“ 47    â”‚  START=32 END=48 â”‚\n#   â”‚  Run B  â”‚  slides 48 â€“ 63    â”‚  START=48 END=64 â”‚\n#   â”‚  Run C  â”‚  slides 64 â€“ 74    â”‚  START=64 END=74 â”‚\n#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n#\n#   After all runs complete, use bracs_wsi_merge.py to combine the CSVs.\n#\n# ============================================================================\n\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# *** CHANGE THESE TWO NUMBERS EACH RUN ***\n# ============================================================================\n\nSLIDE_START_INDEX = 15   # first slide to process (0-based index into sorted slide list)\nSLIDE_END_INDEX   = 30   # process up to but NOT including this index\n\n# ============================================================================\n# CONFIGURATION (leave these unchanged across all runs)\n# ============================================================================\n\nPARALLEL_WORKERS = 4\nBATCH_SIZE = 8\ndataset_to_process = \"saadinn/bracs-wsi-group-mt-type-ic-01\"\n\n# ============================================================================\n# SETUP\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - SLICED RUN\")\nprint(\"=\"*80)\nprint(f\"\\nSlide slice: index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1}\")\nprint(f\"Downloading dataset: {dataset_to_process}\")\n\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\n\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name:  {dataset_name}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION\n# ============================================================================\n\ndef build_tissue_mask(slide):\n    mask_level = slide.level_count - 1\n    img = np.array(\n        slide.read_region((0, 0), mask_level, slide.level_dimensions[mask_level])\n    )[:, :, :3]\n\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    value = hsv[:, :, 2]\n\n    mask = (saturation > 0.03) & (value < 0.95)\n    mask = remove_small_objects(mask, min_size=300)\n    mask = remove_small_holes(mask, area_threshold=300)\n    return mask, mask_level\n\n\ndef tissue_ratio(mask, x_level0, y_level0, patch_size_level0, scale):\n    xs = int(x_level0 / scale)\n    ys = int(y_level0 / scale)\n    ps = max(int(patch_size_level0 / scale), 1)\n    patch_mask = mask[ys:ys + ps, xs:xs + ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return float(patch_mask.mean())\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n\n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.clip(rgb_norm, 1e-6, 1.0)\n        od = -np.log(rgb_norm)\n\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],\n            [0.07, 0.99, 0.11],\n            [0.27, 0.57, 0.78]\n        ])\n\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        return hematoxylin\n\n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        try:\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            hematoxylin_eq = clahe.apply(hematoxylin)\n\n            _, nucleus_mask_otsu = cv2.threshold(\n                hematoxylin_eq, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n            )\n\n            otsu_ratio = nucleus_mask_otsu.mean() / 255.0\n            if otsu_ratio < 0.05 or otsu_ratio > 0.70:\n                nucleus_mask = cv2.adaptiveThreshold(\n                    hematoxylin_eq, 255,\n                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                    cv2.THRESH_BINARY,\n                    blockSize=31,\n                    C=-2\n                )\n                nucleus_mask = nucleus_mask > 0\n            else:\n                nucleus_mask = nucleus_mask_otsu > 0\n\n        except Exception:\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            gray_inv = 255 - gray\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            gray_inv_eq = clahe.apply(gray_inv)\n            nucleus_mask = cv2.adaptiveThreshold(\n                gray_inv_eq, 255,\n                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                cv2.THRESH_BINARY,\n                blockSize=31,\n                C=-2\n            )\n            nucleus_mask = nucleus_mask > 0\n\n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=8)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=8)\n\n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n\n        nucleus_mask = dilation(nucleus_mask, disk(1))\n        distance = ndi.distance_transform_edt(nucleus_mask)\n        coords = peak_local_max(\n            distance, min_distance=2, labels=nucleus_mask, exclude_border=False\n        )\n\n        if len(coords) == 0:\n            return label(nucleus_mask)\n\n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n\n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n\n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        features = {}\n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        features['circularity'] = (\n            float(4 * np.pi * region.area / (region.perimeter ** 2))\n            if region.perimeter > 0 else 0.0\n        )\n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        features['aspect_ratio'] = (\n            float(region.major_axis_length / region.minor_axis_length)\n            if region.minor_axis_length > 0 else 0.0\n        )\n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n\n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        return features\n\n\nclass SpatialFeatureExtractor:\n\n    @staticmethod\n    def extract_spatial_features(regions):\n        default_keys = [\n            'nucleus_count', 'total_nucleus_area',\n            'nn_distance_mean', 'nn_distance_std', 'nn_distance_min',\n            'nn_distance_max', 'nn_distance_median',\n            'pairwise_distance_mean', 'pairwise_distance_std',\n            'pairwise_distance_min', 'pairwise_distance_max',\n            'centroid_x_variance', 'centroid_y_variance',\n            'centroid_x_range', 'centroid_y_range',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) == 0:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        features['nucleus_count'] = float(len(regions))\n        features['total_nucleus_area'] = float(sum(r.area for r in regions))\n\n        if len(centroids) > 1:\n            distances = cdist(centroids, centroids)\n            np.fill_diagonal(distances, np.inf)\n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n\n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            finite_vals = upper_triangle[np.isfinite(upper_triangle)]\n            if len(finite_vals) > 0:\n                features['pairwise_distance_mean'] = float(np.mean(finite_vals))\n                features['pairwise_distance_std'] = float(np.std(finite_vals))\n                features['pairwise_distance_min'] = float(np.min(finite_vals))\n                features['pairwise_distance_max'] = float(np.max(finite_vals))\n\n        if len(centroids) > 2:\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n\n        return features\n\n\nclass GraphFeatureExtractor:\n\n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        from scipy.spatial import Delaunay\n        if len(centroids) < 3:\n            return None, None\n        try:\n            tri = Delaunay(centroids)\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i + 1) % 3]]))\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            return tri, list(edges)\n        except Exception:\n            return None, None\n\n    @staticmethod\n    def extract_graph_features(regions):\n        default_keys = [\n            'num_edges', 'edge_density',\n            'degree_mean', 'degree_std', 'degree_max', 'degree_min',\n            'edge_length_mean', 'edge_length_std',\n            'edge_length_min', 'edge_length_max',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) < 3:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n\n        if edges is None or len(edges) == 0:\n            return features\n\n        features['num_edges'] = float(len(edges))\n        n = len(regions)\n        features['edge_density'] = float(len(edges) / (n * (n - 1) / 2))\n\n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n\n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n\n        edge_lengths = [\n            np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges\n        ]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n\n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n\n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n\n    def extract_all_features(self, rgb_patch):\n        all_features = {}\n\n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        regions = [r for r in regions if r.area >= 8]\n\n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum(r.area for r in regions)) if regions else 0.0\n\n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except Exception:\n                    continue\n\n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n\n        spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n        all_features.update(spatial_features)\n\n        graph_features = self.graph_extractor.extract_graph_features(regions)\n        all_features.update(graph_features)\n\n        return all_features\n\n# ============================================================================\n# STEP 5: WSI PATCH EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(wsi_path, patch_size=256, target_level=1, tissue_threshold=0.3):\n    slide = openslide.OpenSlide(wsi_path)\n    tissue_mask, mask_level = build_tissue_mask(slide)\n    mask_scale = slide.level_downsamples[mask_level]\n    target_downsample = slide.level_downsamples[target_level]\n\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n\n    for y in range(0, height, patch_size):\n        for x in range(0, width, patch_size):\n            x_level0 = int(x * target_downsample)\n            y_level0 = int(y * target_downsample)\n            patch_size_level0 = int(patch_size * target_downsample)\n\n            ratio = tissue_ratio(tissue_mask, x_level0, y_level0, patch_size_level0, mask_scale)\n\n            if ratio < tissue_threshold:\n                continue\n\n            patch = slide.read_region((x_level0, y_level0), target_level, (patch_size, patch_size))\n            patch = np.array(patch)[:, :, :3]\n\n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception:\n                continue\n\n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    if not patch_features_list:\n        return {}\n\n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n\n    slide_features = {'slide_name': slide_name, 'num_patches': len(patch_features_list)}\n\n    for feature in feature_cols:\n        feature_values = df[feature].dropna().values\n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            for suffix in ['mean', 'std', 'min', 'max', 'median', 'q25', 'q75']:\n                slide_features[f'{feature}_{suffix}'] = 0.0\n\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n\n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING\n# ============================================================================\n\ndef process_single_slide(args):\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    try:\n        patch_features = extract_object_features_from_wsi(\n            slide_path, patch_size, target_level, tissue_threshold\n        )\n        if patch_features:\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, f\"{dataset_name}_{slide_name}\"\n            )\n            return {\n                'success': True, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': slide_features,\n                'num_patches': len(patch_features), 'error': None\n            }\n        else:\n            return {\n                'success': False, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': None,\n                'num_patches': 0, 'error': 'No tissue patches found'\n            }\n    except Exception as e:\n        return {\n            'success': False, 'slide_path': slide_path,\n            'slide_name': slide_name, 'features': None,\n            'num_patches': 0, 'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: MAIN PROCESSING LOOP\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING SLICED BATCH PROCESSING\")\nprint(\"=\"*80)\n\n# Build run-specific output folder so each run's CSV is separate\nrun_label = f\"slides_{SLIDE_START_INDEX}_{SLIDE_END_INDEX - 1}\"\noutput_path = f'/kaggle/working/object_features_{dataset_name}_{run_label}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Collect and sort all slides so the index is deterministic across runs\nall_slides = []\nfor root, dirs, files in os.walk(dataset_path):\n    all_slides.extend([\n        os.path.join(root, f) for f in files\n        if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))\n    ])\nall_slides = sorted(all_slides)  # IMPORTANT: sort so index is consistent every run\n\nprint(f\"Total slides in dataset: {len(all_slides)}\")\n\n# Apply the slice\nslides_to_process = all_slides[SLIDE_START_INDEX:SLIDE_END_INDEX]\nprint(f\"This run will process: {len(slides_to_process)} slides \"\n      f\"(index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1})\")\nfor s in slides_to_process:\n    print(f\"  â€¢ {os.path.basename(s)}\")\n\nall_slides_features = []\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n\n    print(f\"\\n{'='*80}\")\n    print(f\"BATCH {batch_start // BATCH_SIZE + 1} â€” \"\n          f\"slides {SLIDE_START_INDEX + batch_start + 1}â€“\"\n          f\"{SLIDE_START_INDEX + batch_end} of {len(all_slides)} total\")\n    print(f\"{'='*80}\")\n\n    slide_args = [(s, dataset_name, 256, 1, 0.3) for s in batch_slides]\n\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        futures = {executor.submit(process_single_slide, args): args[0] for args in slide_args}\n\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            try:\n                result = future.result()\n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n\n    # Save interim CSV after every batch\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides saved so far\")\n\n# ============================================================================\n# STEP 9: SAVE THIS RUN'S FINAL CSV\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING RUN RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    final_df = pd.DataFrame(all_slides_features)\n    print(f\"Slides processed this run: {len(final_df)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n\n    # Diagnostics\n    nucleus_count_cols = [c for c in final_df.columns if 'nucleus_count' in c.lower()]\n    for col in nucleus_count_cols:\n        zero_count = (final_df[col] == 0).sum()\n        print(f\"{col}: mean={final_df[col].mean():.2f}, \"\n              f\"zero slides={zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n\n    nan_total = final_df.isna().sum().sum()\n    print(f\"Total NaN values: {nan_total} ({'none âœ“' if nan_total == 0 else 'check merge script'})\")\n\n    csv_path = f'{output_path}/{dataset_name}_{run_label}_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved: {csv_path}\")\nelse:\n    print(\"âš  No slides were successfully processed this run!\")\n\n# ============================================================================\n# STEP 10: UPLOAD THIS RUN'S OUTPUT TO KAGGLE DATASETS\n# ============================================================================\n\nfrom kaggle import api\n\ndataset_slug = f\"object-features-{dataset_name.replace('_', '-')}-{run_label.replace('_', '-')}\"\nmetadata = {\n    \"title\": f\"Object Features {dataset_name} {run_label}\",\n    \"id\": f\"onyekamuoka/{dataset_slug}\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n\nwith open(f'{output_path}/dataset-metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\n\ntry:\n    api.dataset_create_new(\n        folder=output_path, dir_mode='zip', convert_to_csv=False, public=False\n    )\n    print(f\"âœ“ Created Kaggle dataset: {dataset_slug}\")\nexcept Exception:\n    api.dataset_create_version(\n        folder=output_path,\n        version_notes=f\"Run {run_label}\",\n        dir_mode='zip', convert_to_csv=False\n    )\n    print(f\"âœ“ Updated Kaggle dataset: {dataset_slug}\")\n\nprint(f\"\\nâœ“ https://www.kaggle.com/datasets/onyekamuoka/{dataset_slug}\")\nprint(\"\\n\" + \"=\"*80)\nprint(f\"RUN COMPLETE â€” {run_label}\")\nprint(\"Change SLIDE_START_INDEX and SLIDE_END_INDEX and run again for next slice.\")\nprint(\"When all runs done, use bracs_wsi_merge.py to combine all CSVs.\")\nprint(\"=\"*80)","metadata":{}},{"cell_type":"markdown","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (SLICED RUNS)\n# ============================================================================\n#\n# HOW TO USE:\n#   This notebook processes a specific slice of slides to stay within\n#   Kaggle's 12-hour time limit. Run it multiple times, changing only\n#   SLIDE_START_INDEX and SLIDE_END_INDEX each time.\n#\n#   Recommended splits for UDH (74 slides, 31 already done):\n#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n#   â”‚  Run    â”‚  Slide Range        â”‚  Change To       â”‚\n#   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n#   â”‚  Run A  â”‚  slides 32 â€“ 47    â”‚  START=32 END=48 â”‚\n#   â”‚  Run B  â”‚  slides 48 â€“ 63    â”‚  START=48 END=64 â”‚\n#   â”‚  Run C  â”‚  slides 64 â€“ 74    â”‚  START=64 END=74 â”‚\n#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n#\n#   After all runs complete, use bracs_wsi_merge.py to combine the CSVs.\n#\n# ============================================================================\n\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# *** CHANGE THESE TWO NUMBERS EACH RUN ***\n# ============================================================================\n\nSLIDE_START_INDEX = 15   # first slide to process (0-based index into sorted slide list)\nSLIDE_END_INDEX   = 30   # process up to but NOT including this index\n\n# ============================================================================\n# CONFIGURATION (leave these unchanged across all runs)\n# ============================================================================\n\nPARALLEL_WORKERS = 4\nBATCH_SIZE = 8\ndataset_to_process = \"saadinn/bracs-wsi-group-mt-type-ic-01\"\n\n# ============================================================================\n# SETUP\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - SLICED RUN\")\nprint(\"=\"*80)\nprint(f\"\\nSlide slice: index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1}\")\nprint(f\"Downloading dataset: {dataset_to_process}\")\n\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\n\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name:  {dataset_name}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION\n# ============================================================================\n\ndef build_tissue_mask(slide):\n    mask_level = slide.level_count - 1\n    img = np.array(\n        slide.read_region((0, 0), mask_level, slide.level_dimensions[mask_level])\n    )[:, :, :3]\n\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    value = hsv[:, :, 2]\n\n    mask = (saturation > 0.03) & (value < 0.95)\n    mask = remove_small_objects(mask, min_size=300)\n    mask = remove_small_holes(mask, area_threshold=300)\n    return mask, mask_level\n\n\ndef tissue_ratio(mask, x_level0, y_level0, patch_size_level0, scale):\n    xs = int(x_level0 / scale)\n    ys = int(y_level0 / scale)\n    ps = max(int(patch_size_level0 / scale), 1)\n    patch_mask = mask[ys:ys + ps, xs:xs + ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return float(patch_mask.mean())\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n\n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.clip(rgb_norm, 1e-6, 1.0)\n        od = -np.log(rgb_norm)\n\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],\n            [0.07, 0.99, 0.11],\n            [0.27, 0.57, 0.78]\n        ])\n\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        return hematoxylin\n\n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        try:\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            hematoxylin_eq = clahe.apply(hematoxylin)\n\n            _, nucleus_mask_otsu = cv2.threshold(\n                hematoxylin_eq, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n            )\n\n            otsu_ratio = nucleus_mask_otsu.mean() / 255.0\n            if otsu_ratio < 0.05 or otsu_ratio > 0.70:\n                nucleus_mask = cv2.adaptiveThreshold(\n                    hematoxylin_eq, 255,\n                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                    cv2.THRESH_BINARY,\n                    blockSize=31,\n                    C=-2\n                )\n                nucleus_mask = nucleus_mask > 0\n            else:\n                nucleus_mask = nucleus_mask_otsu > 0\n\n        except Exception:\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            gray_inv = 255 - gray\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            gray_inv_eq = clahe.apply(gray_inv)\n            nucleus_mask = cv2.adaptiveThreshold(\n                gray_inv_eq, 255,\n                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                cv2.THRESH_BINARY,\n                blockSize=31,\n                C=-2\n            )\n            nucleus_mask = nucleus_mask > 0\n\n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=8)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=8)\n\n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n\n        nucleus_mask = dilation(nucleus_mask, disk(1))\n        distance = ndi.distance_transform_edt(nucleus_mask)\n        coords = peak_local_max(\n            distance, min_distance=2, labels=nucleus_mask, exclude_border=False\n        )\n\n        if len(coords) == 0:\n            return label(nucleus_mask)\n\n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n\n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n\n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        features = {}\n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        features['circularity'] = (\n            float(4 * np.pi * region.area / (region.perimeter ** 2))\n            if region.perimeter > 0 else 0.0\n        )\n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        features['aspect_ratio'] = (\n            float(region.major_axis_length / region.minor_axis_length)\n            if region.minor_axis_length > 0 else 0.0\n        )\n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n\n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        return features\n\n\nclass SpatialFeatureExtractor:\n\n    @staticmethod\n    def extract_spatial_features(regions):\n        default_keys = [\n            'nucleus_count', 'total_nucleus_area',\n            'nn_distance_mean', 'nn_distance_std', 'nn_distance_min',\n            'nn_distance_max', 'nn_distance_median',\n            'pairwise_distance_mean', 'pairwise_distance_std',\n            'pairwise_distance_min', 'pairwise_distance_max',\n            'centroid_x_variance', 'centroid_y_variance',\n            'centroid_x_range', 'centroid_y_range',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) == 0:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        features['nucleus_count'] = float(len(regions))\n        features['total_nucleus_area'] = float(sum(r.area for r in regions))\n\n        if len(centroids) > 1:\n            distances = cdist(centroids, centroids)\n            np.fill_diagonal(distances, np.inf)\n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n\n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            finite_vals = upper_triangle[np.isfinite(upper_triangle)]\n            if len(finite_vals) > 0:\n                features['pairwise_distance_mean'] = float(np.mean(finite_vals))\n                features['pairwise_distance_std'] = float(np.std(finite_vals))\n                features['pairwise_distance_min'] = float(np.min(finite_vals))\n                features['pairwise_distance_max'] = float(np.max(finite_vals))\n\n        if len(centroids) > 2:\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n\n        return features\n\n\nclass GraphFeatureExtractor:\n\n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        from scipy.spatial import Delaunay\n        if len(centroids) < 3:\n            return None, None\n        try:\n            tri = Delaunay(centroids)\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i + 1) % 3]]))\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            return tri, list(edges)\n        except Exception:\n            return None, None\n\n    @staticmethod\n    def extract_graph_features(regions):\n        default_keys = [\n            'num_edges', 'edge_density',\n            'degree_mean', 'degree_std', 'degree_max', 'degree_min',\n            'edge_length_mean', 'edge_length_std',\n            'edge_length_min', 'edge_length_max',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) < 3:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n\n        if edges is None or len(edges) == 0:\n            return features\n\n        features['num_edges'] = float(len(edges))\n        n = len(regions)\n        features['edge_density'] = float(len(edges) / (n * (n - 1) / 2))\n\n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n\n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n\n        edge_lengths = [\n            np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges\n        ]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n\n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n\n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n\n    def extract_all_features(self, rgb_patch):\n        all_features = {}\n\n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        regions = [r for r in regions if r.area >= 8]\n\n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum(r.area for r in regions)) if regions else 0.0\n\n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except Exception:\n                    continue\n\n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n\n        spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n        all_features.update(spatial_features)\n\n        graph_features = self.graph_extractor.extract_graph_features(regions)\n        all_features.update(graph_features)\n\n        return all_features\n\n# ============================================================================\n# STEP 5: WSI PATCH EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(wsi_path, patch_size=256, target_level=1, tissue_threshold=0.3):\n    slide = openslide.OpenSlide(wsi_path)\n    tissue_mask, mask_level = build_tissue_mask(slide)\n    mask_scale = slide.level_downsamples[mask_level]\n    target_downsample = slide.level_downsamples[target_level]\n\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n\n    for y in range(0, height, patch_size):\n        for x in range(0, width, patch_size):\n            x_level0 = int(x * target_downsample)\n            y_level0 = int(y * target_downsample)\n            patch_size_level0 = int(patch_size * target_downsample)\n\n            ratio = tissue_ratio(tissue_mask, x_level0, y_level0, patch_size_level0, mask_scale)\n\n            if ratio < tissue_threshold:\n                continue\n\n            patch = slide.read_region((x_level0, y_level0), target_level, (patch_size, patch_size))\n            patch = np.array(patch)[:, :, :3]\n\n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception:\n                continue\n\n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    if not patch_features_list:\n        return {}\n\n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n\n    slide_features = {'slide_name': slide_name, 'num_patches': len(patch_features_list)}\n\n    for feature in feature_cols:\n        feature_values = df[feature].dropna().values\n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            for suffix in ['mean', 'std', 'min', 'max', 'median', 'q25', 'q75']:\n                slide_features[f'{feature}_{suffix}'] = 0.0\n\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n\n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING\n# ============================================================================\n\ndef process_single_slide(args):\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    try:\n        patch_features = extract_object_features_from_wsi(\n            slide_path, patch_size, target_level, tissue_threshold\n        )\n        if patch_features:\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, f\"{dataset_name}_{slide_name}\"\n            )\n            return {\n                'success': True, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': slide_features,\n                'num_patches': len(patch_features), 'error': None\n            }\n        else:\n            return {\n                'success': False, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': None,\n                'num_patches': 0, 'error': 'No tissue patches found'\n            }\n    except Exception as e:\n        return {\n            'success': False, 'slide_path': slide_path,\n            'slide_name': slide_name, 'features': None,\n            'num_patches': 0, 'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: MAIN PROCESSING LOOP\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING SLICED BATCH PROCESSING\")\nprint(\"=\"*80)\n\n# Build run-specific output folder so each run's CSV is separate\nrun_label = f\"slides_{SLIDE_START_INDEX}_{SLIDE_END_INDEX - 1}\"\noutput_path = f'/kaggle/working/object_features_{dataset_name}_{run_label}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Collect and sort all slides so the index is deterministic across runs\nall_slides = []\nfor root, dirs, files in os.walk(dataset_path):\n    all_slides.extend([\n        os.path.join(root, f) for f in files\n        if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))\n    ])\nall_slides = sorted(all_slides)  # IMPORTANT: sort so index is consistent every run\n\nprint(f\"Total slides in dataset: {len(all_slides)}\")\n\n# Apply the slice\nslides_to_process = all_slides[SLIDE_START_INDEX:SLIDE_END_INDEX]\nprint(f\"This run will process: {len(slides_to_process)} slides \"\n      f\"(index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1})\")\nfor s in slides_to_process:\n    print(f\"  â€¢ {os.path.basename(s)}\")\n\nall_slides_features = []\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n\n    print(f\"\\n{'='*80}\")\n    print(f\"BATCH {batch_start // BATCH_SIZE + 1} â€” \"\n          f\"slides {SLIDE_START_INDEX + batch_start + 1}â€“\"\n          f\"{SLIDE_START_INDEX + batch_end} of {len(all_slides)} total\")\n    print(f\"{'='*80}\")\n\n    slide_args = [(s, dataset_name, 256, 1, 0.3) for s in batch_slides]\n\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        futures = {executor.submit(process_single_slide, args): args[0] for args in slide_args}\n\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            try:\n                result = future.result()\n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n\n    # Save interim CSV after every batch\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides saved so far\")\n\n# ============================================================================\n# STEP 9: SAVE THIS RUN'S FINAL CSV\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING RUN RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    final_df = pd.DataFrame(all_slides_features)\n    print(f\"Slides processed this run: {len(final_df)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n\n    # Diagnostics\n    nucleus_count_cols = [c for c in final_df.columns if 'nucleus_count' in c.lower()]\n    for col in nucleus_count_cols:\n        zero_count = (final_df[col] == 0).sum()\n        print(f\"{col}: mean={final_df[col].mean():.2f}, \"\n              f\"zero slides={zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n\n    nan_total = final_df.isna().sum().sum()\n    print(f\"Total NaN values: {nan_total} ({'none âœ“' if nan_total == 0 else 'check merge script'})\")\n\n    csv_path = f'{output_path}/{dataset_name}_{run_label}_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved: {csv_path}\")\nelse:\n    print(\"âš  No slides were successfully processed this run!\")\n\n# ============================================================================\n# STEP 10: UPLOAD THIS RUN'S OUTPUT TO KAGGLE DATASETS\n# ============================================================================\n\nfrom kaggle import api\n\ndataset_slug = f\"object-features-{dataset_name.replace('_', '-')}-{run_label.replace('_', '-')}\"\nmetadata = {\n    \"title\": f\"Object Features {dataset_name} {run_label}\",\n    \"id\": f\"onyekamuoka/{dataset_slug}\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n\nwith open(f'{output_path}/dataset-metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\n\ntry:\n    api.dataset_create_new(\n        folder=output_path, dir_mode='zip', convert_to_csv=False, public=False\n    )\n    print(f\"âœ“ Created Kaggle dataset: {dataset_slug}\")\nexcept Exception:\n    api.dataset_create_version(\n        folder=output_path,\n        version_notes=f\"Run {run_label}\",\n        dir_mode='zip', convert_to_csv=False\n    )\n    print(f\"âœ“ Updated Kaggle dataset: {dataset_slug}\")\n\nprint(f\"\\nâœ“ https://www.kaggle.com/datasets/onyekamuoka/{dataset_slug}\")\nprint(\"\\n\" + \"=\"*80)\nprint(f\"RUN COMPLETE â€” {run_label}\")\nprint(\"Change SLIDE_START_INDEX and SLIDE_END_INDEX and run again for next slice.\")\nprint(\"When all runs done, use bracs_wsi_merge.py to combine all CSVs.\")\nprint(\"=\"*80)","metadata":{}},{"cell_type":"markdown","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (SLICED RUNS)\n# ============================================================================\n#\n# HOW TO USE:\n#   This notebook processes a specific slice of slides to stay within\n#   Kaggle's 12-hour time limit. Run it multiple times, changing only\n#   SLIDE_START_INDEX and SLIDE_END_INDEX each time.\n#\n#   Recommended splits for UDH (74 slides, 31 already done):\n#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n#   â”‚  Run    â”‚  Slide Range        â”‚  Change To       â”‚\n#   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n#   â”‚  Run A  â”‚  slides 32 â€“ 47    â”‚  START=32 END=48 â”‚\n#   â”‚  Run B  â”‚  slides 48 â€“ 63    â”‚  START=48 END=64 â”‚\n#   â”‚  Run C  â”‚  slides 64 â€“ 74    â”‚  START=64 END=74 â”‚\n#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n#\n#   After all runs complete, use bracs_wsi_merge.py to combine the CSVs.\n#\n# ============================================================================\n\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# *** CHANGE THESE TWO NUMBERS EACH RUN ***\n# ============================================================================\n\nSLIDE_START_INDEX = 15   # first slide to process (0-based index into sorted slide list)\nSLIDE_END_INDEX   = 22   # process up to but NOT including this index\n\n# ============================================================================\n# CONFIGURATION (leave these unchanged across all runs)\n# ============================================================================\n\nPARALLEL_WORKERS = 4\nBATCH_SIZE = 8\ndataset_to_process = \"saadinn/bracs-wsi-group-mt-type-ic-01\"\n\n# ============================================================================\n# SETUP\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - SLICED RUN\")\nprint(\"=\"*80)\nprint(f\"\\nSlide slice: index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1}\")\nprint(f\"Downloading dataset: {dataset_to_process}\")\n\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\n\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name:  {dataset_name}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION\n# ============================================================================\n\ndef build_tissue_mask(slide):\n    mask_level = slide.level_count - 1\n    img = np.array(\n        slide.read_region((0, 0), mask_level, slide.level_dimensions[mask_level])\n    )[:, :, :3]\n\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    value = hsv[:, :, 2]\n\n    mask = (saturation > 0.03) & (value < 0.95)\n    mask = remove_small_objects(mask, min_size=300)\n    mask = remove_small_holes(mask, area_threshold=300)\n    return mask, mask_level\n\n\ndef tissue_ratio(mask, x_level0, y_level0, patch_size_level0, scale):\n    xs = int(x_level0 / scale)\n    ys = int(y_level0 / scale)\n    ps = max(int(patch_size_level0 / scale), 1)\n    patch_mask = mask[ys:ys + ps, xs:xs + ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return float(patch_mask.mean())\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n\n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.clip(rgb_norm, 1e-6, 1.0)\n        od = -np.log(rgb_norm)\n\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],\n            [0.07, 0.99, 0.11],\n            [0.27, 0.57, 0.78]\n        ])\n\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        return hematoxylin\n\n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        try:\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            hematoxylin_eq = clahe.apply(hematoxylin)\n\n            _, nucleus_mask_otsu = cv2.threshold(\n                hematoxylin_eq, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n            )\n\n            otsu_ratio = nucleus_mask_otsu.mean() / 255.0\n            if otsu_ratio < 0.05 or otsu_ratio > 0.70:\n                nucleus_mask = cv2.adaptiveThreshold(\n                    hematoxylin_eq, 255,\n                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                    cv2.THRESH_BINARY,\n                    blockSize=31,\n                    C=-2\n                )\n                nucleus_mask = nucleus_mask > 0\n            else:\n                nucleus_mask = nucleus_mask_otsu > 0\n\n        except Exception:\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            gray_inv = 255 - gray\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            gray_inv_eq = clahe.apply(gray_inv)\n            nucleus_mask = cv2.adaptiveThreshold(\n                gray_inv_eq, 255,\n                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                cv2.THRESH_BINARY,\n                blockSize=31,\n                C=-2\n            )\n            nucleus_mask = nucleus_mask > 0\n\n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=8)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=8)\n\n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n\n        nucleus_mask = dilation(nucleus_mask, disk(1))\n        distance = ndi.distance_transform_edt(nucleus_mask)\n        coords = peak_local_max(\n            distance, min_distance=2, labels=nucleus_mask, exclude_border=False\n        )\n\n        if len(coords) == 0:\n            return label(nucleus_mask)\n\n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n\n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n\n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        features = {}\n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        features['circularity'] = (\n            float(4 * np.pi * region.area / (region.perimeter ** 2))\n            if region.perimeter > 0 else 0.0\n        )\n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        features['aspect_ratio'] = (\n            float(region.major_axis_length / region.minor_axis_length)\n            if region.minor_axis_length > 0 else 0.0\n        )\n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n\n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        return features\n\n\nclass SpatialFeatureExtractor:\n\n    @staticmethod\n    def extract_spatial_features(regions):\n        default_keys = [\n            'nucleus_count', 'total_nucleus_area',\n            'nn_distance_mean', 'nn_distance_std', 'nn_distance_min',\n            'nn_distance_max', 'nn_distance_median',\n            'pairwise_distance_mean', 'pairwise_distance_std',\n            'pairwise_distance_min', 'pairwise_distance_max',\n            'centroid_x_variance', 'centroid_y_variance',\n            'centroid_x_range', 'centroid_y_range',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) == 0:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        features['nucleus_count'] = float(len(regions))\n        features['total_nucleus_area'] = float(sum(r.area for r in regions))\n\n        if len(centroids) > 1:\n            distances = cdist(centroids, centroids)\n            np.fill_diagonal(distances, np.inf)\n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n\n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            finite_vals = upper_triangle[np.isfinite(upper_triangle)]\n            if len(finite_vals) > 0:\n                features['pairwise_distance_mean'] = float(np.mean(finite_vals))\n                features['pairwise_distance_std'] = float(np.std(finite_vals))\n                features['pairwise_distance_min'] = float(np.min(finite_vals))\n                features['pairwise_distance_max'] = float(np.max(finite_vals))\n\n        if len(centroids) > 2:\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n\n        return features\n\n\nclass GraphFeatureExtractor:\n\n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        from scipy.spatial import Delaunay\n        if len(centroids) < 3:\n            return None, None\n        try:\n            tri = Delaunay(centroids)\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i + 1) % 3]]))\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            return tri, list(edges)\n        except Exception:\n            return None, None\n\n    @staticmethod\n    def extract_graph_features(regions):\n        default_keys = [\n            'num_edges', 'edge_density',\n            'degree_mean', 'degree_std', 'degree_max', 'degree_min',\n            'edge_length_mean', 'edge_length_std',\n            'edge_length_min', 'edge_length_max',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) < 3:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n\n        if edges is None or len(edges) == 0:\n            return features\n\n        features['num_edges'] = float(len(edges))\n        n = len(regions)\n        features['edge_density'] = float(len(edges) / (n * (n - 1) / 2))\n\n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n\n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n\n        edge_lengths = [\n            np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges\n        ]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n\n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n\n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n\n    def extract_all_features(self, rgb_patch):\n        all_features = {}\n\n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        regions = [r for r in regions if r.area >= 8]\n\n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum(r.area for r in regions)) if regions else 0.0\n\n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except Exception:\n                    continue\n\n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n\n        spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n        all_features.update(spatial_features)\n\n        graph_features = self.graph_extractor.extract_graph_features(regions)\n        all_features.update(graph_features)\n\n        return all_features\n\n# ============================================================================\n# STEP 5: WSI PATCH EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(wsi_path, patch_size=256, target_level=1, tissue_threshold=0.3):\n    slide = openslide.OpenSlide(wsi_path)\n    tissue_mask, mask_level = build_tissue_mask(slide)\n    mask_scale = slide.level_downsamples[mask_level]\n    target_downsample = slide.level_downsamples[target_level]\n\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n\n    for y in range(0, height, patch_size):\n        for x in range(0, width, patch_size):\n            x_level0 = int(x * target_downsample)\n            y_level0 = int(y * target_downsample)\n            patch_size_level0 = int(patch_size * target_downsample)\n\n            ratio = tissue_ratio(tissue_mask, x_level0, y_level0, patch_size_level0, mask_scale)\n\n            if ratio < tissue_threshold:\n                continue\n\n            patch = slide.read_region((x_level0, y_level0), target_level, (patch_size, patch_size))\n            patch = np.array(patch)[:, :, :3]\n\n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception:\n                continue\n\n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    if not patch_features_list:\n        return {}\n\n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n\n    slide_features = {'slide_name': slide_name, 'num_patches': len(patch_features_list)}\n\n    for feature in feature_cols:\n        feature_values = df[feature].dropna().values\n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            for suffix in ['mean', 'std', 'min', 'max', 'median', 'q25', 'q75']:\n                slide_features[f'{feature}_{suffix}'] = 0.0\n\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n\n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING\n# ============================================================================\n\ndef process_single_slide(args):\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    try:\n        patch_features = extract_object_features_from_wsi(\n            slide_path, patch_size, target_level, tissue_threshold\n        )\n        if patch_features:\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, f\"{dataset_name}_{slide_name}\"\n            )\n            return {\n                'success': True, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': slide_features,\n                'num_patches': len(patch_features), 'error': None\n            }\n        else:\n            return {\n                'success': False, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': None,\n                'num_patches': 0, 'error': 'No tissue patches found'\n            }\n    except Exception as e:\n        return {\n            'success': False, 'slide_path': slide_path,\n            'slide_name': slide_name, 'features': None,\n            'num_patches': 0, 'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: MAIN PROCESSING LOOP\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING SLICED BATCH PROCESSING\")\nprint(\"=\"*80)\n\n# Build run-specific output folder so each run's CSV is separate\nrun_label = f\"slides_{SLIDE_START_INDEX}_{SLIDE_END_INDEX - 1}\"\noutput_path = f'/kaggle/working/object_features_{dataset_name}_{run_label}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Collect and sort all slides so the index is deterministic across runs\nall_slides = []\nfor root, dirs, files in os.walk(dataset_path):\n    all_slides.extend([\n        os.path.join(root, f) for f in files\n        if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))\n    ])\nall_slides = sorted(all_slides)  # IMPORTANT: sort so index is consistent every run\n\nprint(f\"Total slides in dataset: {len(all_slides)}\")\n\n# Apply the slice\nslides_to_process = all_slides[SLIDE_START_INDEX:SLIDE_END_INDEX]\nprint(f\"This run will process: {len(slides_to_process)} slides \"\n      f\"(index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1})\")\nfor s in slides_to_process:\n    print(f\"  â€¢ {os.path.basename(s)}\")\n\nall_slides_features = []\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n\n    print(f\"\\n{'='*80}\")\n    print(f\"BATCH {batch_start // BATCH_SIZE + 1} â€” \"\n          f\"slides {SLIDE_START_INDEX + batch_start + 1}â€“\"\n          f\"{SLIDE_START_INDEX + batch_end} of {len(all_slides)} total\")\n    print(f\"{'='*80}\")\n\n    slide_args = [(s, dataset_name, 256, 1, 0.3) for s in batch_slides]\n\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        futures = {executor.submit(process_single_slide, args): args[0] for args in slide_args}\n\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            try:\n                result = future.result()\n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n\n    # Save interim CSV after every batch\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides saved so far\")\n\n# ============================================================================\n# STEP 9: SAVE THIS RUN'S FINAL CSV\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING RUN RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    final_df = pd.DataFrame(all_slides_features)\n    print(f\"Slides processed this run: {len(final_df)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n\n    # Diagnostics\n    nucleus_count_cols = [c for c in final_df.columns if 'nucleus_count' in c.lower()]\n    for col in nucleus_count_cols:\n        zero_count = (final_df[col] == 0).sum()\n        print(f\"{col}: mean={final_df[col].mean():.2f}, \"\n              f\"zero slides={zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n\n    nan_total = final_df.isna().sum().sum()\n    print(f\"Total NaN values: {nan_total} ({'none âœ“' if nan_total == 0 else 'check merge script'})\")\n\n    csv_path = f'{output_path}/{dataset_name}_{run_label}_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved: {csv_path}\")\nelse:\n    print(\"âš  No slides were successfully processed this run!\")\n\n# ============================================================================\n# STEP 10: UPLOAD THIS RUN'S OUTPUT TO KAGGLE DATASETS\n# ============================================================================\n\nfrom kaggle import api\n\ndataset_slug = f\"object-features-{dataset_name.replace('_', '-')}-{run_label.replace('_', '-')}\"\nmetadata = {\n    \"title\": f\"Object Features {dataset_name} {run_label}\",\n    \"id\": f\"onyekamuoka/{dataset_slug}\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n\nwith open(f'{output_path}/dataset-metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\n\ntry:\n    api.dataset_create_new(\n        folder=output_path, dir_mode='zip', convert_to_csv=False, public=False\n    )\n    print(f\"âœ“ Created Kaggle dataset: {dataset_slug}\")\nexcept Exception:\n    api.dataset_create_version(\n        folder=output_path,\n        version_notes=f\"Run {run_label}\",\n        dir_mode='zip', convert_to_csv=False\n    )\n    print(f\"âœ“ Updated Kaggle dataset: {dataset_slug}\")\n\nprint(f\"\\nâœ“ https://www.kaggle.com/datasets/onyekamuoka/{dataset_slug}\")\nprint(\"\\n\" + \"=\"*80)\nprint(f\"RUN COMPLETE â€” {run_label}\")\nprint(\"Change SLIDE_START_INDEX and SLIDE_END_INDEX and run again for next slice.\")\nprint(\"When all runs done, use bracs_wsi_merge.py to combine all CSVs.\")\nprint(\"=\"*80)","metadata":{}},{"cell_type":"code","source":"# ============================================================================\n# KAGGLE NOTEBOOK: BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION (SLICED RUNS)\n# ============================================================================\n#\n# HOW TO USE:\n#   This notebook processes a specific slice of slides to stay within\n#   Kaggle's 12-hour time limit. Run it multiple times, changing only\n#   SLIDE_START_INDEX and SLIDE_END_INDEX each time.\n#\n#   Recommended splits for UDH (74 slides, 31 already done):\n#   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n#   â”‚  Run    â”‚  Slide Range        â”‚  Change To       â”‚\n#   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n#   â”‚  Run A  â”‚  slides 32 â€“ 47    â”‚  START=32 END=48 â”‚\n#   â”‚  Run B  â”‚  slides 48 â€“ 63    â”‚  START=48 END=64 â”‚\n#   â”‚  Run C  â”‚  slides 64 â€“ 74    â”‚  START=64 END=74 â”‚\n#   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n#\n#   After all runs complete, use bracs_wsi_merge.py to combine the CSVs.\n#\n# ============================================================================\n\nimport os\nimport numpy as np\nimport cv2\nimport kagglehub\nimport openslide\nfrom skimage.color import rgb2hsv\nfrom skimage.morphology import remove_small_holes, remove_small_objects, disk, dilation\nfrom skimage.measure import label, regionprops\nfrom skimage.segmentation import watershed\nfrom skimage.feature import peak_local_max\nfrom scipy import ndimage as ndi\nfrom scipy.spatial.distance import cdist\nfrom scipy.stats import skew, kurtosis\nimport json\nimport pandas as pd\nfrom concurrent.futures import ProcessPoolExecutor, as_completed\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# ============================================================================\n# *** CHANGE THESE TWO NUMBERS EACH RUN ***\n# ============================================================================\n\nSLIDE_START_INDEX = 22   # first slide to process (0-based index into sorted slide list)\nSLIDE_END_INDEX   = 32   # process up to but NOT including this index\n\n# ============================================================================\n# CONFIGURATION (leave these unchanged across all runs)\n# ============================================================================\n\nPARALLEL_WORKERS = 4\nBATCH_SIZE = 8\ndataset_to_process = \"saadinn/bracs-wsi-group-mt-type-ic-01\"\n\n# ============================================================================\n# SETUP\n# ============================================================================\n\nprint(\"=\"*80)\nprint(\"BRACS WSI OBJECT-LEVEL FEATURE EXTRACTION - SLICED RUN\")\nprint(\"=\"*80)\nprint(f\"\\nSlide slice: index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1}\")\nprint(f\"Downloading dataset: {dataset_to_process}\")\n\ndataset_path = kagglehub.dataset_download(dataset_to_process)\ndataset_name = dataset_to_process.split('/')[-1]\n\nprint(f\"âœ“ Downloaded to: {dataset_path}\")\nprint(f\"âœ“ Dataset name:  {dataset_name}\")\n\n# ============================================================================\n# STEP 2: TISSUE DETECTION\n# ============================================================================\n\ndef build_tissue_mask(slide):\n    mask_level = slide.level_count - 1\n    img = np.array(\n        slide.read_region((0, 0), mask_level, slide.level_dimensions[mask_level])\n    )[:, :, :3]\n\n    hsv = rgb2hsv(img)\n    saturation = hsv[:, :, 1]\n    value = hsv[:, :, 2]\n\n    mask = (saturation > 0.03) & (value < 0.95)\n    mask = remove_small_objects(mask, min_size=300)\n    mask = remove_small_holes(mask, area_threshold=300)\n    return mask, mask_level\n\n\ndef tissue_ratio(mask, x_level0, y_level0, patch_size_level0, scale):\n    xs = int(x_level0 / scale)\n    ys = int(y_level0 / scale)\n    ps = max(int(patch_size_level0 / scale), 1)\n    patch_mask = mask[ys:ys + ps, xs:xs + ps]\n    if patch_mask.size == 0:\n        return 0.0\n    return float(patch_mask.mean())\n\n# ============================================================================\n# STEP 3: NUCLEUS SEGMENTATION\n# ============================================================================\n\nclass NucleusSegmenter:\n\n    @staticmethod\n    def extract_hematoxylin_channel(rgb_patch):\n        rgb_norm = rgb_patch.astype(np.float32) / 255.0\n        rgb_norm = np.clip(rgb_norm, 1e-6, 1.0)\n        od = -np.log(rgb_norm)\n\n        HE_matrix = np.array([\n            [0.65, 0.70, 0.29],\n            [0.07, 0.99, 0.11],\n            [0.27, 0.57, 0.78]\n        ])\n\n        od_flat = od.reshape(-1, 3)\n        stains = np.linalg.lstsq(HE_matrix.T, od_flat.T, rcond=None)[0].T\n        hematoxylin = stains[:, 0].reshape(rgb_patch.shape[:2])\n        hematoxylin = np.clip(hematoxylin, 0, None)\n        hematoxylin = (hematoxylin / (hematoxylin.max() + 1e-6) * 255).astype(np.uint8)\n        return hematoxylin\n\n    @staticmethod\n    def segment_nuclei(rgb_patch):\n        try:\n            hematoxylin = NucleusSegmenter.extract_hematoxylin_channel(rgb_patch)\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            hematoxylin_eq = clahe.apply(hematoxylin)\n\n            _, nucleus_mask_otsu = cv2.threshold(\n                hematoxylin_eq, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU\n            )\n\n            otsu_ratio = nucleus_mask_otsu.mean() / 255.0\n            if otsu_ratio < 0.05 or otsu_ratio > 0.70:\n                nucleus_mask = cv2.adaptiveThreshold(\n                    hematoxylin_eq, 255,\n                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                    cv2.THRESH_BINARY,\n                    blockSize=31,\n                    C=-2\n                )\n                nucleus_mask = nucleus_mask > 0\n            else:\n                nucleus_mask = nucleus_mask_otsu > 0\n\n        except Exception:\n            gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n            gray_inv = 255 - gray\n            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n            gray_inv_eq = clahe.apply(gray_inv)\n            nucleus_mask = cv2.adaptiveThreshold(\n                gray_inv_eq, 255,\n                cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n                cv2.THRESH_BINARY,\n                blockSize=31,\n                C=-2\n            )\n            nucleus_mask = nucleus_mask > 0\n\n        nucleus_mask = remove_small_objects(nucleus_mask, min_size=8)\n        nucleus_mask = remove_small_holes(nucleus_mask, area_threshold=8)\n\n        if not nucleus_mask.any():\n            return np.zeros(rgb_patch.shape[:2], dtype=int)\n\n        nucleus_mask = dilation(nucleus_mask, disk(1))\n        distance = ndi.distance_transform_edt(nucleus_mask)\n        coords = peak_local_max(\n            distance, min_distance=2, labels=nucleus_mask, exclude_border=False\n        )\n\n        if len(coords) == 0:\n            return label(nucleus_mask)\n\n        mask_centers = np.zeros(distance.shape, dtype=bool)\n        mask_centers[tuple(coords.T)] = True\n        markers = label(mask_centers)\n        labeled_nuclei = watershed(-distance, markers, mask=nucleus_mask)\n\n        return labeled_nuclei\n\n# ============================================================================\n# STEP 4: FEATURE EXTRACTORS\n# ============================================================================\n\nclass NucleusFeatureExtractor:\n\n    @staticmethod\n    def extract_nucleus_features(region, intensity_image):\n        features = {}\n        features['area'] = float(region.area)\n        features['perimeter'] = float(region.perimeter)\n        features['eccentricity'] = float(region.eccentricity)\n        features['solidity'] = float(region.solidity)\n        features['extent'] = float(region.extent)\n        features['orientation'] = float(region.orientation)\n        features['circularity'] = (\n            float(4 * np.pi * region.area / (region.perimeter ** 2))\n            if region.perimeter > 0 else 0.0\n        )\n        features['major_axis_length'] = float(region.major_axis_length)\n        features['minor_axis_length'] = float(region.minor_axis_length)\n        features['aspect_ratio'] = (\n            float(region.major_axis_length / region.minor_axis_length)\n            if region.minor_axis_length > 0 else 0.0\n        )\n        bbox = region.bbox\n        features['bbox_width'] = float(bbox[3] - bbox[1])\n        features['bbox_height'] = float(bbox[2] - bbox[0])\n        features['bbox_area'] = float(features['bbox_width'] * features['bbox_height'])\n\n        nucleus_pixels = intensity_image[region.coords[:, 0], region.coords[:, 1]]\n        features['intensity_mean'] = float(np.mean(nucleus_pixels))\n        features['intensity_std'] = float(np.std(nucleus_pixels))\n        features['intensity_min'] = float(np.min(nucleus_pixels))\n        features['intensity_max'] = float(np.max(nucleus_pixels))\n        features['intensity_range'] = float(np.max(nucleus_pixels) - np.min(nucleus_pixels))\n        features['intensity_median'] = float(np.median(nucleus_pixels))\n        features['intensity_skewness'] = float(skew(nucleus_pixels))\n        features['intensity_kurtosis'] = float(kurtosis(nucleus_pixels))\n        return features\n\n\nclass SpatialFeatureExtractor:\n\n    @staticmethod\n    def extract_spatial_features(regions):\n        default_keys = [\n            'nucleus_count', 'total_nucleus_area',\n            'nn_distance_mean', 'nn_distance_std', 'nn_distance_min',\n            'nn_distance_max', 'nn_distance_median',\n            'pairwise_distance_mean', 'pairwise_distance_std',\n            'pairwise_distance_min', 'pairwise_distance_max',\n            'centroid_x_variance', 'centroid_y_variance',\n            'centroid_x_range', 'centroid_y_range',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) == 0:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        features['nucleus_count'] = float(len(regions))\n        features['total_nucleus_area'] = float(sum(r.area for r in regions))\n\n        if len(centroids) > 1:\n            distances = cdist(centroids, centroids)\n            np.fill_diagonal(distances, np.inf)\n            nn_distances = np.min(distances, axis=1)\n            features['nn_distance_mean'] = float(np.mean(nn_distances))\n            features['nn_distance_std'] = float(np.std(nn_distances))\n            features['nn_distance_min'] = float(np.min(nn_distances))\n            features['nn_distance_max'] = float(np.max(nn_distances))\n            features['nn_distance_median'] = float(np.median(nn_distances))\n\n            upper_triangle = distances[np.triu_indices_from(distances, k=1)]\n            finite_vals = upper_triangle[np.isfinite(upper_triangle)]\n            if len(finite_vals) > 0:\n                features['pairwise_distance_mean'] = float(np.mean(finite_vals))\n                features['pairwise_distance_std'] = float(np.std(finite_vals))\n                features['pairwise_distance_min'] = float(np.min(finite_vals))\n                features['pairwise_distance_max'] = float(np.max(finite_vals))\n\n        if len(centroids) > 2:\n            features['centroid_x_variance'] = float(np.var(centroids[:, 1]))\n            features['centroid_y_variance'] = float(np.var(centroids[:, 0]))\n            features['centroid_x_range'] = float(np.max(centroids[:, 1]) - np.min(centroids[:, 1]))\n            features['centroid_y_range'] = float(np.max(centroids[:, 0]) - np.min(centroids[:, 0]))\n\n        return features\n\n\nclass GraphFeatureExtractor:\n\n    @staticmethod\n    def build_delaunay_graph(centroids, max_edge_length=100):\n        from scipy.spatial import Delaunay\n        if len(centroids) < 3:\n            return None, None\n        try:\n            tri = Delaunay(centroids)\n            edges = set()\n            for simplex in tri.simplices:\n                for i in range(3):\n                    edge = tuple(sorted([simplex[i], simplex[(i + 1) % 3]]))\n                    dist = np.linalg.norm(centroids[edge[0]] - centroids[edge[1]])\n                    if dist < max_edge_length:\n                        edges.add(edge)\n            return tri, list(edges)\n        except Exception:\n            return None, None\n\n    @staticmethod\n    def extract_graph_features(regions):\n        default_keys = [\n            'num_edges', 'edge_density',\n            'degree_mean', 'degree_std', 'degree_max', 'degree_min',\n            'edge_length_mean', 'edge_length_std',\n            'edge_length_min', 'edge_length_max',\n        ]\n        features = {k: 0.0 for k in default_keys}\n\n        if len(regions) < 3:\n            return features\n\n        centroids = np.array([region.centroid for region in regions])\n        tri, edges = GraphFeatureExtractor.build_delaunay_graph(centroids)\n\n        if edges is None or len(edges) == 0:\n            return features\n\n        features['num_edges'] = float(len(edges))\n        n = len(regions)\n        features['edge_density'] = float(len(edges) / (n * (n - 1) / 2))\n\n        degree_count = {}\n        for edge in edges:\n            degree_count[edge[0]] = degree_count.get(edge[0], 0) + 1\n            degree_count[edge[1]] = degree_count.get(edge[1], 0) + 1\n\n        if degree_count:\n            degrees = list(degree_count.values())\n            features['degree_mean'] = float(np.mean(degrees))\n            features['degree_std'] = float(np.std(degrees))\n            features['degree_max'] = float(np.max(degrees))\n            features['degree_min'] = float(np.min(degrees))\n\n        edge_lengths = [\n            np.linalg.norm(centroids[e[0]] - centroids[e[1]]) for e in edges\n        ]\n        features['edge_length_mean'] = float(np.mean(edge_lengths))\n        features['edge_length_std'] = float(np.std(edge_lengths))\n        features['edge_length_min'] = float(np.min(edge_lengths))\n        features['edge_length_max'] = float(np.max(edge_lengths))\n\n        return features\n\n\nclass ComprehensiveObjectFeatureExtractor:\n\n    def __init__(self):\n        self.nucleus_extractor = NucleusFeatureExtractor()\n        self.spatial_extractor = SpatialFeatureExtractor()\n        self.graph_extractor = GraphFeatureExtractor()\n\n    def extract_all_features(self, rgb_patch):\n        all_features = {}\n\n        labeled_nuclei = NucleusSegmenter.segment_nuclei(rgb_patch)\n        gray = cv2.cvtColor(rgb_patch, cv2.COLOR_RGB2GRAY)\n        regions = regionprops(labeled_nuclei, intensity_image=gray)\n        regions = [r for r in regions if r.area >= 8]\n\n        all_features['nucleus_count'] = len(regions)\n        all_features['total_nucleus_area'] = float(sum(r.area for r in regions)) if regions else 0.0\n\n        if len(regions) > 0:\n            nucleus_features_list = []\n            for region in regions:\n                try:\n                    nuc_feat = self.nucleus_extractor.extract_nucleus_features(region, gray)\n                    nucleus_features_list.append(nuc_feat)\n                except Exception:\n                    continue\n\n            if nucleus_features_list:\n                df = pd.DataFrame(nucleus_features_list)\n                for col in df.columns:\n                    all_features[f'nucleus_{col}_mean'] = float(df[col].mean())\n                    all_features[f'nucleus_{col}_std'] = float(df[col].std())\n                    all_features[f'nucleus_{col}_min'] = float(df[col].min())\n                    all_features[f'nucleus_{col}_max'] = float(df[col].max())\n                    all_features[f'nucleus_{col}_median'] = float(df[col].median())\n\n        spatial_features = self.spatial_extractor.extract_spatial_features(regions)\n        all_features.update(spatial_features)\n\n        graph_features = self.graph_extractor.extract_graph_features(regions)\n        all_features.update(graph_features)\n\n        return all_features\n\n# ============================================================================\n# STEP 5: WSI PATCH EXTRACTION\n# ============================================================================\n\ndef extract_object_features_from_wsi(wsi_path, patch_size=256, target_level=1, tissue_threshold=0.3):\n    slide = openslide.OpenSlide(wsi_path)\n    tissue_mask, mask_level = build_tissue_mask(slide)\n    mask_scale = slide.level_downsamples[mask_level]\n    target_downsample = slide.level_downsamples[target_level]\n\n    extractor = ComprehensiveObjectFeatureExtractor()\n    features_list = []\n    width, height = slide.level_dimensions[target_level]\n\n    for y in range(0, height, patch_size):\n        for x in range(0, width, patch_size):\n            x_level0 = int(x * target_downsample)\n            y_level0 = int(y * target_downsample)\n            patch_size_level0 = int(patch_size * target_downsample)\n\n            ratio = tissue_ratio(tissue_mask, x_level0, y_level0, patch_size_level0, mask_scale)\n\n            if ratio < tissue_threshold:\n                continue\n\n            patch = slide.read_region((x_level0, y_level0), target_level, (patch_size, patch_size))\n            patch = np.array(patch)[:, :, :3]\n\n            try:\n                patch_features = extractor.extract_all_features(patch)\n                patch_features['patch_x'] = x\n                patch_features['patch_y'] = y\n                patch_features['tissue_ratio'] = float(ratio)\n                features_list.append(patch_features)\n            except Exception:\n                continue\n\n    slide.close()\n    return features_list\n\n# ============================================================================\n# STEP 6: SLIDE-LEVEL AGGREGATION\n# ============================================================================\n\ndef aggregate_patch_features_to_slide_level(patch_features_list, slide_name):\n    if not patch_features_list:\n        return {}\n\n    df = pd.DataFrame(patch_features_list)\n    metadata_cols = ['patch_x', 'patch_y', 'tissue_ratio']\n    feature_cols = [col for col in df.columns if col not in metadata_cols]\n\n    slide_features = {'slide_name': slide_name, 'num_patches': len(patch_features_list)}\n\n    for feature in feature_cols:\n        feature_values = df[feature].dropna().values\n        if len(feature_values) > 0:\n            slide_features[f'{feature}_mean'] = float(np.mean(feature_values))\n            slide_features[f'{feature}_std'] = float(np.std(feature_values))\n            slide_features[f'{feature}_min'] = float(np.min(feature_values))\n            slide_features[f'{feature}_max'] = float(np.max(feature_values))\n            slide_features[f'{feature}_median'] = float(np.median(feature_values))\n            slide_features[f'{feature}_q25'] = float(np.percentile(feature_values, 25))\n            slide_features[f'{feature}_q75'] = float(np.percentile(feature_values, 75))\n        else:\n            for suffix in ['mean', 'std', 'min', 'max', 'median', 'q25', 'q75']:\n                slide_features[f'{feature}_{suffix}'] = 0.0\n\n    slide_features['tissue_ratio_mean'] = float(df['tissue_ratio'].mean())\n    slide_features['tissue_ratio_std'] = float(df['tissue_ratio'].std())\n\n    return slide_features\n\n# ============================================================================\n# STEP 7: PARALLEL SLIDE PROCESSING\n# ============================================================================\n\ndef process_single_slide(args):\n    slide_path, dataset_name, patch_size, target_level, tissue_threshold = args\n    slide_name = os.path.basename(slide_path)\n    try:\n        patch_features = extract_object_features_from_wsi(\n            slide_path, patch_size, target_level, tissue_threshold\n        )\n        if patch_features:\n            slide_features = aggregate_patch_features_to_slide_level(\n                patch_features, f\"{dataset_name}_{slide_name}\"\n            )\n            return {\n                'success': True, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': slide_features,\n                'num_patches': len(patch_features), 'error': None\n            }\n        else:\n            return {\n                'success': False, 'slide_path': slide_path,\n                'slide_name': slide_name, 'features': None,\n                'num_patches': 0, 'error': 'No tissue patches found'\n            }\n    except Exception as e:\n        return {\n            'success': False, 'slide_path': slide_path,\n            'slide_name': slide_name, 'features': None,\n            'num_patches': 0, 'error': str(e)\n        }\n\n# ============================================================================\n# STEP 8: MAIN PROCESSING LOOP\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"STARTING SLICED BATCH PROCESSING\")\nprint(\"=\"*80)\n\n# Build run-specific output folder so each run's CSV is separate\nrun_label = f\"slides_{SLIDE_START_INDEX}_{SLIDE_END_INDEX - 1}\"\noutput_path = f'/kaggle/working/object_features_{dataset_name}_{run_label}/'\nos.makedirs(output_path, exist_ok=True)\n\n# Collect and sort all slides so the index is deterministic across runs\nall_slides = []\nfor root, dirs, files in os.walk(dataset_path):\n    all_slides.extend([\n        os.path.join(root, f) for f in files\n        if f.endswith(('.svs', '.tif', '.tiff', '.ndpi'))\n    ])\nall_slides = sorted(all_slides)  # IMPORTANT: sort so index is consistent every run\n\nprint(f\"Total slides in dataset: {len(all_slides)}\")\n\n# Apply the slice\nslides_to_process = all_slides[SLIDE_START_INDEX:SLIDE_END_INDEX]\nprint(f\"This run will process: {len(slides_to_process)} slides \"\n      f\"(index {SLIDE_START_INDEX} â†’ {SLIDE_END_INDEX - 1})\")\nfor s in slides_to_process:\n    print(f\"  â€¢ {os.path.basename(s)}\")\n\nall_slides_features = []\ntotal_processed = 0\n\nfor batch_start in range(0, len(slides_to_process), BATCH_SIZE):\n    batch_end = min(batch_start + BATCH_SIZE, len(slides_to_process))\n    batch_slides = slides_to_process[batch_start:batch_end]\n\n    print(f\"\\n{'='*80}\")\n    print(f\"BATCH {batch_start // BATCH_SIZE + 1} â€” \"\n          f\"slides {SLIDE_START_INDEX + batch_start + 1}â€“\"\n          f\"{SLIDE_START_INDEX + batch_end} of {len(all_slides)} total\")\n    print(f\"{'='*80}\")\n\n    slide_args = [(s, dataset_name, 256, 1, 0.3) for s in batch_slides]\n\n    with ProcessPoolExecutor(max_workers=PARALLEL_WORKERS) as executor:\n        futures = {executor.submit(process_single_slide, args): args[0] for args in slide_args}\n\n        for future in as_completed(futures):\n            slide_path = futures[future]\n            try:\n                result = future.result()\n                if result['success']:\n                    print(f\"  âœ“ {result['slide_name']}: {result['num_patches']} patches\")\n                    all_slides_features.append(result['features'])\n                    total_processed += 1\n                else:\n                    print(f\"  âœ— {result['slide_name']}: {result['error']}\")\n            except Exception as e:\n                print(f\"  âœ— Error with {os.path.basename(slide_path)}: {str(e)}\")\n\n    # Save interim CSV after every batch\n    if all_slides_features:\n        temp_df = pd.DataFrame(all_slides_features)\n        temp_df.to_csv(f'{output_path}/slide_object_features_temp.csv', index=False)\n        print(f\"\\n  ðŸ’¾ Batch checkpoint: {total_processed} slides saved so far\")\n\n# ============================================================================\n# STEP 9: SAVE THIS RUN'S FINAL CSV\n# ============================================================================\n\nprint(\"\\n\" + \"=\"*80)\nprint(\"SAVING RUN RESULTS\")\nprint(\"=\"*80)\n\nif all_slides_features:\n    final_df = pd.DataFrame(all_slides_features)\n    print(f\"Slides processed this run: {len(final_df)}\")\n    print(f\"Features per slide: {final_df.shape[1]}\")\n\n    # Diagnostics\n    nucleus_count_cols = [c for c in final_df.columns if 'nucleus_count' in c.lower()]\n    for col in nucleus_count_cols:\n        zero_count = (final_df[col] == 0).sum()\n        print(f\"{col}: mean={final_df[col].mean():.2f}, \"\n              f\"zero slides={zero_count}/{len(final_df)} ({100*zero_count/len(final_df):.1f}%)\")\n\n    nan_total = final_df.isna().sum().sum()\n    print(f\"Total NaN values: {nan_total} ({'none âœ“' if nan_total == 0 else 'check merge script'})\")\n\n    csv_path = f'{output_path}/{dataset_name}_{run_label}_features.csv'\n    final_df.to_csv(csv_path, index=False)\n    print(f\"\\nâœ“ Saved: {csv_path}\")\nelse:\n    print(\"âš  No slides were successfully processed this run!\")\n\n# ============================================================================\n# STEP 10: UPLOAD THIS RUN'S OUTPUT TO KAGGLE DATASETS\n# ============================================================================\n\nfrom kaggle import api\n\ndataset_slug = f\"object-features-{dataset_name.replace('_', '-')}-{run_label.replace('_', '-')}\"\nmetadata = {\n    \"title\": f\"Object Features {dataset_name} {run_label}\",\n    \"id\": f\"onyekamuoka/{dataset_slug}\",\n    \"licenses\": [{\"name\": \"CC0-1.0\"}]\n}\n\nwith open(f'{output_path}/dataset-metadata.json', 'w') as f:\n    json.dump(metadata, f, indent=2)\n\ntry:\n    api.dataset_create_new(\n        folder=output_path, dir_mode='zip', convert_to_csv=False, public=False\n    )\n    print(f\"âœ“ Created Kaggle dataset: {dataset_slug}\")\nexcept Exception:\n    api.dataset_create_version(\n        folder=output_path,\n        version_notes=f\"Run {run_label}\",\n        dir_mode='zip', convert_to_csv=False\n    )\n    print(f\"âœ“ Updated Kaggle dataset: {dataset_slug}\")\n\nprint(f\"\\nâœ“ https://www.kaggle.com/datasets/onyekamuoka/{dataset_slug}\")\nprint(\"\\n\" + \"=\"*80)\nprint(f\"RUN COMPLETE â€” {run_label}\")\nprint(\"Change SLIDE_START_INDEX and SLIDE_END_INDEX and run again for next slice.\")\nprint(\"When all runs done, use bracs_wsi_merge.py to combine all CSVs.\")\nprint(\"=\"*80)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}